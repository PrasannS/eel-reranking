{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbdfd6d-d718-4eec-88b0-77789bf845d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 04:15:00.541792: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-24 04:15:00.541813: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "from rerank_score_cands_new import load_cands\n",
    "import numpy as np\n",
    "from comet import download_model, load_from_checkpoint\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bd5aacbb-a9a8-40b6-b96c-163a23fe0a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a5a294e-2a53-41f1-b41e-2ca2f82e8458",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Encoder-Decoder Model Embedding, Add a Weighted Layer at the end that leads to regression\n",
    "class XLMCometRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self, drop_rate=0.1):\n",
    "        # TODO should we be freezing layers?\n",
    "        super().__init__()\n",
    "        \n",
    "        self.xlmroberta = AutoModel.from_pretrained('xlm-roberta-base')\n",
    "        # Num labels 1 should just indicate regression (?)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.xlmroberta.config.hidden_size, 1), \n",
    "        )\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        # don't finetune xlmroberta model\n",
    "        #with torch.no_grad():\n",
    "        word_rep, sentence_rep = self.xlmroberta(input_ids, attention_mask=attention_masks, encoder_attention_mask=attention_masks, return_dict=False)\n",
    "        # use the first <s> token as a CLS token, TODO experiment with using the sum of \n",
    "        # outputs = self.regressor(torch.sum(word_rep, 1))\n",
    "        outputs = self.regressor(torch.sum(word_rep, 1))\n",
    "        #print(\"Shape: \", outputs.shape)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "model = XLMCometRegressor(drop_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be093eb4-509d-43d7-989b-7540cd122cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./torchsaved/comestim.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0a50c18-84a1-420f-8ad8-de907b586847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data comes from WMT 2019 [I think], TODO validate exact year being used\n",
    "# data generated with gold reference given as hyp\n",
    "golddf = pd.read_csv('./processeddata/golddata.csv')\n",
    "golddf['inp'] = golddf['fr']\n",
    "golddf['hyp'] = golddf['en']\n",
    "# data generated on candidates from beam search 50 and lattice (lots of bad)\n",
    "distill_df = pd.read_csv('distill_cometdata_1.csv')\n",
    "# data generated between random / unrelated sentences \n",
    "rand_df = pd.read_csv('distill_cometdata_rand.csv')[:30000]\n",
    "# combine\n",
    "alldf = distill_df.append(rand_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b273369-3dfb-482d-a8df-c165787a8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "del golddf, rand_df, distill_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f134a5ad-4a74-41ed-9fc7-40a06b1c6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XLM roberta for now\n",
    "xlm_tok = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
    "# shuffle data \n",
    "alldf = shuffle(alldf)\n",
    "alldf = alldf.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1a791c95-4d52-4c37-a6dd-3b607997b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct inputs from dataframe\n",
    "def get_inputs(inpdf):\n",
    "    xinp = []\n",
    "    yinp = []\n",
    "    maskinp = []\n",
    "    \n",
    "    for index, row in inpdf.iterrows():\n",
    "        if index%1000==0:\n",
    "            print(index)\n",
    "        #print(row['c1'], row['c2'])\n",
    "        # will need to make a custom mask (maybe) so that inputs from both languages are encoded separately\n",
    "        toktmp = xlm_tok(row['inp']).input_ids\n",
    "        lent = len(toktmp)\n",
    "        hyptmp = xlm_tok(row['hyp']).input_ids\n",
    "        toktmp.extend(hyptmp)\n",
    "        mask = torch.zeros(len(toktmp), len(toktmp))\n",
    "        # should set upper left and bottom right quadrants to 1, mask other stuff\n",
    "        # TODO make different types of masks. \n",
    "        mask[:lent, :lent] = 1\n",
    "        mask[lent:, lent:] = 1\n",
    "        xinp.append(toktmp)\n",
    "        maskinp.append(mask)\n",
    "        yinp.append(row['scores'])\n",
    "    return xinp, yinp, maskinp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b189ebb-18a1-451e-9f1c-738ecded9e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates masks, tokenized input, and labels in training ready format\n",
    "xdata, ydata, mdata = get_inputs(alldf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21d6961d-2ff6-41dc-8c5b-64671db61ea3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(xtrain)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mxtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m500\u001b[39m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m xtrain[i]\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m ytrain[i]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(xtrain)):\n",
    "    if len(xtrain[i])>500:\n",
    "        del xtrain[i]\n",
    "        del ytrain[i]\n",
    "        del mtrain[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "650234a5-13dc-4445-b97b-a292e1be4d74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "144000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24f07e35-1994-485e-ba44-c6fef5c57d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "cut = int(len(xdata)*.9)\n",
    "xtrain, ytrain, mtrain = xdata[:cut], ydata[:cut], mdata[:cut]\n",
    "xtest, ytest, mtest = xdata[cut:], ydata[cut:], mdata[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8af5ff6e-68ce-4807-81f1-83822199ec70",
   "metadata": {},
   "outputs": [],
   "source": [
    "xtiny, ytiny, mtiny = xtrain[:10000], ytrain[:10000], mtrain[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7b29751-2cc4-4109-8cb4-ac7be7146b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all as precaution\n",
    "def save_cometqe_data(md, xd, yd):\n",
    "    # save data into a pickle file\n",
    "    with open('processeddata/commasks.pkl', 'wb') as f:\n",
    "        pickle.dump(md, f)\n",
    "\n",
    "    with open('processeddata/cominps.pkl', 'wb') as f:\n",
    "        pickle.dump(xd, f)\n",
    "\n",
    "    with open('processeddata/comlabels.pkl', 'wb') as f:\n",
    "        pickle.dump(yd, f)\n",
    "        \n",
    "def load_cometqe_data():\n",
    "    with open('processeddata/commasks.pkl', 'rb') as f:\n",
    "        masks = pickle.load(f)\n",
    "\n",
    "    with open('processeddata/cominps.pkl', 'rb') as f:\n",
    "        xinps = pickle.load(f)\n",
    "\n",
    "    with open('processeddata/comlabels.pkl', 'rb') as f:\n",
    "        yinps = pickle.load(f)\n",
    "    return masks, xinps, yinps\n",
    "\n",
    "mdata, xdata, ydata = load_cometqe_data()\n",
    "        \n",
    "#save_cometqe_data(mdata, xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a419403-ff57-4583-9f69-ee14771f2f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "del mdata, xdata, ydata\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "24beb2d9-8520-4520-b8a2-e6d06aa30014",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, masks):\n",
    "        assert len(sentences) == len(labels)\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.masks = masks\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences[i], self.labels[i], self.masks[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "def collate_custom(datafull):\n",
    "    #print(len(datafull[0]))\n",
    "    data = [torch.tensor(d[0]) for d in datafull]\n",
    "    masdata=  [d[2] for d in datafull]\n",
    "    labels = [d[1] for d in datafull]\n",
    "    max_len = max([x.squeeze().numel() for x in data])\n",
    "    data = [torch.nn.functional.pad(x, pad=(0, max_len - x.numel()), mode='constant', value=0) for x in data]\n",
    "    data = torch.stack(data).to(device)\n",
    "    # just a normal mask for now\n",
    "    masdata = [torch.ones_like(m) for m in masdata]\n",
    "    masdata = [torch.nn.functional.pad(x, pad=(0, max_len - x[0].numel(), 0, max_len - x[0].numel()), mode='constant', value=0) for x in masdata]\n",
    "    masdata = torch.stack(masdata).to(device)\n",
    "    return data, torch.tensor(labels).to(device), masdata\n",
    "\n",
    "testloader = DataLoader(RegressionDataset(xtest, ytest, mtest), batch_size=32, shuffle=True, collate_fn=collate_custom)\n",
    "trainloader = DataLoader(RegressionDataset(xtrain, ytrain, mtrain), batch_size=32, shuffle=True, collate_fn=collate_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79d91005-836e-415c-b943-a3b425e6b3b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtiny' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tinyloader \u001b[38;5;241m=\u001b[39m DataLoader(RegressionDataset(\u001b[43mxtiny\u001b[49m, ytiny, mtiny), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_custom)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xtiny' is not defined"
     ]
    }
   ],
   "source": [
    "tinyloader = DataLoader(RegressionDataset(xtiny, ytiny, mtiny), batch_size=8, shuffle=True, collate_fn=collate_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cfe13842-e550-4128-840f-09615ce82dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr=1e-5,\n",
    "                  eps=1e-8)\n",
    "epochs = 100\n",
    "total_steps = len(trainloader) * epochs\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer,       \n",
    "                 num_warmup_steps=0, num_training_steps=total_steps)\n",
    "\n",
    "loss_function = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2a551c6e-b034-4fbc-a6bc-717c21c4ead7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(l[0][0]) for l in iter(trainloader)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1a03299-cb46-4488-bbc4-2baafc36fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "def train(model, optimizer, scheduler, loss_function, epochs,       \n",
    "          train_dataloader, device, clip_value=2):\n",
    "    print(\"Total steps :\", total_steps)\n",
    "    best_loss = 1e10\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%1==0:\n",
    "            print(\"EPOCH \", epoch)\n",
    "            print(\"-----\")\n",
    "            print(best_loss)\n",
    "        model.train()\n",
    "        cbest = 1e10\n",
    "        lostot = 0\n",
    "        loscnt = 0\n",
    "        for step, batch in enumerate(train_dataloader): \n",
    "            batch_inputs, batch_labels, batch_masks = \\\n",
    "                               tuple(b.to(device) for b in batch)\n",
    "            model.zero_grad()\n",
    "            outputs = model(batch_inputs, batch_masks)\n",
    "            #print(outputs.squeeze().shape)\n",
    "            #print(batch_labels.squeeze().shape)\n",
    "            loss = loss_function(outputs.squeeze(), \n",
    "                             batch_labels.squeeze())\n",
    "            lostot+=loss\n",
    "            loscnt+=1\n",
    "            if step%500==0:\n",
    "                #print(loss)  \n",
    "                if loscnt>0:\n",
    "                    print(lostot/loscnt)\n",
    "                    cbest = min(float(lostot/loscnt), cbest)\n",
    "                    best_loss = min(best_loss, cbest)\n",
    "                    print(\"cbest, \", cbest)\n",
    "                    if cbest==best_loss:\n",
    "                        torch.save(model.state_dict(),\"torchsaved/comestim\"+str(epoch)+\".pt\")\n",
    "            #best_loss = min(best_loss, float(loss))\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        cbest = min(float(lostot/loscnt), cbest)\n",
    "        best_loss = min(best_loss, cbest)\n",
    "        print(\"cbest, \", cbest)\n",
    "        if cbest==best_loss:\n",
    "            torch.save(model.state_dict(), \"torchsaved/comestim\"+str(epoch)+\".pt\")\n",
    "    return model\n",
    "\n",
    "def evaluate(model, loss_function, tdataloader, device):\n",
    "    model.eval()\n",
    "    test_loss, test_r2 = [], []\n",
    "    preds = []\n",
    "    ind = 0\n",
    "    for batch in tdataloader:\n",
    "        batch_inputs, batch_labels,batch_masks = \\\n",
    "                                 tuple(b.to(device) for b in batch)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_inputs, batch_masks)\n",
    "        loss = loss_function(outputs.squeeze(), \n",
    "                             batch_labels.squeeze())\n",
    "        preds.extend(list(outputs.squeeze()))\n",
    "        test_loss.append(loss.item())\n",
    "        #r2 = r2_score(outputs, batch_labels)\n",
    "        #test_r2.append(r2.item())\n",
    "        if ind==10:\n",
    "            print(batch_labels)\n",
    "            print(outputs)\n",
    "        ind+=1\n",
    "    return test_loss, preds\n",
    "\n",
    "def r2_score(outputs, labels):\n",
    "    labels_mean = torch.mean(labels)\n",
    "    ss_tot = torch.sum((labels - labels_mean) ** 2)\n",
    "    ss_res = torch.sum((labels - outputs) ** 2)\n",
    "    r2 = 1 - ss_res / ss_tot\n",
    "    return r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cf629fb-072b-4326-8af1-ccec6f11bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model \n",
    "model = XLMCometRegressor(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/comestim15.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46c96ce7-5520-4b13-92bf-58a2de69a7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = evaluate(model, loss_function, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35907783-1f6f-4801-8ae5-d8e05bb80ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "28abafa5-bf6a-45b4-b5c2-37d76474cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sloss = [math.sqrt(l) for l in loss[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e01c24ca-445c-4d04-8565-6a89ab8ae0aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps : 450000\n",
      "EPOCH  0\n",
      "-----\n",
      "10000000000.0\n",
      "tensor(0.0096, device='cuda:3', grad_fn=<DivBackward0>)\n",
      "cbest,  0.009644205681979656\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [73]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m#best_loss = min(best_loss, float(loss))\u001b[39;00m\n\u001b[1;32m     36\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 37\u001b[0m \u001b[43mclip_grad_norm_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     39\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:42\u001b[0m, in \u001b[0;36mclip_grad_norm_\u001b[0;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[1;32m     40\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m norms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(norms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mstack(norms))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([torch\u001b[38;5;241m.\u001b[39mnorm(p\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mdetach(), norm_type)\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]), norm_type)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/utils/clip_grad.py:42\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     40\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m norms[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(norms) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mmax(torch\u001b[38;5;241m.\u001b[39mstack(norms))\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 42\u001b[0m     total_norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(torch\u001b[38;5;241m.\u001b[39mstack([\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m parameters]), norm_type)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m error_if_nonfinite \u001b[38;5;129;01mand\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mlogical_or(total_norm\u001b[38;5;241m.\u001b[39misnan(), total_norm\u001b[38;5;241m.\u001b[39misinf()):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m     45\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe total norm of order \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnorm_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for gradients from \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`parameters` is non-finite, so it cannot be clipped. To disable \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthis error and scale the gradients by the non-finite norm anyway, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     48\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mset `error_if_nonfinite=False`\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/functional.py:1421\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(input, p, dim, keepdim, out, dtype)\u001b[0m\n\u001b[1;32m   1419\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(p, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m   1420\u001b[0m         _dim \u001b[38;5;241m=\u001b[39m [i \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(ndim)]  \u001b[38;5;66;03m# noqa: C416 TODO: rewrite as list(range(m))\u001b[39;00m\n\u001b[0;32m-> 1421\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_VF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m(\u001b[38;5;28minput\u001b[39m, p, dim\u001b[38;5;241m=\u001b[39m_dim, keepdim\u001b[38;5;241m=\u001b[39mkeepdim)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[1;32m   1423\u001b[0m \u001b[38;5;66;03m# TODO: when https://github.com/pytorch/pytorch/issues/33782 is fixed\u001b[39;00m\n\u001b[1;32m   1424\u001b[0m \u001b[38;5;66;03m# remove the overloads where dim is an int and replace with BraodcastingList1\u001b[39;00m\n\u001b[1;32m   1425\u001b[0m \u001b[38;5;66;03m# and remove next four lines, replace _dim with dim\u001b[39;00m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train(model, optimizer, scheduler, loss_function, epochs, \n",
    "              trainloader, device, clip_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ce4792d4-8a3b-4413-aef2-8c6ce3fa83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nval = [float(l) for l in loss[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e7c3dd6-a85f-4d18-b84c-4e9e968735d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([292., 161.,  12.,   2.,   6.,   5.,   9.,   8.,   4.,   1.]),\n",
       " array([0.05344863, 0.10210352, 0.15075841, 0.1994133 , 0.24806819,\n",
       "        0.29672308, 0.34537797, 0.39403286, 0.44268775, 0.49134264,\n",
       "        0.53999753]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(sloss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68853bf4-ea68-4eb3-ab3e-6a6c6608c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0028c47e-4fc8-4089-bf00-693ed030a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c97e6578-01b4-4ab4-87f0-69b68885ca16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  159.,  1468., 11332., 17375.,  2914.,  3905.,  6422., 14571.,\n",
       "        49381.,  2473.]),\n",
       " array([-2.37672544, -2.00800377, -1.63928211, -1.27056044, -0.90183878,\n",
       "        -0.53311712, -0.16439545,  0.20432621,  0.57304788,  0.94176954,\n",
       "         1.3104912 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(alldf['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b1d335-f94b-4fd5-bd69-7f86d9e7269c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
