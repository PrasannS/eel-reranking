{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dbdfd6d-d718-4eec-88b0-77789bf845d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "from rerank_score_cands_new import load_cands\n",
    "import numpy as np\n",
    "from comet import download_model, load_from_checkpoint\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "#from distill_comet import XLMCometRegressor\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)\n",
    "xlm_tok = AutoTokenizer.from_pretrained('xlm-roberta-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd4f3f2-85c7-452f-84f9-74205cb8627a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XLMCometRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self, drop_rate=0.1):\n",
    "        # TODO should we be freezing layers?\n",
    "        super().__init__()\n",
    "        \n",
    "        self.xlmroberta = AutoModel.from_pretrained('xlm-roberta-base')\n",
    "        # Num labels 1 should just indicate regression (?)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.xlmroberta.config.hidden_size, 1), \n",
    "        )\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        # don't finetune xlmroberta model\n",
    "        #with torch.no_grad():\n",
    "        word_rep, sentence_rep = self.xlmroberta(input_ids, attention_mask=attention_masks, encoder_attention_mask=attention_masks, return_dict=False)\n",
    "        # use the first <s> token as a CLS token, TODO experiment with using the sum of \n",
    "        # ensure padding not factored in\n",
    "        word_rep = word_rep*(input_ids>0).unsqueeze(-1)\n",
    "        outputs = self.regressor(torch.sum(word_rep, 1))\n",
    "        #print(\"Shape: \", outputs.shape)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959f8b23-872a-4e36-81f5-5ade199f12bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nothing is everything\n",
    "# 1 is with distilled data lattice + beam\n",
    "# 2 is with just beam data? \n",
    "# ordered is the clean ranking ready set\n",
    "def load_cometqe_data(ind):\n",
    "    with open('processeddata/orderedmasks.pkl', 'rb') as f:\n",
    "        masks = pickle.load(f)\n",
    "\n",
    "    with open('processeddata/orderedinps.pkl', 'rb') as f:\n",
    "        xinps = pickle.load(f)\n",
    "\n",
    "    with open('processeddata/orderedlabels.pkl', 'rb') as f:\n",
    "        yinps = pickle.load(f)\n",
    "    return masks, xinps, yinps\n",
    "\n",
    "mdata, xdata, ydata = load_cometqe_data(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24f07e35-1994-485e-ba44-c6fef5c57d87",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# train test split\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m cut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mxdata\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.9\u001b[39m)\u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(xdata)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m.9\u001b[39m)\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      3\u001b[0m xtrain, ytrain, mtrain \u001b[38;5;241m=\u001b[39m xdata[:cut], ydata[:cut], mdata[:cut]\n\u001b[1;32m      4\u001b[0m xtest, ytest, mtest \u001b[38;5;241m=\u001b[39m xdata[cut:], ydata[cut:], mdata[cut:]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xdata' is not defined"
     ]
    }
   ],
   "source": [
    "# train test split\n",
    "cut = int(len(xdata)*.9)- int(len(xdata)*.9)%32\n",
    "xtrain, ytrain, mtrain = xdata[:cut], ydata[:cut], mdata[:cut]\n",
    "xtest, ytest, mtest = xdata[cut:], ydata[cut:], mdata[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a419403-ff57-4583-9f69-ee14771f2f79",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mdata' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m mdata, xdata, ydata\n\u001b[1;32m      2\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mdata' is not defined"
     ]
    }
   ],
   "source": [
    "del mdata, xdata, ydata\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4729652-ffdb-4ce6-803c-15e17833f409",
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = torch.tensor(ytrain[:31]+[.8]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "987705a3-5c97-47a4-903c-e3d0583f5a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "145728"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "012d84f1-5654-45e1-8691-4af5ece2ed51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, masks):\n",
    "        assert len(sentences) == len(labels)\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.masks = masks\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences[i], self.labels[i], self.masks[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "def collate_custom(datafull):\n",
    "    #print(len(datafull[0]))\n",
    "    data = [torch.tensor(d[0]) for d in datafull]\n",
    "    masdata=  [d[2] for d in datafull]\n",
    "    labels = [d[1] for d in datafull]\n",
    "    max_len = max([x.squeeze().numel() for x in data])\n",
    "    data = [torch.nn.functional.pad(x, pad=(0, max_len - x.numel()), mode='constant', value=0) for x in data]\n",
    "    data = torch.stack(data).to(device)\n",
    "    # TODO just a normal mask for now\n",
    "    #masdata = [torch.ones_like(m) for m in masdata]\n",
    "    masdata = [torch.nn.functional.pad(x, pad=(0, max_len - x[0].numel(), 0, max_len - x[0].numel()), mode='constant', value=0) for x in masdata]\n",
    "    masdata = torch.stack(masdata).to(device)\n",
    "    return data, torch.tensor(labels).to(device), masdata\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a69ce8cc-6284-41a8-bef7-a3733e8e317f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xtest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m testloader \u001b[38;5;241m=\u001b[39m DataLoader(RegressionDataset(\u001b[43mxtest\u001b[49m, ytest, mtest), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_custom)\n\u001b[1;32m      2\u001b[0m trainloader \u001b[38;5;241m=\u001b[39m DataLoader(RegressionDataset(xtrain, ytrain, mtrain), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, collate_fn\u001b[38;5;241m=\u001b[39mcollate_custom)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xtest' is not defined"
     ]
    }
   ],
   "source": [
    "testloader = DataLoader(RegressionDataset(xtest, ytest, mtest), batch_size=32, shuffle=False, collate_fn=collate_custom)\n",
    "trainloader = DataLoader(RegressionDataset(xtrain, ytrain, mtrain), batch_size=32, shuffle=False, collate_fn=collate_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d91005-836e-415c-b943-a3b425e6b3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tinmax = 100000\n",
    "xtiny, ytiny, mtiny = xtrain[:tinmax], ytrain[:tinmax], mtrain[:tinmax]\n",
    "tinyloader = DataLoader(RegressionDataset(xtiny, ytiny, mtiny), batch_size=32, shuffle=True, collate_fn=collate_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daee20ab-5811-4500-abad-aa9eb20983ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfe13842-e550-4128-840f-09615ce82dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1a03299-cb46-4488-bbc4-2baafc36fd6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "def train(model, optimizer, scheduler, loss_function, epochs,       \n",
    "          train_dataloader, device, clip_value=2):\n",
    "    print(\"Total steps :\", epochs*len(train_dataloader))\n",
    "    best_loss = 1e10\n",
    "    for epoch in range(epochs):\n",
    "        if epoch%1==0:\n",
    "            print(\"EPOCH \", epoch)\n",
    "            print(\"-----\")\n",
    "            print(best_loss)\n",
    "        model.train()\n",
    "        cbest = 1e10\n",
    "        lostot = 0\n",
    "        loscnt = 0\n",
    "        for step, batch in enumerate(train_dataloader): \n",
    "            batch_inputs, batch_labels, batch_masks = \\\n",
    "                               tuple(b.to(device) for b in batch)\n",
    "            model.zero_grad()\n",
    "            outputs = model(batch_inputs, batch_masks)\n",
    "            loss = loss_function(outputs.squeeze(), \n",
    "                             batch_labels.squeeze())\n",
    "            lostot+=loss\n",
    "            loscnt+=1\n",
    "            if step%500==0:\n",
    "                #print(loss)  \n",
    "                if loscnt>0:\n",
    "                    print(lostot/loscnt)\n",
    "                    cbest = min(float(lostot/loscnt), cbest)\n",
    "                    best_loss = min(best_loss, cbest)\n",
    "                    print(\"cbest, \", cbest)\n",
    "            loss.backward()\n",
    "            clip_grad_norm_(model.parameters(), clip_value)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "        cbest = min(float(lostot/loscnt), cbest)\n",
    "        best_loss = min(best_loss, cbest)\n",
    "        print(\"cbest, \", cbest)\n",
    "        \n",
    "        torch.save(model.state_dict(), \"torchsaved/divlat\"+str(epoch)+\".pt\")\n",
    "    return model\n",
    "\n",
    "def evaluate(model, loss_function, tdataloader, device):\n",
    "    model.eval()\n",
    "    test_loss, test_r2 = [], []\n",
    "    preds = []\n",
    "    ind = 0\n",
    "    for batch in tdataloader:\n",
    "        if ind%100==0:\n",
    "            print(ind)\n",
    "        try:\n",
    "            batch_inputs, batch_labels,batch_masks = \\\n",
    "                                     tuple(b.to(device) for b in batch)\n",
    "            with torch.no_grad():\n",
    "                outputs = model(batch_inputs, batch_masks)\n",
    "            loss = loss_function(outputs.squeeze(), \n",
    "                                 batch_labels.squeeze())\n",
    "            preds.append(list(outputs.squeeze()))\n",
    "            test_loss.append(loss.item())\n",
    "            #r2 = r2_score(outputs, batch_labels)\n",
    "            #test_r2.append(r2.item())\n",
    "            if ind==10:\n",
    "                print(batch_labels)\n",
    "                print(outputs)\n",
    "            ind+=1\n",
    "        except:\n",
    "            preds.append([0.5]*32)\n",
    "            test_loss.append(0)\n",
    "            \n",
    "    return test_loss, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "61daad59-70ee-4804-86c3-61b7c68a9055",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model.state_dict(), \"torchsaved/maskedtestcomestimdone.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c13f0fd3-f0e5-4494-8ac0-a017ccb71618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = XLMCometRegressor(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/germanlat0.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b47870-ca7b-4f6c-915f-42e5d09332b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "218d3e10-6a44-4909-97c1-ddbf3ad796f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maskedcont1 has first round of optimizing loss\n",
    "# maskedcont2 more contrastive learning\n",
    "# maskedcont3 full on contrastive \n",
    "# torch.save(model.state_dict(), \"torchsaved/maskedcont4.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784319d1-d9ac-4524-9fc5-748f2d119255",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1918c74d-5efb-4a45-ba35-0fb4bb665fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmask = (torch.triu(torch.ones(32, 32))*2-torch.ones(32, 32))*-1\n",
    "vmask = vmask.to(device)\n",
    "mse = nn.MSELoss()\n",
    "def rank_loss(preds, golds):\n",
    "    totloss = 0\n",
    "    for i in range(1, len(preds)):\n",
    "        # for margin\n",
    "        margin = (golds - torch.roll(golds, i))*vmask[i]\n",
    "        diff = (preds - torch.roll(preds, i)-margin)*vmask[i]\n",
    "        diff[diff<0] = 0\n",
    "        totloss+=torch.sum(diff)\n",
    "    return totloss + mse(preds, golds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c9c5376b-786f-483d-9560-d8c3fd8006db",
   "metadata": {},
   "outputs": [],
   "source": [
    "vmask = (torch.triu(torch.ones(32, 32))*2-torch.ones(32, 32))*-1\n",
    "vmask = vmask.to(device)\n",
    "mse = nn.MSELoss()\n",
    "def nomarg_rank_loss(preds, golds):\n",
    "    totloss = 0\n",
    "    for i in range(1, len(preds)):\n",
    "        # for margin\n",
    "        # margin = (golds - torch.roll(golds, i))*vmask[i]\n",
    "        diff = (preds - torch.roll(preds, i))*vmask[i]\n",
    "        diff[diff<0] = 0\n",
    "        totloss+=torch.sum(diff)\n",
    "    return totloss + mse(preds, golds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d02e9c-2aed-4ab3-949b-45e56b64c3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model_train_params(learn_r, epochs, loader, mod):\n",
    "    optimizer = AdamW(mod.parameters(),\n",
    "                      lr=learn_r,\n",
    "                      eps=1e-8)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,       \n",
    "                     num_warmup_steps=0, num_training_steps=epochs*len(loader))\n",
    "    model = train(mod, optimizer, scheduler, rank_loss, epochs, \n",
    "                  loader, device, clip_value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c16f43a4-da47-478d-9872-f721771e4e95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total steps : 16516\n",
      "EPOCH  0\n",
      "-----\n",
      "10000000000.0\n",
      "tensor(26.8449, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "cbest,  26.84491729736328\n",
      "tensor(62.9235, device='cuda:1', grad_fn=<DivBackward0>)\n",
      "cbest,  26.84491729736328\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The expanded size of the tensor (553) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [32, 553].  Tensor sizes: [1, 514]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [53]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_model_train_params\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbigloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m run_model_train_params(\u001b[38;5;241m1e-5\u001b[39m, \u001b[38;5;241m10\u001b[39m, bigloader, model)\n\u001b[1;32m      3\u001b[0m run_model_train_params(\u001b[38;5;241m1e-6\u001b[39m, \u001b[38;5;241m20\u001b[39m, bigloader, model)\n",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36mrun_model_train_params\u001b[0;34m(learn_r, epochs, loader, mod)\u001b[0m\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m AdamW(mod\u001b[38;5;241m.\u001b[39mparameters(),\n\u001b[1;32m      3\u001b[0m                   lr\u001b[38;5;241m=\u001b[39mlearn_r,\n\u001b[1;32m      4\u001b[0m                   eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-8\u001b[39m)\n\u001b[1;32m      5\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m get_linear_schedule_with_warmup(optimizer,       \n\u001b[1;32m      6\u001b[0m                  num_warmup_steps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, num_training_steps\u001b[38;5;241m=\u001b[39mepochs\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mlen\u001b[39m(loader))\n\u001b[0;32m----> 7\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrank_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m              \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclip_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, scheduler, loss_function, epochs, train_dataloader, device, clip_value)\u001b[0m\n\u001b[1;32m     16\u001b[0m batch_inputs, batch_labels, batch_masks \u001b[38;5;241m=\u001b[39m \\\n\u001b[1;32m     17\u001b[0m                    \u001b[38;5;28mtuple\u001b[39m(b\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m batch)\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_masks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_function(outputs\u001b[38;5;241m.\u001b[39msqueeze(), \n\u001b[1;32m     21\u001b[0m                  batch_labels\u001b[38;5;241m.\u001b[39msqueeze())\n\u001b[1;32m     22\u001b[0m lostot\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mXLMCometRegressor.forward\u001b[0;34m(self, input_ids, attention_masks)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_ids, attention_masks):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# don't finetune xlmroberta model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m#with torch.no_grad():\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     word_rep, sentence_rep \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxlmroberta\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# use the first <s> token as a CLS token, TODO experiment with using the sum of \u001b[39;00m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# ensure padding not factored in\u001b[39;00m\n\u001b[1;32m     21\u001b[0m     word_rep \u001b[38;5;241m=\u001b[39m word_rep\u001b[38;5;241m*\u001b[39m(input_ids\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/roberta/modeling_roberta.py:809\u001b[0m, in \u001b[0;36mRobertaModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    808\u001b[0m     buffered_token_type_ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings\u001b[38;5;241m.\u001b[39mtoken_type_ids[:, :seq_length]\n\u001b[0;32m--> 809\u001b[0m     buffered_token_type_ids_expanded \u001b[38;5;241m=\u001b[39m \u001b[43mbuffered_token_type_ids\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_length\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    810\u001b[0m     token_type_ids \u001b[38;5;241m=\u001b[39m buffered_token_type_ids_expanded\n\u001b[1;32m    811\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The expanded size of the tensor (553) must match the existing size (514) at non-singleton dimension 1.  Target sizes: [32, 553].  Tensor sizes: [1, 514]"
     ]
    }
   ],
   "source": [
    "#run_model_train_params(1e-4, 2, bigloader, model)\n",
    "run_model_train_params(1e-5, 10, bigloader, model)\n",
    "run_model_train_params(1e-6, 20, bigloader, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0b8c02b8-def2-4017-a91f-aaec8eec261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ittest = iter(bigloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404c6094-5aab-42b5-9eb5-2f5a3ec50d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in trainloader:\n",
    "    #print(t[1])\n",
    "    assert t[1][-1] == max(t[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2cf629fb-072b-4326-8af1-ccec6f11bb9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del model \n",
    "model = XLMCometRegressor(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/maskedcont4.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "46c96ce7-5520-4b13-92bf-58a2de69a7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "loss = evaluate(model, rank_loss, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35907783-1f6f-4801-8ae5-d8e05bb80ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dede517-a94b-4e4e-a037-dac55a310ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abafa5-bf6a-45b4-b5c2-37d76474cadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sloss = [math.sqrt(l) for l in loss[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4792d4-8a3b-4413-aef2-8c6ce3fa83af",
   "metadata": {},
   "outputs": [],
   "source": [
    "nval = [float(l) for l in loss[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68853bf4-ea68-4eb3-ab3e-6a6c6608c3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mind = []\n",
    "for l in loss[1]:\n",
    "    mind+=[l.index(max(l))]\n",
    "\n",
    "sum(mind)/len(mind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0028c47e-4fc8-4089-bf00-693ed030a883",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97e6578-01b4-4ab4-87f0-69b68885ca16",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(alldf['scores'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "d1b1d335-f94b-4fd5-bd69-7f86d9e7269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# old data loading stuff\n",
    "\n",
    "# data comes from WMT 2019 [I think], TODO validate exact year being used\n",
    "# data generated with gold reference given as hyp\n",
    "#golddf = pd.read_csv('./processeddata/golddata.csv')\n",
    "#golddf['inp'] = golddf['fr']\n",
    "#golddf['hyp'] = golddf['en']\n",
    "# data generated on candidates from beam search 50 and lattice (lots of bad)\n",
    "distill_df = pd.read_csv('processeddata/cpfdata2.csv')\n",
    "# data generated between random / unrelated sentences \n",
    "#rand_df = pd.read_csv('distill_cometdata_rand.csv')[:30000]\n",
    "# combine\n",
    "alldf = distill_df#.append(rand_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "96e3ef86-e21e-4c81-950b-2666932380c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>score</th>\n",
       "      <th>comscores</th>\n",
       "      <th>posthoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as an investigative reporter in the...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>0.423756</td>\n",
       "      <td>0.001024</td>\n",
       "      <td>0.534086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a field investigative journalist...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>0.500724</td>\n",
       "      <td>0.187095</td>\n",
       "      <td>0.493034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as an investigative reporter in the...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>0.377539</td>\n",
       "      <td>0.009930</td>\n",
       "      <td>0.544490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a journalist investigating the c...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>0.240281</td>\n",
       "      <td>0.006175</td>\n",
       "      <td>0.509931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a journalist investigating in th...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>0.253478</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.760619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309135</th>\n",
       "      <td>309135</td>\n",
       "      <td>De grosses erreurs ont été commises qui ont en...</td>\n",
       "      <td>Large errors were committed which further fuel...</td>\n",
       "      <td>Big mistakes were made, fueling further violen...</td>\n",
       "      <td>0.798258</td>\n",
       "      <td>0.331076</td>\n",
       "      <td>0.684784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309136</th>\n",
       "      <td>309136</td>\n",
       "      <td>De grosses erreurs ont été commises qui ont en...</td>\n",
       "      <td>Major mistakes were made and the violence was ...</td>\n",
       "      <td>Big mistakes were made, fueling further violen...</td>\n",
       "      <td>0.803969</td>\n",
       "      <td>0.414651</td>\n",
       "      <td>0.797772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309137</th>\n",
       "      <td>309137</td>\n",
       "      <td>De grosses erreurs ont été commises qui ont en...</td>\n",
       "      <td>Big mistakes have been made and the violence c...</td>\n",
       "      <td>Big mistakes were made, fueling further violen...</td>\n",
       "      <td>0.747567</td>\n",
       "      <td>0.365663</td>\n",
       "      <td>0.942066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309138</th>\n",
       "      <td>309138</td>\n",
       "      <td>De grosses erreurs ont été commises qui ont en...</td>\n",
       "      <td>Big mistakes have been made and they have furt...</td>\n",
       "      <td>Big mistakes were made, fueling further violen...</td>\n",
       "      <td>0.864925</td>\n",
       "      <td>0.487513</td>\n",
       "      <td>0.732962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309139</th>\n",
       "      <td>309139</td>\n",
       "      <td>De grosses erreurs ont été commises qui ont en...</td>\n",
       "      <td>Big mistakes were made, fueling further violen...</td>\n",
       "      <td>Big mistakes were made, fueling further violen...</td>\n",
       "      <td>1.137886</td>\n",
       "      <td>0.431999</td>\n",
       "      <td>1.575130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>309140 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                                                src  \\\n",
       "0                0  Après tout, en tant que journaliste d'investig...   \n",
       "1                1  Après tout, en tant que journaliste d'investig...   \n",
       "2                2  Après tout, en tant que journaliste d'investig...   \n",
       "3                3  Après tout, en tant que journaliste d'investig...   \n",
       "4                4  Après tout, en tant que journaliste d'investig...   \n",
       "...            ...                                                ...   \n",
       "309135      309135  De grosses erreurs ont été commises qui ont en...   \n",
       "309136      309136  De grosses erreurs ont été commises qui ont en...   \n",
       "309137      309137  De grosses erreurs ont été commises qui ont en...   \n",
       "309138      309138  De grosses erreurs ont été commises qui ont en...   \n",
       "309139      309139  De grosses erreurs ont été commises qui ont en...   \n",
       "\n",
       "                                                      hyp  \\\n",
       "0       After all, as an investigative reporter in the...   \n",
       "1       After all, as a field investigative journalist...   \n",
       "2       After all, as an investigative reporter in the...   \n",
       "3       After all, as a journalist investigating the c...   \n",
       "4       After all, as a journalist investigating in th...   \n",
       "...                                                   ...   \n",
       "309135  Large errors were committed which further fuel...   \n",
       "309136  Major mistakes were made and the violence was ...   \n",
       "309137  Big mistakes have been made and the violence c...   \n",
       "309138  Big mistakes have been made and they have furt...   \n",
       "309139  Big mistakes were made, fueling further violen...   \n",
       "\n",
       "                                                      ref     score  \\\n",
       "0       After all, as a campaigning investigative jour...  0.423756   \n",
       "1       After all, as a campaigning investigative jour...  0.500724   \n",
       "2       After all, as a campaigning investigative jour...  0.377539   \n",
       "3       After all, as a campaigning investigative jour...  0.240281   \n",
       "4       After all, as a campaigning investigative jour...  0.253478   \n",
       "...                                                   ...       ...   \n",
       "309135  Big mistakes were made, fueling further violen...  0.798258   \n",
       "309136  Big mistakes were made, fueling further violen...  0.803969   \n",
       "309137  Big mistakes were made, fueling further violen...  0.747567   \n",
       "309138  Big mistakes were made, fueling further violen...  0.864925   \n",
       "309139  Big mistakes were made, fueling further violen...  1.137886   \n",
       "\n",
       "        comscores   posthoc  \n",
       "0        0.001024  0.534086  \n",
       "1        0.187095  0.493034  \n",
       "2        0.009930  0.544490  \n",
       "3        0.006175  0.509931  \n",
       "4        0.000042  0.760619  \n",
       "...           ...       ...  \n",
       "309135   0.331076  0.684784  \n",
       "309136   0.414651  0.797772  \n",
       "309137   0.365663  0.942066  \n",
       "309138   0.487513  0.732962  \n",
       "309139   0.431999  1.575130  \n",
       "\n",
       "[309140 rows x 7 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alldf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe10bb4a-76b0-4ffd-af5d-7ad859d86a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted3 = alldf.sort_values(['ref', 'score']).reset_index().drop(columns=['index', 'Unnamed: 0'])\n",
    "sorted3 = sorted3[sorted3[\"src\"].str.contains(\"&#\")==False]\n",
    "sorted3 = sorted3[sorted3['src'].str.len()>40]\n",
    "sorted3 = sorted3[sorted3['ref'].str.len()>40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "13043736-015b-4143-a38a-6d4876d63f0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>score</th>\n",
       "      <th>comscores</th>\n",
       "      <th>posthoc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>« La médecine clinique est-elle corrompue ? » ...</td>\n",
       "      <td>\"Is clinical medicine corrupt?\" asked an edito...</td>\n",
       "      <td>\"Just how tainted has clinical medicine become...</td>\n",
       "      <td>0.104513</td>\n",
       "      <td>0.290672</td>\n",
       "      <td>0.564603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>« La médecine clinique est-elle corrompue ? » ...</td>\n",
       "      <td>\"Is clinical medicine corrupt?\" asked an edito...</td>\n",
       "      <td>\"Just how tainted has clinical medicine become...</td>\n",
       "      <td>0.152255</td>\n",
       "      <td>0.299467</td>\n",
       "      <td>0.566226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>« La médecine clinique est-elle corrompue ? » ...</td>\n",
       "      <td>\"Is clinical medicine corrupt?\" an editorial i...</td>\n",
       "      <td>\"Just how tainted has clinical medicine become...</td>\n",
       "      <td>0.178602</td>\n",
       "      <td>0.273248</td>\n",
       "      <td>0.531792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>« La médecine clinique est-elle corrompue ? » ...</td>\n",
       "      <td>\"Is clinical medicine corrupt?\" asked an edito...</td>\n",
       "      <td>\"Just how tainted has clinical medicine become...</td>\n",
       "      <td>0.183225</td>\n",
       "      <td>0.298458</td>\n",
       "      <td>0.597017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 src  \\\n",
       "0  « La médecine clinique est-elle corrompue ? » ...   \n",
       "1  « La médecine clinique est-elle corrompue ? » ...   \n",
       "2  « La médecine clinique est-elle corrompue ? » ...   \n",
       "3  « La médecine clinique est-elle corrompue ? » ...   \n",
       "\n",
       "                                                 hyp  \\\n",
       "0  \"Is clinical medicine corrupt?\" asked an edito...   \n",
       "1  \"Is clinical medicine corrupt?\" asked an edito...   \n",
       "2  \"Is clinical medicine corrupt?\" an editorial i...   \n",
       "3  \"Is clinical medicine corrupt?\" asked an edito...   \n",
       "\n",
       "                                                 ref     score  comscores  \\\n",
       "0  \"Just how tainted has clinical medicine become...  0.104513   0.290672   \n",
       "1  \"Just how tainted has clinical medicine become...  0.152255   0.299467   \n",
       "2  \"Just how tainted has clinical medicine become...  0.178602   0.273248   \n",
       "3  \"Just how tainted has clinical medicine become...  0.183225   0.298458   \n",
       "\n",
       "    posthoc  \n",
       "0  0.564603  \n",
       "1  0.566226  \n",
       "2  0.531792  \n",
       "3  0.597017  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted3.to_csv(\"processeddata/cpfdata0\")\n",
    "stind = 9\n",
    "sorted3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8e382e31-5a97-4bbb-9944-030b227d6450",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted3['weighted'] = (-1.25)*sorted3['posthoc']+(0.9)*sorted3['comscores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9b2f4f26-6305-4f95-a617-513f80cc2930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# go through dataframe, get sets of size BATCH that are ranked by score\n",
    "dlists = []\n",
    "prevs = sorted3['src'].iloc[0]\n",
    "sofar = []\n",
    "for index, row in sorted3.iterrows():\n",
    "    if row['src']==prevs:\n",
    "        sofar.append(row)\n",
    "    else:\n",
    "        dlists.append(sofar)\n",
    "        sofar = []\n",
    "        prevs = row['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "14e7897b-f48d-4919-8c01-6eefa2c439d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4587"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dlists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "21ba8908-c845-4912-b923-2d485dc29fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the last 90% as set to work with\n",
    "dls = dlists[:int(len(dlists)/10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "63874e51-fe5a-4ca1-9e84-d5b8ce20d1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "allvals = []\n",
    "for d in dls:\n",
    "    allvals.extend(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1ca10ad6-ac72-4443-b2a3-d7e41d44fb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0990b05-3a04-49d7-bd0f-9a771a947a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = 32\n",
    "# sample from stuff, 32 at a time\n",
    "def get_samples(dlist, best, batch):\n",
    "    nbatches = int(len(dlist)/batch)+1\n",
    "    res = []\n",
    "    for i in range(nbatches):\n",
    "        print(len(dlist))\n",
    "        # get a random sorted sample, make sure best is in each batch\n",
    "        indices = random.sample(range(len(dlist)), batch-1)\n",
    "        res.append([dlist[i] for i in sorted(indices)]+[best])\n",
    "    return res\n",
    "\n",
    "def all_samples(dls, batch):\n",
    "    done = []\n",
    "    for d in dls:\n",
    "        done.extend(get_samples(d[:-1], d[-1], batch))\n",
    "    return done\n",
    "\n",
    "asamps = all_samples(dls, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8a10d548-b10a-4dee-81f1-9a1e566260f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(asamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98760b9f-95a4-4523-a063-83e96237a0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = []\n",
    "for a in asamps:\n",
    "    done.extend(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0a161adb-f536-4d9d-a683-3dc8b8efca7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = pd.DataFrame(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "b6162d52-44f2-4f79-9fe6-22e0c7b4338c",
   "metadata": {},
   "outputs": [],
   "source": [
    "done = done.reset_index().drop(columns= ['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a4b68d5c-3664-4105-af4c-929c771e09e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "src          But that seems unlikely: since the Democrats’ ...\n",
       "hyp          Aber das scheint unwahrscheinlich: Seit der gr...\n",
       "ref          Aber das scheint unwahrscheinlich: Seit der gr...\n",
       "score                                                 0.835206\n",
       "comscores                                             0.560319\n",
       "posthoc                                                5.20967\n",
       "weighted                                               -6.0078\n",
       "Name: 63, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done.loc[31+32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e7f350f2-6407-464a-ad05-4d71433f4c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXTOKS =512\n",
    "# construct inputs from dataframe\n",
    "def get_inputs(inpdf):\n",
    "    xinp = []\n",
    "    yinp = []\n",
    "    maskinp = []\n",
    "    \n",
    "    for index, row in inpdf.iterrows():\n",
    "        if index%1000==0:\n",
    "            print(index)\n",
    "        #print(row['c1'], row['c2'])\n",
    "        # will need to make a custom mask (maybe) so that inputs from both languages are encoded separately\n",
    "        toktmp = xlm_tok(row['src']).input_ids\n",
    "        lent = len(toktmp)\n",
    "        hyptmp = xlm_tok(row['hyp']).input_ids\n",
    "        toktmp.extend(hyptmp)\n",
    "        tlen = min(len(toktmp), MAXTOKS)\n",
    "        toktmp = toktmp[:tlen]\n",
    "        mask = torch.ones(tlen, tlen)\n",
    "        # should set upper left and bottom right quadrants to 1, mask other stuff\n",
    "        # TODO make different types of masks. \n",
    "        # make causal encoder-decoder mask\n",
    "        mask[:lent, lent:] = 0\n",
    "        mask[lent:, lent:] = torch.tril(mask[lent:, lent:])\n",
    "        xinp.append(toktmp)\n",
    "        maskinp.append(mask)\n",
    "        yinp.append(row['score'])\n",
    "    return xinp, yinp, maskinp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "36fa1228-da1f-4d64-8058-1c9c27abcdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (789 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "12000\n",
      "13000\n",
      "14000\n",
      "15000\n",
      "16000\n",
      "17000\n",
      "18000\n",
      "19000\n",
      "20000\n",
      "21000\n",
      "22000\n",
      "23000\n",
      "24000\n",
      "25000\n",
      "26000\n",
      "27000\n",
      "28000\n",
      "29000\n"
     ]
    }
   ],
   "source": [
    "xdata, ydata, mdata = get_inputs(done)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4f1b777a-2c47-4853-b65e-a27602e67567",
   "metadata": {},
   "outputs": [],
   "source": [
    "bigloader = DataLoader(RegressionDataset(xdata, ydata, mdata), batch_size=32, shuffle=False, collate_fn=collate_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fd7bf22f-646d-484f-9c71-b090beba71ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "iterbig = iter(bigloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba600370-c398-4b20-ad8a-ad747b7b2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "inext = iterbig.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2b5dec7-4f06-42e0-94ad-384b04ffb992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> Après tout, les taux d’intérêt en Europe du Sud dépassaient largement les 10 % au cours de la décennie précédant l’introduction de l’euro.</s><s> After all, interest rates in southern Europe far exceeded 10% in the decade leading up to the euro.</s><s><s><s><s><s>'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlm_tok.decode(inext[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9b170d24-f7cc-4fef-b250-c72877fc86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "srcs = list(set(done['src']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "168766bd-3b6c-4ac9-aadf-5711f2afab52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1042"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ea42a977-db7c-485f-8ab3-ff03eaa55e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatten_lattice as fl\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b92f64da-92f9-4b03-990a-23b37a72530c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3027"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir(fren))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "78cc5ba9-1512-482b-ace6-9cd1fda0d211",
   "metadata": {},
   "outputs": [],
   "source": [
    "done.to_csv(\"french_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a9e4ff73-92db-4a8e-bbb9-25da8fddd9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ende = \"custom_output/data/mt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.904_0.0_0.9/\"\n",
    "fren = \"custom_output/data/mtn1_fr-en_bfs_recom_4_-1_False_0.4_True_False_4_5_rcb_0.903_0.0_0.9/\"\n",
    "def lattice_test_names(folder, srcnames):\n",
    "    for name in os.listdir(folder):\n",
    "        g = pickle.load(open(folder+name))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b67b30c3-5acc-4c1c-9d2b-8f178ef1d538",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11577"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = os.listdir(\"custom_output/data/mt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.904_0.0_0.9\")\n",
    "len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2608422-b5eb-4dcb-b2d8-e27ccc1783a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'custom_output/data/mt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.904_0.0_0.9/mt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.904_0.0_0.9_305_But-it-is-.pkl'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ende+os.listdir(ende)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6634941a-6ac6-4960-b84c-3727a5aa1cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-exploded EXPLODED] [-device DEVICE]\n",
      "                             [-model {dbs,bs,greedy,topp,temp,bs_recom,sample_recom,bfs,bfs_recom}]\n",
      "                             [-beam_size BEAM_SIZE] [-nexample NEXAMPLE]\n",
      "                             [-task {sum,mt1n,mtn1,custom}] [-dataset DATASET]\n",
      "                             [-hf_model_name HF_MODEL_NAME]\n",
      "                             [-path_output PATH_OUTPUT] [-top_p TOP_P]\n",
      "                             [-temp TEMP] [-beam_group BEAM_GROUP]\n",
      "                             [-hamming_penalty HAMMING_PENALTY]\n",
      "                             [-extra_steps EXTRA_STEPS] [-min_len MIN_LEN]\n",
      "                             [-max_len MAX_LEN]\n",
      "                             [-num_beam_hyps_to_keep NUM_BEAM_HYPS_TO_KEEP]\n",
      "                             [-ngram_suffix NGRAM_SUFFIX] [-len_diff LEN_DIFF]\n",
      "                             [-k_best K_BEST] [-avg_score AVG_SCORE]\n",
      "                             [-use_heu [USE_HEU]] [-post [POST]]\n",
      "                             [-dfs_expand [DFS_EXPAND]]\n",
      "                             [-post_ratio POST_RATIO]\n",
      "                             [-heu_seq_score HEU_SEQ_SCORE]\n",
      "                             [-heu_seq_score_len_rwd HEU_SEQ_SCORE_LEN_RWD]\n",
      "                             [-heu_pos HEU_POS] [-heu_ent HEU_ENT]\n",
      "                             [-heu_word HEU_WORD] [-merge {zip,rcb,none}]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/prasann/.local/share/jupyter/runtime/kernel-c7da4496-5b5d-4dd0-a419-b551d1cc1c91.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "g = pickle.load(open(ende+os.listdir(ende)[0], 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6c2a00cc-0e95-4166-b7a1-63a69e3f72fe",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [77]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mg\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'g' is not defined"
     ]
    }
   ],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b6bc26b-230b-44b7-ace6-d7ef7ddacf35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "loss = evaluate(model, nomarg_rank_loss, bigloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d83e3f92-ad26-4ef9-9131-8f006bb3b70f",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "de863d80-86aa-4da2-95aa-b730e01064a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d85322e1-18d0-4d58-9614-d069287a304d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"testpreds.pkl\", \"wb\") as f:\n",
    "    pickle.dump(loss, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cc262d23-e982-4b2b-b93a-04e165c897d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "allpreds = []\n",
    "for l in loss[1]:\n",
    "    allpreds.extend(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "909127a7-f053-4305-a935-c32571b5fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "avals = [a['score'] for a in allvals]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "79e3ff18-e2c7-4e9f-9206-bcb30975ab6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = [len(d) for d in asamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b6d95520-0c1d-4c34-bf93-919446a7b78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "avsplit = []\n",
    "apsplit = []\n",
    "cur = 0\n",
    "for l in lens:\n",
    "    avsplit.append(avals[cur:cur+l])\n",
    "    apsplit.append(allpreds[cur:cur+l])\n",
    "    cur = cur+l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d56fdfba-1bdc-46a5-905b-65cf3526dbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "516e0438-afab-420b-92ca-7a8da7601e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpsamps = [a[:-1] for a in asamps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "351165f3-41ab-4607-9fa8-17c420b85647",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmpsamps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b8c918-4542-46ec-bc15-accd0ef97027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get stuff using our lattice encoding pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff4f4db1-bd6b-4476-a5b4-1b6ee40191c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_by_metric(metr, samps, ifmax):\n",
    "    mlist = [float(f[metr]) for f in samps]\n",
    "    if ifmax:\n",
    "        index_max = np.argmax(mlist) \n",
    "    else:\n",
    "        index_max = np.argmin(mlist) \n",
    "    return samps[int(index_max)]['score']\n",
    "\n",
    "def update_values(sampstuff):\n",
    "    tot = 0\n",
    "    mval = 0 \n",
    "    cnt = 0\n",
    "    pred_dist = []\n",
    "    gold_dist = []\n",
    "    com_dist = []\n",
    "    ph_dist = []\n",
    "    weight_dist = []\n",
    "    ourweight_dist = []\n",
    "    for i in range(0, len(sampstuff)):\n",
    "        index_max = np.argmax([float(f) for f in loss[1][i][:len(sampstuff[i])]])\n",
    "        pred_dist.append(sampstuff[i][int(index_max)]['score'])\n",
    "        tmpw = [float(loss[1][i][j])*0.9+sampstuff[i][j]['posthoc']*(-.5) for j in range(len(sampstuff[i]))]\n",
    "        index_max = np.argmax(tmpw)\n",
    "        ourweight_dist.append(sampstuff[i][int(index_max)]['score'])\n",
    "        tot+=pred_dist[-1]\n",
    "        m = -5\n",
    "        for val in sampstuff[i]:\n",
    "            m = max(m, val['score'])\n",
    "        com_dist.append(max_by_metric('comscores', sampstuff[i], True))\n",
    "        ph_dist.append(max_by_metric('posthoc', sampstuff[i], False))\n",
    "        weight_dist.append(max_by_metric('weighted', sampstuff[i], True))\n",
    "        gold_dist.append(m)\n",
    "        mval+=m\n",
    "        cnt+=1\n",
    "    print(\"Our model \", tot/cnt)\n",
    "    print(\"Gold \", mval/cnt)\n",
    "    print(\"Just COMET\", sum(weight_dist)/len(weight_dist))\n",
    "    print(\"Just post-hoc\", sum(ph_dist)/len(ph_dist))\n",
    "    print(\"Weighted COMET+post-hoc\", sum(com_dist)/len(com_dist))\n",
    "    print(\"Our weighted \", sum(ourweight_dist)/len(ourweight_dist))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "9815071a-ca86-4ae4-93fb-ed0f57d8b22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our model  0.3314042544963317\n",
      "Gold  0.6495842319274538\n",
      "Just COMET 0.47004136759891085\n",
      "Just post-hoc 0.40897692126340734\n",
      "Weighted COMET+post-hoc 0.5748562992975639\n",
      "Our weighted  0.40923807891120173\n"
     ]
    }
   ],
   "source": [
    "update_values(tmpsamps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "573f4f98-b09b-454e-90f9-bea625be0899",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for lo in loss[1]:\n",
    "    for l in lo:\n",
    "        res.append(float(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a3b1a894-61cc-4e77-becc-da8270b15e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([6.0840e+03, 1.3725e+04, 9.4040e+03, 3.7160e+03, 1.3470e+03,\n",
       "        2.5100e+02, 6.4000e+01, 1.5000e+01, 1.5000e+01, 3.0000e+00]),\n",
       " array([0.44550452, 0.44874629, 0.45198807, 0.45522984, 0.45847161,\n",
       "        0.46171339, 0.46495516, 0.46819694, 0.47143871, 0.47468049,\n",
       "        0.47792226]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6168353-74ea-4124-9397-149c5795e223",
   "metadata": {},
   "outputs": [],
   "source": [
    "for alist in tmpsamps:\n",
    "    for a in alist:\n",
    "        a['weighted'] = (-1.25)*a['posthoc']+(1)*a['comscores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "54573a82-5c9e-4e8e-bdc5-a010052fc6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorted3['weighted'] = (-1.25)*sorted3['posthoc']+(.9)*sorted3['comscores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f34c8540-4c73-4507-9614-aa50feb76ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6869075171600706"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(weight_dist)/len(weight_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "27cde108-4a12-4916-ad22-e3bcd5efc36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f311a85efd0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(gold_dist, pred_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4c5d7f7d-bf14-4875-86cf-871bcfe4b61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  2.,   1.,   7.,   9.,  15.,  55.,  60., 332., 305., 131.]),\n",
       " array([-0.92208248, -0.70902837, -0.49597425, -0.28292014, -0.06986603,\n",
       "         0.14318809,  0.3562422 ,  0.56929632,  0.78235043,  0.99540455,\n",
       "         1.20845866]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(pred_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "edc77acf-5423-4c58-a3a7-f6a31faba388",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 14.,  42., 110., 163., 180., 190., 116.,  54.,  36.,  12.]),\n",
       " array([0.85879219, 0.89463915, 0.93048611, 0.96633307, 1.00218003,\n",
       "        1.03802699, 1.07387395, 1.10972091, 1.14556787, 1.18141483,\n",
       "        1.21726179]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(gold_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ca69c1e3-012b-442c-a3a6-f3b54127e723",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2281265/1805698635.py:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  apdistr.append(vtmp[int(torch.argmax(torch.tensor(ptmp)))])\n",
      "/tmp/ipykernel_2281265/1805698635.py:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  avdistr.append(vtmp[int(torch.argmax(torch.tensor(vtmp)))])\n"
     ]
    }
   ],
   "source": [
    "def get_top_avgs():\n",
    "    avdistr = []\n",
    "    apdistr = []\n",
    "    for i in range(len(avsplit)):\n",
    "        try:\n",
    "            vtmp = torch.tensor(avsplit[i])\n",
    "            ptmp = torch.tensor(apsplit[i])\n",
    "            if vtmp[-1]<0.5:\n",
    "                continue\n",
    "            #print(ptmp)\n",
    "            apdistr.append(vtmp[int(torch.argmax(torch.tensor(ptmp)))])\n",
    "            avdistr.append(vtmp[int(torch.argmax(torch.tensor(vtmp)))])\n",
    "        except:\n",
    "            print(\"something wrong\")\n",
    "            print(i)\n",
    "    return avdistr, apdistr\n",
    "\n",
    "av_distr, ap_distr = get_top_avgs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f68c158-90e4-40df-a074-73db624d3184",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8024)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(ap_distr)/len(ap_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "15d43eac-1081-48f7-9b0b-31a26a7c94b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8291)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(av_distr)/len(ap_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2dbad7f4-d609-45fb-9888-c28bd2d5d523",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e5f84622-0d4a-41fa-a9e6-588d549df8c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  4.,  6., 13., 15.,  3.,  5.,  1.,  0.,  1.]),\n",
       " array([0.49793291, 0.57491657, 0.65190022, 0.72888387, 0.80586753,\n",
       "        0.88285118, 0.95983484, 1.03681849, 1.11380215, 1.1907858 ,\n",
       "        1.26776946]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([float(f) for f in ap_distr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "0bd700a2-73c1-47e0-be3d-d9c70c8ef0d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9036)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(av_distr) / len(ap_distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a454d341-5855-4c85-974d-dfac7428efbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2., 4., 0., 4., 1., 1., 0., 1., 1., 1.]),\n",
       " array([0.73842299, 0.78217971, 0.82593644, 0.86969316, 0.91344988,\n",
       "        0.95720661, 1.00096333, 1.04472005, 1.08847678, 1.1322335 ,\n",
       "        1.17599022]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([float(f) for f in av_distr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2333ab69-47f1-4840-a4f9-758f167bcd7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, len(xdata)):\n",
    "    if len(xdata[i])>500:\n",
    "        del xdata[i]\n",
    "        del ydata[i]\n",
    "        del mdata[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d840b719-e6fd-4818-afa6-10b3dbd9c53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all as precaution\n",
    "def save_cometqe_data(md, xd, yd):\n",
    "    # save data into a pickle file\n",
    "    with open('processeddata/germanlatmasks.pkl', 'wb') as f:\n",
    "        pickle.dump(md, f)\n",
    "\n",
    "    with open('processeddata/germanlatinps.pkl', 'wb') as f:\n",
    "        pickle.dump(xd, f)\n",
    "\n",
    "    with open('processeddata/germanlatlabels.pkl', 'wb') as f:\n",
    "        pickle.dump(yd, f)\n",
    "        \n",
    "#mdata, xdata, ydata = load_cometqe_data()\n",
    "        \n",
    "save_cometqe_data(mdata, xdata, ydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9bcd62a3-6a2d-463d-b89e-3379adcfe921",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "fren = './rerank_outputs/post1explodedmtn1_fr-en_bfs_recom_4_-1_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9.json'\n",
    "ende = './rerank_outputs/post1explodedmt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9.json'\n",
    "# Opening JSON file\n",
    "with open(fren) as json_file:\n",
    "    lat4 = json.load(json_file)['data']\n",
    "    \n",
    "# was post1cpybeam4fr_en\n",
    "with open('./rerank_outputs/post2post1beam49fr_en.json') as json_file:\n",
    "    beam49 = json.load(json_file)['data']\n",
    "    \n",
    "def json_to_df(inputs):\n",
    "    res = []\n",
    "    for inp in inputs:\n",
    "        tlist = []\n",
    "        for i in range(len(inp['cands'])):\n",
    "            tmp = {}\n",
    "            tmp['src'] = inp['src']\n",
    "            tmp['ref'] = inp['ref']\n",
    "            tmp['hyp'] = inp['cands'][i]\n",
    "            tmp['scores'] = inp['cometscores'][i]\n",
    "            tlist.append(tmp)\n",
    "        res.append(tlist)\n",
    "    return res\n",
    "\n",
    "dlists = json_to_df(lat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aef4635-96bf-460c-934c-51fcae180201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('latenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
