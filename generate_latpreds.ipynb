{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2ead7b8-bddb-4f7e-8e57-053d17491265",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 12:31:55.450882: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-27 12:31:55.450904: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from encode_utils.new_mask_utils import randomsingle, useall\n",
    "from encode_utils.eval_utils import all_lattice_multi, mean, all_unnoun_multi\n",
    "from generate_tables import metrics_mapping\n",
    "from encode_utils.rerank_data import rerank_df, rerank_single, rerank_rand, rerank_weighted\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "500ae169-1de3-48b0-8b1b-6d2c57a09dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run pipeline for generating lattice preds, using different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cd21ecef-5b03-42de-ab2c-2261b4e5e9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up information for set\n",
    "col = {\n",
    "    \"noun_xsum\": [\"nounsum_reversed/\", \"nounxsumlargeexplodev2.csv\"],\n",
    "    \"noun_fren\": [\"frtest_reversed/\", \"nounlargeexplodev1.csv\"],\n",
    "    \"mt_fren\": [\"frtest_reversed/\", \"frenchlargeexplodev1.csv\"],\n",
    "    \"mt_ende\": [\"detest_reversed/\", \"germanlargeexplodev1.csv\"],\n",
    "    \"mt_enru\": [\"rutest_reversed/\", \"russianlargeexplodev1.csv\"],\n",
    "    \"mt_fren_b12\": ['reversed_mtfren_beam12/', 'mtfrenbeam12v2.csv'],\n",
    "    \"mt_fren_b50\": ['reversed_mtfren_beam50/', 'mtfrenbeam50v2.csv'],\n",
    "    \"noun_xsum_b12\": ['reversed_xsum_beam12/', 'nounxsumbeam12v2.csv'],\n",
    "    \"noun_xsum_b50\": ['reversed_xsum_beam50/', 'nounxsumbeam50v2.csv'],\n",
    "}\n",
    "curcol = \"mt_fren_b50\"\n",
    "gsuffix = col[curcol][0]\n",
    "expl_fname = col[curcol][1]\n",
    "base = \"outputs/graph_pickles/\"+gsuffix\n",
    "goldmetric = \"dupcqe\"\n",
    "explode_df = pd.read_csv(\"outputs/score_csvs/\"+expl_fname)\n",
    "#TODO switch back for french-english\n",
    "if \"fren\" in curcol:\n",
    "    SETLEN = len(os.listdir(base))\n",
    "else:\n",
    "    SETLEN = int(len(os.listdir(base))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d32d0661-9622-4e0a-a273-8ff869fd9103",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_43/checkpoints/epoch=3-step=130000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# use noun model\n",
    "if \"noun\" in expl_fname:\n",
    "    encodemod = get_effrerank_model(\"noun\")\n",
    "# use mt model (causal)\n",
    "else:\n",
    "    encodemod = get_effrerank_model(\"comstyle\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15280f8f-e8c8-4a75-b58d-0def378d295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETLEN = len(os.listdir(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b93a1eb-f91b-49eb-bd3c-39cfdbf4b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'setlen':int(SETLEN),\n",
    "    'tok':xlm_tok, \n",
    "    'dev':device,\n",
    "    'model':encodemod,\n",
    "    'explode_df':explode_df,\n",
    "    'base':base,\n",
    "    'goldmetric':goldmetric,\n",
    "    'device':device, \n",
    "    'efficient':False,\n",
    "    'noregen':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8d02192-1e2c-49cd-8a54-fc3d157022b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448   448   tensor(0.7896, device='cuda:2', grad_fn=<SumBackward0>)   tensor(0.8043, device='cuda:2', grad_fn=<SumBackward0>)  \n",
      "449   449   tensor(0.7688, device='cuda:2', grad_fn=<SumBackward0>)   tensor(0.7780, device='cuda:2', grad_fn=<SumBackward0>)  \n",
      "450   450   tensor(0.7494, device='cuda:2', grad_fn=<SumBackward0>)   tensor(0.7494, device='cuda:2', grad_fn=<SumBackward0>)  \n",
      "451   451   tensor(0.7364, device='cuda:2', grad_fn=<SumBackward0>)   tensor(0.7307, device='cuda:2', grad_fn=<SumBackward0>)  \n",
      "452   452   tensor(0.8575, device='cuda:2', grad_fn=<SumBackward0>)   tensor(0.8493, device='cuda:2', grad_fn=<SumBackward0>)  \n"
     ]
    }
   ],
   "source": [
    "latpreds = all_lattice_multi(1, weightaddprob , randomsingle, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3714fea9-2d68-498e-b3f9-c8381feb0f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pickle.load(open(base+str(0), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cba1ab1d-ef24-4385-8ac4-eb12e55d39c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist[1].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61dd50b-1e50-4894-8c8d-304df81f215b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14368c2e-c4fd-4891-bcbf-bfdb23bd8d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.2108125"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(explode_df)/1000)/(5*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4158653d-2784-4932-ab31-8eba6e800ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "latpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "24e44b80-adb6-44c3-b0b8-d9163f183838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7406, device='cuda:2', grad_fn=<DivBackward0>)\n",
      "tensor(0.7250, device='cuda:2', grad_fn=<DivBackward0>)\n",
      "tensor(0.0157, device='cuda:2', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(mean(latpreds['goldsco']))\n",
    "print(mean(latpreds['hypsco']))\n",
    "print(mean(latpreds['goldsco'])-mean(latpreds['hypsco']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f78779f-75c3-4b7a-8eb6-9d63c501c072",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wmt20-comet-da is already in cache.\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Predicting DataLoader 0: 100%|████████████████████████████████████████████████████████████████████████████████████| 15/15 [00:04<00:00,  3.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOK TIME  8.24\n"
     ]
    }
   ],
   "source": [
    "metrics_mapping(\"comet\", lpredstmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3915a4e7-4384-44ee-ac9a-c040fc448540",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6508571936298679"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(lpredstmp['comet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ecc9f05c-033e-4768-a301-2d2622610ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpredstmp = pd.read_csv(\"outputs/predcsvs/noun_comstyle_xsum_randsing_8shot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9d30218b-32cb-40c2-a773-808b04c9dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "luns = latpreds['ref'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e4667188-e792-4295-afbb-81a5d4fda085",
   "metadata": {},
   "outputs": [],
   "source": [
    "edf = explode_df[explode_df['ref'].isin(luns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fb543b-633f-4cda-b3f9-1c5225295e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "olatpreds = pd.read_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90d8aef7-3347-44d9-9e08-28b1c2dfcede",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7609684539601108"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_df(explode_df, rerank_single, ['comet', 'comet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "00220418-7f13-4b63-b167-7bd7b204742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = list(latpreds['hypsco'])\n",
    "hs = list(latpreds['goldsco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c714a8e0-554d-49b8-9555-845fc8a13f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7450, device='cuda:2', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean([max(gs[i], hs[i]) for i in range(len(latpreds))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5215d9f2-39da-4df8-838b-0671342dc33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb186146-fff1-4396-b538-d4566f116a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfile = \"mt_fren_eelb501shotweighted.csv\"\n",
    "latpreds.to_csv(\"outputs/predcsvs/\"+outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4f965c6-9e6f-4bcd-8ae2-f403accbca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "lpredstmp = pd.read_csv(\"outputs/predcsvs/\"+\"mt_fren_eelb501shotweighted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848bee65-7943-44f2-9350-1a8d04f97d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e959e55-264c-4c30-88e2-836bd2254477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "tensor(0.6634, device='cuda:2', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "phoc = all_unnoun_multi(1, \"dupcqe\", args)\n",
    "print(mean(phoc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebd7e64-a228-40fe-980d-e680fddb4e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "args['noregen'] = True\n",
    "args['setlen'] = 100\n",
    "phoc = all_unnoun_multi(1, \"utnoun\", args)\n",
    "print(mean(phoc))\n",
    "e = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "595618f6-20ff-4b3b-9a73-3790bf8f13af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9002537321537099"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(e-s)/len(phoc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e41107-943e-4d77-a242-bb39954225a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "args['explode_df']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9f8c470-ad28-42a1-b490-9e0f8aabd0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "explode_df['phocrank'] = explode_df['posthoc']*-1\n",
    "#rand = all_unnoun_multi(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4757ee2e-82e0-4d05-87ec-554fee2b2b45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8749, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7175ce6a-7330-4c3c-ae19-ac4761620510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hyp</th>\n",
       "      <th>hypsco</th>\n",
       "      <th>gold</th>\n",
       "      <th>goldsco</th>\n",
       "      <th>ascos</th>\n",
       "      <th>ahyps</th>\n",
       "      <th>numnodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Немецкие и французские стороны явно нуждались ...</td>\n",
       "      <td>tensor(0.3987, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>Германия и Франция явно нуждались во взаимном ...</td>\n",
       "      <td>tensor(0.9256, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>[0.3987096846103668]</td>\n",
       "      <td>[Немецкие и французские стороны явно нуждались...</td>\n",
       "      <td>385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Небольшая часть населения Индии не имеет ни од...</td>\n",
       "      <td>tensor(0.6347, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>Сложно понять низкую позицию Индии.</td>\n",
       "      <td>tensor(0.9250, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>[0.6347033977508545]</td>\n",
       "      <td>[Небольшая часть населения Индии не имеет ни о...</td>\n",
       "      <td>501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Так много о предсказках Кругмана.</td>\n",
       "      <td>tensor(0.2668, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>Это все, что предсказывал Кругман.</td>\n",
       "      <td>tensor(0.7456, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>[0.2667738199234009]</td>\n",
       "      <td>[Так много о предсказках Кругмана.]</td>\n",
       "      <td>554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Мы узнали, что это была просто воздушная пузыр...</td>\n",
       "      <td>tensor(0.8288, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>Мы поняли, что это было просто кружево.</td>\n",
       "      <td>tensor(1.0661, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>[0.8288499116897583]</td>\n",
       "      <td>[Мы узнали, что это была просто воздушная пузы...</td>\n",
       "      <td>558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>В некоторых странах до 30% более оптимистичных...</td>\n",
       "      <td>tensor(0.7622, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>До 30% наиболее оптимистичных потребителей в н...</td>\n",
       "      <td>tensor(1.0325, device='cuda:0', grad_fn=&lt;SumBa...</td>\n",
       "      <td>[0.7622228264808655]</td>\n",
       "      <td>[В некоторых странах до 30% более оптимистичны...</td>\n",
       "      <td>381</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  hyp  \\\n",
       "7   Немецкие и французские стороны явно нуждались ...   \n",
       "13  Небольшая часть населения Индии не имеет ни од...   \n",
       "19                  Так много о предсказках Кругмана.   \n",
       "31  Мы узнали, что это была просто воздушная пузыр...   \n",
       "71  В некоторых странах до 30% более оптимистичных...   \n",
       "\n",
       "                                               hypsco  \\\n",
       "7   tensor(0.3987, device='cuda:0', grad_fn=<SumBa...   \n",
       "13  tensor(0.6347, device='cuda:0', grad_fn=<SumBa...   \n",
       "19  tensor(0.2668, device='cuda:0', grad_fn=<SumBa...   \n",
       "31  tensor(0.8288, device='cuda:0', grad_fn=<SumBa...   \n",
       "71  tensor(0.7622, device='cuda:0', grad_fn=<SumBa...   \n",
       "\n",
       "                                                 gold  \\\n",
       "7   Германия и Франция явно нуждались во взаимном ...   \n",
       "13                Сложно понять низкую позицию Индии.   \n",
       "19                 Это все, что предсказывал Кругман.   \n",
       "31            Мы поняли, что это было просто кружево.   \n",
       "71  До 30% наиболее оптимистичных потребителей в н...   \n",
       "\n",
       "                                              goldsco                 ascos  \\\n",
       "7   tensor(0.9256, device='cuda:0', grad_fn=<SumBa...  [0.3987096846103668]   \n",
       "13  tensor(0.9250, device='cuda:0', grad_fn=<SumBa...  [0.6347033977508545]   \n",
       "19  tensor(0.7456, device='cuda:0', grad_fn=<SumBa...  [0.2667738199234009]   \n",
       "31  tensor(1.0661, device='cuda:0', grad_fn=<SumBa...  [0.8288499116897583]   \n",
       "71  tensor(1.0325, device='cuda:0', grad_fn=<SumBa...  [0.7622228264808655]   \n",
       "\n",
       "                                                ahyps  numnodes  \n",
       "7   [Немецкие и французские стороны явно нуждались...       385  \n",
       "13  [Небольшая часть населения Индии не имеет ни о...       501  \n",
       "19                [Так много о предсказках Кругмана.]       554  \n",
       "31  [Мы узнали, что это была просто воздушная пузы...       558  \n",
       "71  [В некоторых странах до 30% более оптимистичны...       381  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latpreds[latpreds['goldsco']-latpreds['hypsco']>.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74b0471-5f9d-403a-850f-e27892c45841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code for getting comparable sets for lattice generation\n",
    "#frset = pd.read_csv(\"outputs/score_csvs/frenchlargeexplodev1.csv\")\n",
    "#xsumset = pd.read_csv(\"outputs/score_csvs/nounxsumlargeexplodev2.csv\")\n",
    "#frset = frset.drop_duplicates(subset='ref')\n",
    "#xsumset = xsumset.drop_duplicates(subset='ref')\n",
    "#xsumset.to_csv(\"sumexamps.csv\")\n",
    "#frset.to_csv(\"frset.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
