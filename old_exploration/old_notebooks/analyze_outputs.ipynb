{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7403237-4abe-4b50-9669-6c2575ac73b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-12 05:56:06.291541: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-12 05:56:06.291562: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "from encoding_utils import *\n",
    "from flatten_lattice import *\n",
    "from model_construct import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3dcd8c2-f679-4d12-8b1f-a065095cba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submask_help(words):\n",
    "    msk = []\n",
    "    for i in range(len(words)-1):\n",
    "        if \"#\" in words[i+1]:\n",
    "            msk.append(0)\n",
    "        else:\n",
    "            msk.append(1)\n",
    "    msk.append(1)\n",
    "    return torch.tensor(msk)\n",
    "\n",
    "def subword_mask_all ():\n",
    "    msk = torch.ones_like(sents)\n",
    "    for i in range(0, len(sents)):\n",
    "        tmp = [tok.decode(s) for s in sents[i]]\n",
    "        msk[i] = submask_help(tmp)\n",
    "    return msk\n",
    "\n",
    "def get_acc():\n",
    "    # simplify prediction tensors\n",
    "    ysimp = torch.clone(ylabels)\n",
    "    psimp = torch.argmax(pred1, dim=2)\n",
    "    # clean up labels\n",
    "    sm = subword_mask_all()\n",
    "    ysimp[sents==0] = 0\n",
    "    ysimp[sents==102] = 0\n",
    "    ysimp[sm==0] = 0\n",
    "    ysimp[:, 0] = 0\n",
    "    # apply cleanaup to x \n",
    "    psimp[ysimp==0] = 0\n",
    "    # apply cleanaup to x \n",
    "    psimp[ysimp==0] = 0\n",
    "    # compute accuracy\n",
    "    acc = 1 - ((ysimp-psimp).count_nonzero())/ysimp.count_nonzero()\n",
    "    return acc, ysimp, psimp\n",
    "\n",
    "def get_tmap_acc(tmaps, sents):\n",
    "    a, ysmp, p = get_acc()\n",
    "    \n",
    "    assert len(tmaps)==len(ysmp)\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    inddistr = []\n",
    "    for a in ysmp.nonzero():\n",
    "        if int(p[a[0], a[1]]) in tmaps[a[0]][str(int(sents[a[0], a[1]]))]:\n",
    "            #print(int(ysmp[a[0], a[1]]), \" \",  tmaps[a[0]][str(int(sents[a[0], a[1]]))])\n",
    "            cor+=1\n",
    "        else:\n",
    "            # print(int(ysmp[a[0], a[1]]))\n",
    "            # print(int(p[a[0], a[1]]), \" \",tmaps[a[0]][str(int(sents[a[0], a[1]]))] )\n",
    "            inddistr.append(a[1])\n",
    "        tot+=1\n",
    "    print(cor/tot)\n",
    "    print(cor)\n",
    "    print(tot)\n",
    "    return cor/tot, inddistr\n",
    "            \n",
    "\n",
    "def get_err_tensors():\n",
    "    diff = ysimp-psimp\n",
    "    diff = diff.abs().bool().int()\n",
    "    errg = ysimp\n",
    "    errp = psimp\n",
    "    errg[diff==0] = 0\n",
    "    errp[diff==0] = 0\n",
    "    return errg, errp\n",
    "\n",
    "\n",
    "def print_decoded(toks):\n",
    "    nt = []\n",
    "    for t in toks:\n",
    "        if t==100 or t==101 or t==102 or t==0:\n",
    "            continue\n",
    "        nt.append(t)\n",
    "    print(tok.decode(nt))\n",
    "    return tok.decode(nt)\n",
    "    \n",
    "# \n",
    "def error_vis(ind):\n",
    "    nt = print_decoded(sents[ind])\n",
    "    p = [lablist[int(errp[ind][i])] for i in errp[ind].nonzero()]\n",
    "    g = [lablist[int(errg[ind][i])] for i in errp[ind].nonzero()]\n",
    "    s = [tok.decode(int(sents[ind][i])) for i in errp[ind].nonzero()]\n",
    "    print(\"ERRORS : \")\n",
    "    print(\"(predicted, gold, token)\")\n",
    "    print(list(zip(p, g, s)))\n",
    "    return nt\n",
    "    \n",
    "def vis_model_pred(strinp):\n",
    "    tokinps = tok(strinp, return_tensors='pt').input_ids.to(device)\n",
    "    msk = torch.tril(torch.ones((len(tokinps[0]), len(tokinps[0]))))\n",
    "    preds = bmodel(tokinps, attmasks=torch.stack([msk]).to(device))\n",
    "    preds = torch.argmax(preds, dim=2)\n",
    "    labs = [lablist[int(p)] for p in preds[0]]\n",
    "    tinps = [tok.decode(int(t))for t in tokinps[0]]\n",
    "    #print(list(zip(labs, tinps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea09515e-1dfb-4bdd-80b0-662ee00316f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy, ysimp, psimp = get_acc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2c8183-0289-49d7-8a5c-85107994cec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ysimp.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecd5943c-9b18-4ab3-ac99-7381e272e347",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Mem Used =  534572544\n"
     ]
    }
   ],
   "source": [
    "tok = fl.bert_tok\n",
    "\n",
    "# loads in odata with keys: tmaps, masks, pgraphs\n",
    "with open('torchsaved/outputv7.pkl', 'rb') as file:\n",
    "    odata = pickle.load(file)\n",
    "    \n",
    "with open('./a3distrib/lab_vocab.json') as json_file:\n",
    "    labels = json.load(json_file)\n",
    "    \n",
    "# load in other metadata\n",
    "bmodel = load_model(labels)\n",
    "sents, posids = create_inputs(odata['pgraphs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce80274a-5f7f-4106-8ca9-0e4f8d887297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n"
     ]
    }
   ],
   "source": [
    "ylabels = tmap_pos_goldlabels(odata['tmaps'], sents)   \n",
    "lablist = [l for l in labels.keys()]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pg = odata['pgraphs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c686dc87-95c8-4d81-81e2-6d1d8d11da8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  tensor(0.9288, device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "sents, posids = create_inputs(odata['pgraphs'])\n",
    "pred1 = bmodel(sents, fix_posids(posids), odata['masks'])\n",
    "accuracy, ysimp, psimp = get_acc()\n",
    "\n",
    "print(\"accuracy: \", accuracy)\n",
    "\n",
    "errg, errp = get_err_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06605e7-8d7e-4b79-92ea-5ad4e467fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ysimp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4b559c-5ba3-4d69-bdc7-6dc77998a3f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# can put any number between 0-100 and it will show an example and errors with the example\n",
    "INP = 9\n",
    "for i in range(0, 100):\n",
    "    vis_model_pred(error_vis(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dbcf96-c0d0-4c07-89f6-b0be3ababd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "len((ysimp-psimp).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0ab4c2-a22b-4c31-99ec-77304745a915",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ysimp.nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe237ad8-1616-4002-802c-acb1a31d8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### BEYOND THIS IS RANDOM SANITY CHECKING ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "41262adf-233e-42d3-835e-6025759af0fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9654552521620834\n",
      "19871\n",
      "20582\n"
     ]
    }
   ],
   "source": [
    "ta, ind_distr = get_tmap_acc(odata['tmaps'], sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "68a3d9ef-b3d2-49fb-bfd6-7291c6b21936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8bb62b0e-e8fc-4968-a471-26760f1ede14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15., 21., 14., 22., 28., 25., 15., 29., 24., 36., 19., 32., 29.,\n",
       "        25., 33., 26., 19., 22., 23., 17., 22., 20., 18., 22., 18., 16.,\n",
       "        18., 16.,  6.,  9., 12., 11.,  9.,  3.,  5.,  5.,  5.,  2.,  5.,\n",
       "         0.,  1.,  1.,  0.,  3.,  2.,  2.,  1.,  3.,  0.,  2.]),\n",
       " array([ 16.  ,  24.72,  33.44,  42.16,  50.88,  59.6 ,  68.32,  77.04,\n",
       "         85.76,  94.48, 103.2 , 111.92, 120.64, 129.36, 138.08, 146.8 ,\n",
       "        155.52, 164.24, 172.96, 181.68, 190.4 , 199.12, 207.84, 216.56,\n",
       "        225.28, 234.  , 242.72, 251.44, 260.16, 268.88, 277.6 , 286.32,\n",
       "        295.04, 303.76, 312.48, 321.2 , 329.92, 338.64, 347.36, 356.08,\n",
       "        364.8 , 373.52, 382.24, 390.96, 399.68, 408.4 , 417.12, 425.84,\n",
       "        434.56, 443.28, 452.  ]),\n",
       " <BarContainer object of 50 artists>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ind_distr = [int(i) for i in ind_distr]\n",
    "plt.hist(ind_distr, bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288865bd-bd23-43bb-a401-ca65dc84db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldlist = []\n",
    "predlist = []\n",
    "toklist = []\n",
    "for e in errg.nonzero():\n",
    "    goldlist.append(lablist[int(errg[e[0], e[1]])])\n",
    "    predlist.append(lablist[int(errp[e[0], e[1]])])\n",
    "    toklist.append(tok.decode(int(sents[e[0], e[1]])))\n",
    "    \n",
    "zipped = list(zip(goldlist, predlist, toklist))\n",
    "zipcln = []\n",
    "cnt = 0\n",
    "for z in zipped:\n",
    "    if z[1]==z[2]:\n",
    "        cnt+=1\n",
    "        continue\n",
    "    zipcln.append(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af233c-0509-4fe6-b206-e36c1223efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check masking \n",
    "sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de6baedd-5b4f-48ca-9f19-f71e503b3566",
   "metadata": {},
   "outputs": [],
   "source": [
    "odata['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc72c18-3032-4004-82cb-07174b36d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mask_leadup(ind):\n",
    "    msk = odata['masks'][ind]\n",
    "    smat = torch.zeros_like(msk)\n",
    "    smat[:, :] = sents[ind]\n",
    "    assert msk.shape == smat.shape\n",
    "    return smat, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d5e23-c281-4bef-a3de-c8f87cd50221",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm, m = print_mask_leadup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e467f88-eba6-4366-b924-674d77fbae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm[m==0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231027a3-0ede-48d8-8bd0-bcc58b055b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = tok.batch_decode(sm.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3a408-bfc4-494f-a63d-175c05f3deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = [txt.replace(\" [PAD]\", \"\") for txt in inps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cba68b3-260d-4f0a-896a-1bc38e7e88ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "posids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71194890-0f05-4132-99af-8d1001cc9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(5, 5)\n",
    "a[:3, :3] = torch.ones(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dd1aa2-9477-4146-b2b4-3907e775af50",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tril(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbd37a-9de3-4b5f-8e57-044f41c92c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
