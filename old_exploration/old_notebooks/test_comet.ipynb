{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a27fd736-d0cb-49ef-b7e4-89f5521e05da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-24 06:36:01.652302: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-24 06:36:01.652326: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from comet import download_model, load_from_checkpoint\n",
    "from typing import List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29a9ef29-dd90-4f02-b3aa-7cb440bd4f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cands(fname):\n",
    "    data = []\n",
    "    with open(fname, 'r') as file:\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            #print(line)\n",
    "            # if line is empty\n",
    "            # end of file is reached\n",
    "            if not line or len(line)<3:\n",
    "                break\n",
    "\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def process_cands(cand_data):\n",
    "    refs = []\n",
    "    hyps = []\n",
    "    srcs = []\n",
    "    clen = len(cand_data['scores'])\n",
    "    # return refs, hyps, srcs\n",
    "    return [cand_data['ref']]*clen, cand_data['cands'], [cand_data['inp']]*clen\n",
    "        \n",
    "\n",
    "def get_average_score(cand_data):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    for c in cand_data:\n",
    "        scoresum+=sum(c['scores'])\n",
    "        scoretot+=len(c['scores'])\n",
    "    return scoresum/scoretot\n",
    "\n",
    "\n",
    "#print(get_average_score(beam_cands))\n",
    "#print(get_average_score(lat_cands))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e00ad29b-403d-4f4e-823b-3e60d86b973a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cache dir for cometqe model\n",
    "cometqe_dir = \"./cometqemodel\"\n",
    "cometqe_model = \"wmt20-comet-qe-da\"\n",
    "cometmodel = \"wmt20-comet-da\"\n",
    "batch_size = 64\n",
    "\n",
    "def get_flat(hyp_lists, srcs):\n",
    "    flat_hyps = [hyp for sent_hyps in hyp_lists for hyp in sent_hyps]\n",
    "    dup_srcs = [src for src in srcs for _ in range(len(hyp_lists[0]))]\n",
    "    return flat_hyps, dup_srcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7487972-2b94-45b7-bf2c-ca26ea8bf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to run entire pipeline from a candidate jsonl file\n",
    "\n",
    "cometqe_path = download_model(cometqe_model, cometqe_dir)\n",
    "model = load_from_checkpoint(cometqe_path)\n",
    "cand_data = load_cands(\"./candoutputs/latoutputcandinit.jsonl\")\n",
    "rerank_info = get_reranked_cands(cand_data)\n",
    "storererank = {}\n",
    "storererank['data'] = rerank_info\n",
    "f = open('latticererank.json', 'w')\n",
    "json.dump(storererank, f)\n",
    "del model\n",
    "del cometqe_path\n",
    "comet_path = download_model(cometmodel, \"./cometmodel\")\n",
    "comet = load_from_checkpoint(comet_path)\n",
    "rrinfo = comet_rerank_info(rerank_info)\n",
    "del comet\n",
    "del comet_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56a4d6f0-8bb4-445d-affe-2f201b4bcf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MBartForConditionalGeneration, MBartTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "095dbbea-e896-41e3-bf99-c5dedc0ad0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-many-to-one-mmt\", src_lang=\"en_XX\", tgt_lang=\"ro_RO\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c507cabf-2939-4e1a-8cad-80d9e484dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_cand(ind):\n",
    "\n",
    "    print(cand_data[ind]['ref'])\n",
    "    for c in cand_data[ind]['cands']:\n",
    "        print(c)\n",
    "        \n",
    "def find_common(c1, c2list):\n",
    "    for c in c2list:\n",
    "        if c['ref']==c1['ref']:\n",
    "            return c\n",
    "        \n",
    "beam_cands = load_cands(\"./candoutputs/beam1en_de.jsonl\")\n",
    "lat_cands = load_cands(\"./candoutputs/latoutputde2.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03942265-32da-491e-97db-b08b803bc13b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.84158415841584\n"
     ]
    }
   ],
   "source": [
    "lens = []\n",
    "for l in lat_cands:\n",
    "    lens.append(len(l['cands']))\n",
    "print(sum(lens)/len(lens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e55f4816-7cab-4f71-837a-3e63af547aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_different(lis):\n",
    "    if len(lis)==0:\n",
    "        return True\n",
    "    prev = lis[0]\n",
    "    for l in lis:\n",
    "        if l is not prev:\n",
    "            return True\n",
    "        prev = l\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119eab03-2f93-414c-83eb-636b250ef4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(beam_cands[0]['cands'][0])\n",
    "def comp_debug_cand(ind, k):\n",
    "    if len(lat_cands[ind]['cands'])==0:\n",
    "        return\n",
    "    print(\"INPUT\")\n",
    "    print(lat_cands[ind]['inp'])\n",
    "    print(\"REF\")\n",
    "    print(lat_cands[ind]['ref'])\n",
    "    print(\"LATTICE\")\n",
    "    for i in range(0, k):\n",
    "        try:\n",
    "            print(lat_cands[ind]['scores'][i])\n",
    "            print(lat_cands[ind]['cands'][i])\n",
    "        except:\n",
    "            #print(\"NONE\")\n",
    "            \"\"\n",
    "    print(\"BEAM\")\n",
    "    common = find_common(lat_cands[ind], beam_cands)\n",
    "    #print(common)\n",
    "    for i in range(0, k):\n",
    "        print(common['scores'][i])\n",
    "        print(common['cands'][i])\n",
    "    print(\"BEAM\")\n",
    "    print(get_comet_scores([common['cands'][0]], [lat_cands[ind]['inp']], [lat_cands[ind]['ref']]))\n",
    "    print(\"LATTICE\")\n",
    "    print(get_comet_scores([lat_cands[ind]['cands'][0]], [lat_cands[ind]['inp']], [lat_cands[ind]['ref']]))\n",
    "\n",
    "for i in range(1, 20):\n",
    "    comp_debug_cand(i, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a467dd10-43e8-467e-b53a-64ff9a39d374",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cometqe_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m cometqe_path\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m model\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m comet_path\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cometqe_path' is not defined"
     ]
    }
   ],
   "source": [
    "del cometqe_path\n",
    "del model\n",
    "del comet_path\n",
    "del comet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b1e5084-36ad-4f55-9017-1a82cc323f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wmt20-comet-da is already in cache.\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n"
     ]
    }
   ],
   "source": [
    "#cometqe_path = download_model(cometqe_model, cometqe_dir)\n",
    "#model = load_from_checkpoint(cometqe_path)\n",
    "comet_path = download_model(cometmodel, \"./cometmodel\")\n",
    "comet = load_from_checkpoint(comet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb5d52cc-2d83-4796-b4d4-be02e6293661",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_data = True\n",
    "allscoressaved = []\n",
    "def get_reranked_cands(c_data):\n",
    "    global allscores\n",
    "    reranked_info = []\n",
    "    \n",
    "    if load_data:\n",
    "        allhyps = []\n",
    "        allsrcs = []\n",
    "        \n",
    "        for i in range(0, len(c_data)):\n",
    "            r, h, s = process_cands(c_data[i])\n",
    "            allhyps.extend(h)\n",
    "            allsrcs.extend(s)\n",
    "\n",
    "        allscores = get_cometqe_scores(allhyps, allsrcs)\n",
    "    for i in range(0, len(c_data)):\n",
    "        try:\n",
    "            tmp = {}\n",
    "            r, h, s = process_cands(c_data[i])\n",
    "            tmp['ref'] = r[0]\n",
    "            tmp['src'] = s[0]\n",
    "            tmp['topinitial'] = h[0]\n",
    "            #scoretmp = get_cometqe_scores(h, s)[0]\n",
    "            #print(scoretmp)\n",
    "            slen = len(c_data[i]['scores'])\n",
    "            scoretmp = allscores[0][i*slen:slen*(i+1)]\n",
    "            comind = scoretmp.index(max(scoretmp))\n",
    "            tmp['reranked'] = h[comind]\n",
    "            tmp['initialsco'] = scoretmp[0]\n",
    "            tmp['rersco'] = scoretmp[comind]\n",
    "            reranked_info.append(tmp)\n",
    "        except:\n",
    "            print(\"something weird happenedc\")\n",
    "    return reranked_info\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c87285f5-724f-44e1-9abf-6a6748624ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48.0"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allscores[0])/800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "29c40b8e-def5-4eed-ab2e-11a64ce08598",
   "metadata": {},
   "outputs": [],
   "source": [
    "rerank_info = get_reranked_cands(cand_data)\n",
    "storererank = {}\n",
    "storererank['data'] = rerank_info\n",
    "f = open('rerankdata.json', 'w')\n",
    "json.dump(storererank, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db118f2d-7eee-4fae-8401-aacb4c5f0e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rercomettmp = []\n",
    "firstcomettmp = []\n",
    "def comet_rerank_info(rrk_info):\n",
    "    global rercomettmp\n",
    "    global firstcomettmp\n",
    "    tophyps = []\n",
    "    rerhyps = []\n",
    "    refs = []\n",
    "    srcs = []\n",
    "    for r in rrk_info:\n",
    "        tophyps.append(r['topinitial'])\n",
    "        rerhyps.append(r['reranked'])\n",
    "        refs.append(r['ref'])\n",
    "        srcs.append(r['src'])\n",
    "    rer_comet_sco = get_comet_scores(rerhyps, srcs, refs)\n",
    "    first_comet_sco = get_comet_scores(tophyps, srcs, refs)\n",
    "    rercomettmp = rer_comet_sco\n",
    "    firstcomettmp = first_comet_sco\n",
    "    print(rer_comet_sco[1])\n",
    "    print(first_comet_sco[1])\n",
    "    return rer_comet_sco, first_comet_sco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c6edde-dee2-4ebe-9587-d3ae4e31fd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_rerank_info(rerank_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8ec083d-2466-4c7a-9b36-e1bb15f62dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cometqe_scores(hyps, srcs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt} for src, mt in zip(srcs, hyps)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = model.predict(\n",
    "        cometqe_input, batch_size=40, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs\n",
    "\n",
    "def get_comet_scores(hyps, srcs, refs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt, \"ref\":ref} for src, mt, ref in zip(srcs, hyps, refs)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = comet.predict(\n",
    "        cometqe_input, batch_size=40, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs\n",
    "\n",
    "def test_cometqe(hyp, src):\n",
    "    cqe_input = [{'src':src, 'mt':hyp}]\n",
    "    outputs = model.predict(\n",
    "        cqe_input, batch_size=1, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5cd7d87-47f2-46e9-8227-6e9449b0e8a9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_flat' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m test_srcs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI am doing very well today\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m ]\n\u001b[1;32m      5\u001b[0m test_hyps \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      6\u001b[0m     [\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHeute geht es mir sehr gut\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# should be good\u001b[39;00m\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMir geht es heute sehr schlecht\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;66;03m# should be bad\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     ], \n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 12\u001b[0m ft_hyps, ft_srcs \u001b[38;5;241m=\u001b[39m \u001b[43mget_flat\u001b[49m(test_hyps, test_srcs)\n\u001b[1;32m     13\u001b[0m get_cometqe_scores(ft_hyps, ft_srcs)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_flat' is not defined"
     ]
    }
   ],
   "source": [
    "test_srcs = [\n",
    "    \"I am doing very well today\",\n",
    "]\n",
    "\n",
    "test_hyps = [\n",
    "    [\n",
    "        \"Heute geht es mir sehr gut\", # should be good\n",
    "        \"Mir geht es heute sehr schlecht\", # should be bad\n",
    "    ], \n",
    "]\n",
    "\n",
    "ft_hyps, ft_srcs = get_flat(test_hyps, test_srcs)\n",
    "get_cometqe_scores(ft_hyps, ft_srcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f4d31b-0c56-48a8-852b-7bb51223eeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "def get_sample_set (num):\n",
    "    with open(\"translation_data/news-commentary-v15.de-en.tsv\") as file:\n",
    "        tsv_file = csv.reader(file, delimiter=\"\\t\")\n",
    "        i = 0\n",
    "        res = []\n",
    "        for f in tsv_file:\n",
    "            if i == num:\n",
    "                break\n",
    "            res.append(f)\n",
    "            i = i+1\n",
    "    tmpdf = pd.DataFrame(res)\n",
    "    tmpdf['de'] = tmpdf[0]\n",
    "    tmpdf['en'] = tmpdf[1]\n",
    "    del tmpdf[0]\n",
    "    del tmpdf[1]\n",
    "    return tmpdf\n",
    "\n",
    "data = get_sample_set(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5be71c70-f850-4b67-9ca2-a5beec1aca7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Steigt Gold auf 10.000 Dollar?</td>\n",
       "      <td>$10,000 Gold?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SAN FRANCISCO – Es war noch nie leicht, ein ra...</td>\n",
       "      <td>SAN FRANCISCO – It has never been easy to have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>In letzter Zeit allerdings ist dies schwierige...</td>\n",
       "      <td>Lately, with gold prices up more than 300% ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Erst letzten Dezember verfassten meine Kollege...</td>\n",
       "      <td>Just last December, fellow economists Martin F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Und es kam, wie es kommen musste.</td>\n",
       "      <td>Wouldn’t you know it?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Following its targeted killing of Iran's secon...</td>\n",
       "      <td>Following its targeted killing of Iran's secon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>And that shift would occur at a time of growin...</td>\n",
       "      <td>And that shift would occur at a time of growin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>The targeted killing by the United States of o...</td>\n",
       "      <td>The targeted killing by the United States of o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>After all, Iran and the US have already been a...</td>\n",
       "      <td>After all, Iran and the US have already been a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>As in previous years, Project Syndicate asked ...</td>\n",
       "      <td>As in previous years, Project Syndicate asked ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     de  \\\n",
       "0                        Steigt Gold auf 10.000 Dollar?   \n",
       "1     SAN FRANCISCO – Es war noch nie leicht, ein ra...   \n",
       "2     In letzter Zeit allerdings ist dies schwierige...   \n",
       "3     Erst letzten Dezember verfassten meine Kollege...   \n",
       "4                     Und es kam, wie es kommen musste.   \n",
       "...                                                 ...   \n",
       "9995  Following its targeted killing of Iran's secon...   \n",
       "9996  And that shift would occur at a time of growin...   \n",
       "9997  The targeted killing by the United States of o...   \n",
       "9998  After all, Iran and the US have already been a...   \n",
       "9999  As in previous years, Project Syndicate asked ...   \n",
       "\n",
       "                                                     en  \n",
       "0                                         $10,000 Gold?  \n",
       "1     SAN FRANCISCO – It has never been easy to have...  \n",
       "2     Lately, with gold prices up more than 300% ove...  \n",
       "3     Just last December, fellow economists Martin F...  \n",
       "4                                 Wouldn’t you know it?  \n",
       "...                                                 ...  \n",
       "9995  Following its targeted killing of Iran's secon...  \n",
       "9996  And that shift would occur at a time of growin...  \n",
       "9997  The targeted killing by the United States of o...  \n",
       "9998  After all, Iran and the US have already been a...  \n",
       "9999  As in previous years, Project Syndicate asked ...  \n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data.to_csv('./translation_data/en_de.csv', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b1de6c10-1f46-479d-8c49-1ff5f3b63376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# candidate generation code\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import json\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "#model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "918b0a53-ad7b-42df-95bb-987540176d1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s>de_DE Zunächst und vielleicht vor allem die Revolutionen 1989 und der darauffolgende Zusammenbruch der Sowjetunion haben die globale Bipolarismus ein Ende']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks = [16844,599,39186,147,5877,1843,54810,68,2028,87046,4249,434,1061,122,128826,72537,1067,75900,24064,122,165,13501,33,135555,68,18341,1248,32847,165,235267,250003,2]\n",
    "toks.reverse()\n",
    "tokenizer.batch_decode([toks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c4e492-a4ad-4fd1-8f74-0556696274ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#article_en = \"The head of the United Nations says there is no military solution in Syria\"\n",
    "\n",
    "\n",
    "# translate from English to French (test)\n",
    "\"\"\"\n",
    "generated_tokens = model.generate(\n",
    "    **model_inputs,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"fr_XX\"],\n",
    "    do_sample=True, \n",
    "    max_length=50, \n",
    "    #top_k=50, \n",
    "    top_p=0.95, \n",
    "    num_return_sequences=10\n",
    "    \n",
    ")\n",
    "\"\"\"\n",
    "bs_cands = []\n",
    "def get_bs_candidates(inputs, refs, per_example=10, batch=8):\n",
    "    global bs_cands\n",
    "    bs_cands = []\n",
    "    tmpfile = open(\"./candoutputs/beamsearchcand\"+str(per_example)+\".jsonl\", \"w\")\n",
    "    for i in range(0, int(len(inputs)/batch)):\n",
    "        print(i*batch)\n",
    "        ins = inputs[i*batch:batch*(i+1)]\n",
    "        ref = refs[i*batch:batch*(i+1)]\n",
    "        model_inputs = tokenizer(ins, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"de_DE\"],\n",
    "            num_beams=per_example,\n",
    "            num_return_sequences=per_example,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "\n",
    "        )\n",
    "        allsco = generated_tokens.sequences_scores\n",
    "        allcands = tokenizer.batch_decode(generated_tokens.sequences, skip_special_tokens=True)\n",
    "        for j in range(0, batch):\n",
    "            tmp = {}\n",
    "            tmp['scores'] = list(allsco[j*per_example:per_example*(j+1)])\n",
    "            tmp['scores'] = [tensor.item() for tensor in tmp['scores']]\n",
    "            tmp['cands'] = list(allcands[j*per_example:per_example*(j+1)])\n",
    "            tmp['inp'] = inputs[i*batch+j]\n",
    "            tmp['ref'] = refs[i*batch+j]\n",
    "            #print(tmp)\n",
    "            bs_cands.append(tmp)\n",
    "            tmpfile.write(json.dumps(tmp))\n",
    "            tmpfile.write('\\n')\n",
    "            \n",
    "        # ensure space is cleared\n",
    "        del model_inputs\n",
    "        del generated_tokens\n",
    "        del allsco\n",
    "        del allcands\n",
    "    tmpfile.close()\n",
    "    return bs_cands\n",
    "\n",
    "nuc_cands = []\n",
    "def get_nucleus_candidates(inputs, refs, per_example=10, batch=8):\n",
    "    global nuc_cands\n",
    "    nuc_cands = []\n",
    "    tmpfile = open(\"./candoutputs/nucleuscand\"+str(per_example)+\".jsonl\", \"w\")\n",
    "    for i in range(0, int(len(inputs)/batch)):\n",
    "        print(i*batch)\n",
    "        ins = inputs[i*batch:batch*(i+1)]\n",
    "        ref = refs[i*batch:batch*(i+1)]\n",
    "        model_inputs = tokenizer(ins, return_tensors=\"pt\", truncation=True, padding=True).to(device)\n",
    "        generated_tokens = model.generate(\n",
    "            **model_inputs,\n",
    "            forced_bos_token_id=tokenizer.lang_code_to_id[\"de_DE\"],\n",
    "            do_sample=True, \n",
    "            max_length=50, \n",
    "            top_k=50, \n",
    "            top_p=0.6, \n",
    "            num_return_sequences=per_example,\n",
    "            return_dict_in_generate=True,\n",
    "            output_scores=True,\n",
    "\n",
    "        )\n",
    "        torch.cuda.empty_cache()\n",
    "        allsco = generated_tokens.sequences_scores\n",
    "        allcands = tokenizer.batch_decode(generated_tokens.sequences, skip_special_tokens=True)\n",
    "        for j in range(0, batch):\n",
    "            tmp = {}\n",
    "            tmp['scores'] = list(allsco[j*per_example:per_example*(j+1)])\n",
    "            tmp['scores'] = [tensor.item() for tensor in tmp['scores']]\n",
    "            tmp['cands'] = list(allcands[j*per_example:per_example*(j+1)])\n",
    "            tmp['inp'] = inputs[i*batch+j]\n",
    "            tmp['ref'] = refs[i*batch+j]\n",
    "            #print(tmp)\n",
    "            nuc_cands.append(tmp)\n",
    "            tmpfile.write(json.dumps(tmp))\n",
    "            tmpfile.write('\\n')\n",
    "            \n",
    "        # ensure space is cleared\n",
    "        del model_inputs\n",
    "        del generated_tokens\n",
    "        del allsco\n",
    "        del allcands\n",
    "    tmpfile.close()\n",
    "    return nuc_cands\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf696f5-b5e2-4324-a203-a24dfa826ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab0f59d-9a51-4cc6-a741-706400d2a20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_nucleus_candidates(list(data['en'][:800]), list(data['de'][:800]), 40, 2)\n",
    "del nuc_cands\n",
    "get_nucleus_candidates(list(data['en'][:800]), list(data['de'][:800]), 50, 1)\n",
    "del nuc_cands\n",
    "get_bs_candidates(list(data['en'][:800]), list(data['de'][:800]), 10, 2)\n",
    "del bs_cands\n",
    "\n",
    "\n",
    "#print(generated_tokens)\n",
    "#print(len(generated_tokens.sequences_scores))\n",
    "#tokenizer.batch_decode(generated_tokens.sequences, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5189f7ca-ca8b-4130-9e30-5058826d4f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f46b6a20-aeb3-4a3b-9d66-cb0da9371757",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3305e7ef-9f0b-4d4c-8303-1680207f46b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1 = open(\"myfile.txt\", \"w\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aa052146-1f86-4ea8-a6f9-fd0f6bce6a27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testd = {'yo':\"what is good buddy\"}\n",
    "\n",
    "file1.write(json.dumps(testd))\n",
    "file1.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cffcfd65-ecdd-4816-8e9a-85a50a206d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e1501f-4237-44ed-8c82-61a0f19634c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
