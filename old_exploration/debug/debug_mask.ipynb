{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac3ef579-237a-4014-8391-6e6983f1a878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22946b6-bc06-40d3-b94e-1712fee2b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "frgens = os.listdir(\"./custom_output/data/mtn1_fr-en_bfs_recom_2_-1_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e1f095db-ab26-4e0d-b07e-dcb4a82a2370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85317"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(frgens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08e6e08f-8573-451e-a831-d2beb997ba5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample - I am his friend was\n",
    "# we want the following mask \n",
    "\"\"\"\n",
    "1 0 0 0 0 - I \n",
    "1 1 0 0 0 - am \n",
    "1 1 1 0 1 - his\n",
    "1 1 1 1 1 - friend\n",
    "1 0 0 0 1 - was\n",
    "\"\"\"\n",
    "# start from adjacency (previous nodes)\n",
    "\"\"\"\n",
    "0 0 0 0 0 - I\n",
    "1 0 0 0 0 - am\n",
    "0 1 0 0 0 - his\n",
    "0 0 1 0 0 - friend\n",
    "1 0 0 0 0 - was\n",
    "\"\"\"\n",
    "back_adjac = torch.tensor([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b570f18a-cd50-4581-b64b-e720a6775eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get adjacency from flat canvas of tokens, with previous tokens\n",
    "def adj_mat(flat_canv, mlen):\n",
    "    # TODO write this function\n",
    "    mask = torch.zeros((mlen, mlen))\n",
    "    # have a cutoff after the calculated limit to circumvent extra computation\n",
    "    for row in range(mlen):\n",
    "        for p in flat_canv[row].prevs:\n",
    "            if p.canvpos<mlen:\n",
    "                mask[row][p.canvpos] = 1\n",
    "    return mask\n",
    "\n",
    "# ensure that token canvas has the right values for mask creation\n",
    "def mask_prep_canv(canv, lim):\n",
    "    maxpos = -1\n",
    "    # we're taking in DLReverseNodes\n",
    "    ind = 0\n",
    "    for c in canv:\n",
    "        # maybe should be an assert instead to ward off weirdness?\n",
    "        c.canvpos = ind\n",
    "        maxpos = max(maxpos, c.pos)\n",
    "        # only include as a test, remove later\n",
    "        for prev in c.prevs:\n",
    "            assert prev in canv\n",
    "    return maxpos  \n",
    "\n",
    "# get connectivity matrix from flat canvas of tokens\n",
    "# by exponentiating reverse connected adjacency\n",
    "def connect_mat(flat_canv):\n",
    "    # TODO something to get length, while considering space from inp tokens\n",
    "    mlen = 5\n",
    "    #back_adjac = adj_mat(flat_canv)\n",
    "    tot = back_adjac\n",
    "    tmp = back_adjac\n",
    "    # TODO we need length of longest path in graph, make sure canvpos is updated\n",
    "    # can do in one O(N) pass I think\n",
    "    #maxlen = 3\n",
    "    while torch.sum((tot[:, 0]>0))<(mlen-1):\n",
    "        tmp = torch.mm(back_adjac, tmp)\n",
    "        tot += tmp\n",
    "    tot = tot+ torch.eye(mlen)\n",
    "    return (tot>0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "266aa3a0-975e-4906-a46f-0e2253a14651",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum((back_adjac[:, 0]>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "00485315-c2bd-480e-999e-5d3989596c51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0],\n",
       "        [1, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1],\n",
       "        [0, 0, 1, 0, 0],\n",
       "        [1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_adjac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7f9ed163-f5da-46a7-8fc9-f4b9fb9f8484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 0, 0],\n",
       "        [1, 1, 0, 0, 0],\n",
       "        [1, 1, 1, 0, 1],\n",
       "        [1, 1, 1, 1, 1],\n",
       "        [1, 0, 0, 0, 1]], dtype=torch.int32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "back_adjac = torch.tensor([\n",
    "    [0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 1],\n",
    "    [0, 0, 1, 0, 0],\n",
    "    [1, 0, 0, 0, 0],\n",
    "])\n",
    "connect_mat(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ecfd5e-405c-4f7d-b77c-62688d231333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# TODO go into github to get the older version of this file\n",
    "\n",
    "# TODO more sanity checking on whether or not we're recording the right number of branches     \n",
    "def get_adjac_mat(pgraph):\n",
    "    res = []\n",
    "    for node in pgraph:\n",
    "        tmp = []\n",
    "        for p in pgraph:\n",
    "            if str(p['id']) in node['nexts']:\n",
    "                tmp.append(1)\n",
    "            else:\n",
    "                tmp.append(0)\n",
    "        res.append(torch.tensor(tmp))\n",
    "    return torch.stack(res)\n",
    "\n",
    "def get_poslist(processed):\n",
    "    res = []\n",
    "    for p in processed:\n",
    "        res.append(p['pos'])\n",
    "    return res\n",
    "\n",
    "def conmat(adj, longestpath):\n",
    "    res = torch.zeros_like(adj)\n",
    "    adj = torch.triu(adj)\n",
    "    start = adj\n",
    "    for i in range(0, longestpath):\n",
    "        if i>0:\n",
    "            start = torch.mm(start, adj)\n",
    "        res = res + start\n",
    "    return res\n",
    "\n",
    "# fixes input to now account for [SEP] and [CLS] I believe\n",
    "def correct_mask_sep(mat):\n",
    "    for i in range(len(mat)):\n",
    "        mat[i][i] = 1\n",
    "    # TODO need to remove for stuff\n",
    "    # fixed = torch.nn.functional.pad(input=mat, pad=(1, 1, 1, 1), mode='constant', value=1)\n",
    "    return mat\n",
    "\n",
    "def connect_mat(pgraph):\n",
    "    conm = conmat(get_adjac_mat(pgraph), max(get_poslist(pgraph)))\n",
    "    conm = conm + torch.transpose(conm, 0, 1)\n",
    "\n",
    "    cmat =  (conm>0).float()\n",
    "    # handle things to be able to take when really big input\n",
    "    respad = None\n",
    "    MAX =512\n",
    "    # we're within 498\n",
    "    if len(cmat) < MAX-1:\n",
    "        # get the version with CLS and SEP\n",
    "        cmat = correct_mask_sep(cmat)\n",
    "        # copy that onto fixed input: the rest is padding\n",
    "        respad = torch.zeros((MAX, MAX))\n",
    "        cpmax = len(cmat)\n",
    "        for i in range(cpmax):\n",
    "            for j in range(cpmax):\n",
    "                respad[i][j] = cmat[i][j]\n",
    "    else:\n",
    "        # TODO made changes here\n",
    "        # we're over the limit, first get truncated version\n",
    "        respad = torch.zeros((MAX, MAX))\n",
    "        # make truncated matrix\n",
    "        for i in range(MAX):\n",
    "            for j in range(MAX):\n",
    "                respad[i][j] = cmat[i][j]\n",
    "        # do CLS / SEP tokens on that \n",
    "        respad = correct_mask_sep(respad)\n",
    "        \n",
    "    #respad[respad==0] = -float('inf')\n",
    "    return respad #ones_padding(respad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
