{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4375d25b-f79b-46cb-8ab9-fcfe1727c9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-24 04:06:04.521878: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-24 04:06:04.521897: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "131072"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import csv\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "import sys\n",
    "import random\n",
    "import pandas as pd\n",
    "from rerank_score_cands_new import load_cands\n",
    "import numpy as np\n",
    "from comet import download_model, load_from_checkpoint\n",
    "import pickle\n",
    "\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e11dbe52-3f5c-4131-acba-0302eeca68e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Encoder-Decoder Model Embedding, Add a Weighted Layer at the end that leads to regression\n",
    "class XLMCometRegressor(nn.Module):\n",
    "    \n",
    "    def __init__(self, drop_rate=0.2):\n",
    "        # TODO should we be freezing layers?\n",
    "        super().__init__()\n",
    "        \n",
    "        self.xlmroberta = AutoModel.from_pretrained('xlm-roberta-base')\n",
    "        # Num labels 1 should just indicate regression (?)\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Dropout(drop_rate),\n",
    "            nn.Linear(self.xlmroberta.config.hidden_size, 1))\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input_ids, attention_masks):\n",
    "        # don't finetune xlmroberta model\n",
    "        with torch.no_grad():\n",
    "            outputs = self.xlmroberta(input_ids, attention_mask=attention_masks, encoder_attention_mask=attention_masks)\n",
    "        class_label_output = outputs[1]\n",
    "        outputs = self.regressor(class_label_output)\n",
    "        return outputs\n",
    "    \n",
    "model = XLMCometRegressor(drop_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71060d80-3e49-4543-a66c-7b5a41cd5f71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./torchsaved/comestim8.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f59d5bf-fb6d-4932-9ced-588e549089c8",
   "metadata": {},
   "outputs": [],
   "source": [
    " ### ### Older code, TODO clean up this notebook ### ###\n",
    "def save_cometqe_data(md, xd, yd):\n",
    "    # save data into a pickle file\n",
    "    with open('processeddata/commasks.pkl', 'wb') as f:\n",
    "        pickle.dump(md, f)\n",
    "\n",
    "    with open('processeddata/cominps.pkl', 'wb') as f:\n",
    "        pickle.dump(xd, f)\n",
    "\n",
    "    with open('processeddata/comlabels.pkl', 'wb') as f:\n",
    "        pickle.dump(yd, f)\n",
    "\n",
    "def load_cometqe_data():\n",
    "    with open('processeddata/commasks.pkl', 'rb') as f:\n",
    "        masks = pickle.load(f)\n",
    "\n",
    "    with open('processeddata/cominps.pkl', 'rb') as f:\n",
    "        xinps = pickle.load(f)\n",
    "\n",
    "    with open('processeddata/comlabels.pkl', 'rb') as f:\n",
    "        yinps = pickle.load(f)\n",
    "    return masks, xinps, yinps\n",
    "\n",
    "mdata, xdata, ydata = load_cometqe_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c4e3a84-0514-47ee-bdaa-7375cda76b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "xdata = [torch.tensor(x) for x in xdata]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8aba5030-ad5f-45a0-afd8-04d975e4a3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "cut = int(len(xdata)*.9)\n",
    "xtrain, ytrain, mtrain = xdata[:cut], ydata[:cut], mdata[:cut]\n",
    "xtest, ytest, mtest = xdata[cut:], ydata[cut:], mdata[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c4dc90d-fc43-4602-a8ff-06203aa64cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, masks):\n",
    "        assert len(sentences) == len(labels)\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.masks = masks\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences[i], self.labels[i], self.masks[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "def collate_custom(datafull):\n",
    "    #print(len(datafull[0]))\n",
    "    data = [torch.tensor(d[0]) for d in datafull]\n",
    "    masdata=  [d[2] for d in datafull]\n",
    "    labels = [d[1] for d in datafull]\n",
    "    max_len = max([x.squeeze().numel() for x in data])\n",
    "    data = [torch.nn.functional.pad(x, pad=(0, max_len - x.numel()), mode='constant', value=0) for x in data]\n",
    "    data = torch.stack(data).to(device)\n",
    "    masdata = [torch.nn.functional.pad(x, pad=(0, max_len - x[0].numel(), 0, max_len - x[0].numel()), mode='constant', value=0) for x in masdata]\n",
    "    masdata = torch.stack(masdata).to(device)\n",
    "    return data, torch.tensor(labels).to(device), masdata\n",
    "\n",
    "testloader = DataLoader(RegressionDataset(xtest, ytest, mtest), batch_size=32, shuffle=False, collate_fn=collate_custom)\n",
    "trainloader = DataLoader(RegressionDataset(xtrain, ytrain, mtrain), batch_size=32, shuffle=False, collate_fn=collate_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e8cb3b9d-9c15-40ae-8f89-3bd698e82834",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "def evaluate(model, loss_function, test_dataloader, device):\n",
    "    model.eval()\n",
    "    test_loss, test_r2 = [], []\n",
    "    pdistr = []\n",
    "    for batch in test_dataloader:\n",
    "        batch_inputs, batch_labels, batch_masks = \\\n",
    "                                 tuple(b.to(device) for b in batch)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(batch_inputs, batch_masks)\n",
    "        print(outputs.squeeze())\n",
    "        print(batch_labels.squeeze())\n",
    "        pdistr.extend(outputs)\n",
    "        loss = loss_function(outputs.squeeze(), \n",
    "                             batch_labels.squeeze())\n",
    "        test_loss.append(loss.item())\n",
    "        #r2 = r2_score(outputs, batch_labels)\n",
    "        #test_r2.append(r2.item())\n",
    "    return test_loss, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "98644309-732d-463f-a7d6-0202340f540e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3426236/2613059981.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = [torch.tensor(d[0]) for d in datafull]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1079, 0.1079, 0.1083, 0.1081, 0.1085, 0.1086, 0.1086, 0.1086, 0.1079,\n",
      "        0.1081, 0.1085, 0.1086, 0.1085, 0.1086, 0.1086, 0.1086, 0.1086, 0.1086,\n",
      "        0.1086, 0.1084, 0.1084, 0.1086, 0.1086, 0.1086, 0.1086, 0.1087, 0.1080,\n",
      "        0.1086, 0.1084, 0.1086, 0.1086, 0.1086], device='cuda:0')\n",
      "tensor([ 1.2227,  0.9105,  0.6955,  0.5184,  1.0176,  0.8584, -0.3095,  0.5596,\n",
      "         1.1021,  0.6812, -1.1900,  0.5573, -0.0515,  0.3817, -1.5592,  0.6363,\n",
      "         0.6196,  0.9293, -1.2511,  0.9856,  0.9391,  0.6022, -1.4378, -0.9727,\n",
      "         0.7300, -1.5616,  0.2582, -1.1921, -0.0815,  0.2851,  0.8453,  0.9949],\n",
      "       device='cuda:0')\n",
      "tensor([0.1086, 0.1086, 0.1080, 0.1085, 0.1086, 0.1086, 0.1085, 0.1086, 0.1087,\n",
      "        0.1086, 0.1086, 0.1086, 0.1085, 0.1086, 0.1086, 0.1081, 0.1087, 0.1087,\n",
      "        0.1085, 0.1075, 0.1086, 0.1073, 0.1077, 0.1086, 0.1085, 0.1086, 0.1083,\n",
      "        0.1082, 0.1083, 0.1086, 0.1087, 0.1084], device='cuda:0')\n",
      "tensor([ 0.7350, -1.4246,  0.8351,  0.7925, -1.0432,  0.3040, -1.2722,  0.8418,\n",
      "        -1.1770,  0.7552,  0.8333,  0.6345, -1.4231,  0.7497,  0.9457,  0.7591,\n",
      "        -1.5665,  0.4554, -1.2035,  0.9161, -0.7448,  0.5166,  0.9562,  0.8376,\n",
      "         0.8992,  0.9181,  0.9163,  0.7317,  1.0028,  0.7984,  0.9212,  0.9329],\n",
      "       device='cuda:0')\n",
      "tensor([0.1085, 0.1086, 0.1085, 0.1085, 0.1086, 0.1080, 0.1075, 0.1079, 0.1086,\n",
      "        0.1086, 0.1080, 0.1082, 0.1080, 0.1085, 0.1086, 0.1086, 0.1086, 0.1082,\n",
      "        0.1085, 0.1085, 0.1081, 0.1086, 0.1086, 0.1085, 0.1084, 0.1085, 0.1081,\n",
      "        0.1086, 0.1086, 0.1084, 0.1084, 0.1086], device='cuda:0')\n",
      "tensor([ 0.7981, -1.3094, -1.4395,  0.4508,  0.7391,  1.1938,  1.2234,  0.7809,\n",
      "         0.8036,  0.5024,  0.9291,  0.8865,  0.8348,  0.1046, -1.2056, -1.3558,\n",
      "         0.7890,  1.0437, -1.2334, -2.1427,  0.9873,  0.7628,  0.8023,  0.6380,\n",
      "         0.5959,  0.8663,  0.5148, -1.3666,  0.7839,  0.5712,  0.9710,  0.7724],\n",
      "       device='cuda:0')\n",
      "tensor([0.1085, 0.1086, 0.1087, 0.1075, 0.1086, 0.1086, 0.1086, 0.1086, 0.1078,\n",
      "        0.1078, 0.1085, 0.1087, 0.1086, 0.1082, 0.1086, 0.1077, 0.1081, 0.1082,\n",
      "        0.1081, 0.1086, 0.1077, 0.1086, 0.1086, 0.1084, 0.1086, 0.1084, 0.1079,\n",
      "        0.1084, 0.1085, 0.1085, 0.1086, 0.1086], device='cuda:0')\n",
      "tensor([-1.2424,  0.8140,  0.8533,  1.0479,  0.8007,  0.7718,  0.7259, -1.8276,\n",
      "         1.0402,  0.5943, -1.2951,  1.0519,  0.8844,  1.0155, -1.3282, -1.5956,\n",
      "         0.9206,  0.7541,  0.9715,  0.2818,  1.0506, -1.3100,  0.9523,  0.5383,\n",
      "         0.2413,  1.0311,  0.9869, -0.1975,  0.7784,  0.7810,  0.7732,  0.7052],\n",
      "       device='cuda:0')\n",
      "tensor([0.1085, 0.1079, 0.1086, 0.1086, 0.1087, 0.1086, 0.1083, 0.1086, 0.1085,\n",
      "        0.1083, 0.1086, 0.1087, 0.1082, 0.1086, 0.1085, 0.1085, 0.1085, 0.1085,\n",
      "        0.1086, 0.1077, 0.1084, 0.1086, 0.1086, 0.1084, 0.1085, 0.1080, 0.1080,\n",
      "        0.1086, 0.1086, 0.1082, 0.1083, 0.1086], device='cuda:0')\n",
      "tensor([ 0.1819,  0.9945,  0.7621,  0.2618, -1.1578,  0.8135,  0.8269,  0.7425,\n",
      "         0.7544,  0.9624,  0.9338, -1.2001,  1.0349,  0.6556,  0.8383,  0.5123,\n",
      "        -1.1836,  0.7838, -1.0203,  1.0853,  0.7519, -1.4146,  0.8918,  0.8969,\n",
      "         0.2814,  0.7731, -0.8597,  0.9670,  0.6290,  0.9898,  1.0132,  0.4515],\n",
      "       device='cuda:0')\n",
      "tensor([0.1078, 0.1085, 0.1081, 0.1085, 0.1086, 0.1082, 0.1081, 0.1083, 0.1082,\n",
      "        0.1085, 0.1078, 0.1086, 0.1081, 0.1086, 0.1083, 0.1082, 0.1083, 0.1087,\n",
      "        0.1085, 0.1086, 0.1082, 0.1080, 0.1086, 0.1086, 0.1086, 0.1083, 0.1079,\n",
      "        0.1086, 0.1084, 0.1085, 0.1086, 0.1086], device='cuda:0')\n",
      "tensor([ 0.9947, -1.5585,  0.9558,  0.9720, -1.0922,  0.7364,  0.7764,  0.9197,\n",
      "         0.8722,  0.8767,  0.7446, -0.4686, -0.1401,  0.2428,  0.8704,  1.0122,\n",
      "         0.7359, -1.2994,  0.4430,  0.5931,  1.0558,  0.9295, -0.1702, -0.6526,\n",
      "        -1.3460,  0.3207,  1.1028,  0.7542,  1.0737,  0.8914, -1.3818,  0.7895],\n",
      "       device='cuda:0')\n",
      "tensor([0.1082, 0.1086, 0.1086, 0.1086, 0.1086, 0.1086, 0.1085, 0.1086, 0.1083,\n",
      "        0.1085, 0.1086, 0.1087, 0.1085, 0.1086, 0.1086, 0.1083, 0.1086, 0.1086,\n",
      "        0.1078, 0.1085, 0.1086, 0.1084, 0.1086, 0.1087, 0.1082, 0.1086, 0.1086,\n",
      "        0.1086, 0.1081, 0.1086, 0.1086, 0.1083], device='cuda:0')\n",
      "tensor([ 0.8977, -1.1271, -1.3257,  0.8132, -0.3497,  0.8354, -0.1995, -1.5058,\n",
      "         0.9790,  0.9581, -1.3485,  0.7909,  0.8167,  0.5905,  0.4792, -1.2152,\n",
      "        -1.0718, -0.1361,  1.0217,  0.8357,  0.7537,  0.9576,  0.5041, -1.3158,\n",
      "         0.8915, -1.2614,  0.7325, -0.3406,  0.9852, -0.8599,  0.8493,  0.8823],\n",
      "       device='cuda:0')\n",
      "tensor([0.1086, 0.1084, 0.1087, 0.1085, 0.1085, 0.1085, 0.1086, 0.1086, 0.1085,\n",
      "        0.1086, 0.1087, 0.1086, 0.1084, 0.1086, 0.1086, 0.1086, 0.1081, 0.1081,\n",
      "        0.1085, 0.1086, 0.1086, 0.1084, 0.1086, 0.1086, 0.1086, 0.1081, 0.1086,\n",
      "        0.1085, 0.1086, 0.1086, 0.1086, 0.1087], device='cuda:0')\n",
      "tensor([-1.3249e+00,  9.7945e-01, -1.2435e+00, -1.5582e-03,  8.4462e-01,\n",
      "         8.7620e-01,  8.6091e-01,  7.3252e-01, -1.5592e+00,  1.0412e-01,\n",
      "        -1.1983e+00,  8.5232e-01,  9.6825e-01, -1.1555e+00, -1.3433e+00,\n",
      "        -3.7363e-01,  9.5452e-01,  7.2202e-01, -5.6362e-01,  5.9519e-01,\n",
      "         7.1184e-01, -1.2166e+00, -1.0196e+00,  1.9740e-01, -1.5529e+00,\n",
      "         7.4769e-01, -6.4686e-01,  8.9431e-01,  1.0052e+00, -9.1813e-01,\n",
      "         7.5148e-01, -1.2928e+00], device='cuda:0')\n",
      "tensor([0.1085, 0.1086, 0.1086, 0.1085, 0.1079, 0.1086, 0.1086, 0.1085, 0.1087,\n",
      "        0.1077, 0.1086, 0.1083, 0.1081, 0.1083, 0.1085, 0.1079, 0.1086, 0.1086,\n",
      "        0.1087, 0.1083, 0.1084, 0.1083, 0.1086, 0.1086, 0.1086, 0.1086, 0.1086,\n",
      "        0.1086, 0.1079, 0.1087, 0.1079, 0.1081], device='cuda:0')\n",
      "tensor([-1.0527, -1.0755, -0.1893, -1.2329,  0.9068,  0.4089, -1.2870,  0.8576,\n",
      "         0.0160,  0.8487, -1.1476,  1.0503,  0.9685,  1.0093, -1.2414,  0.9936,\n",
      "        -1.7234,  0.7919, -1.3891,  0.7385,  0.7549,  0.9803, -1.3114, -0.0772,\n",
      "        -1.4113,  0.7334,  0.7860,  0.7535,  0.8706, -1.0661,  0.8670,  0.9999],\n",
      "       device='cuda:0')\n",
      "tensor([0.1081, 0.1081, 0.1071, 0.1086, 0.1085, 0.1088, 0.1085, 0.1081, 0.1085,\n",
      "        0.1081, 0.1085, 0.1085, 0.1087, 0.1086, 0.1086, 0.1086, 0.1076, 0.1085,\n",
      "        0.1086, 0.1086, 0.1085, 0.1086, 0.1086, 0.1086, 0.1082, 0.1084, 0.1086,\n",
      "        0.1086, 0.1085, 0.1079, 0.1086, 0.1079], device='cuda:0')\n",
      "tensor([ 0.7551,  0.8856,  0.9452,  0.5267,  0.8456, -1.4071,  0.7829,  0.9904,\n",
      "         0.9283,  0.9971,  0.8494, -0.2242,  0.5490,  0.7368,  0.2379,  0.7916,\n",
      "         1.1038,  0.1101, -1.2030,  0.5477,  1.0080, -1.2364,  0.0189,  0.5323,\n",
      "         0.8955,  0.9257, -1.4317,  0.3722, -0.2263,  1.0179, -1.2614,  0.9225],\n",
      "       device='cuda:0')\n",
      "tensor([0.1079, 0.1087, 0.1083, 0.1085, 0.1084, 0.1087, 0.1086, 0.1086, 0.1084,\n",
      "        0.1086, 0.1081, 0.1085, 0.1085, 0.1086, 0.1086, 0.1086, 0.1086, 0.1085,\n",
      "        0.1086, 0.1071, 0.1085, 0.1086, 0.1084, 0.1086, 0.1082, 0.1081, 0.1086,\n",
      "        0.1087, 0.1086, 0.1086, 0.1086, 0.1086], device='cuda:0')\n",
      "tensor([ 0.8941, -1.1424,  1.0119,  1.0151,  0.9464,  0.3535,  0.6478,  0.7722,\n",
      "         0.9566,  0.6028,  0.9882,  0.9959,  0.9551,  0.7787,  0.7418, -1.2296,\n",
      "         0.5335,  0.9469,  0.7339,  0.9202,  0.8570,  0.1033, -1.2231,  0.7322,\n",
      "         0.9365,  0.9692,  0.7486, -1.0616,  0.2507,  0.6993,  0.7726, -1.2793],\n",
      "       device='cuda:0')\n",
      "tensor([0.1081, 0.1086, 0.1086, 0.1086, 0.1081, 0.1079, 0.1085, 0.1081, 0.1083,\n",
      "        0.1080, 0.1086, 0.1086, 0.1079, 0.1086, 0.1086, 0.1082, 0.1086, 0.1081,\n",
      "        0.1087, 0.1085, 0.1086, 0.1005, 0.1082, 0.1080, 0.1081, 0.1081, 0.1085,\n",
      "        0.1086, 0.1076, 0.1085, 0.1062, 0.1086], device='cuda:0')\n",
      "tensor([ 0.9548,  0.7862, -1.2070,  0.2340,  0.9574,  0.9309,  0.7423,  0.7261,\n",
      "         1.0623,  0.9503,  0.9682,  0.8070,  0.7451,  0.5454, -1.2141,  0.9661,\n",
      "         0.7879,  0.6471, -1.4137, -0.6016,  0.7437,  0.9687,  0.7551,  0.9718,\n",
      "         0.2641,  0.7794, -0.9960,  0.7215,  1.0797,  0.6871,  1.1046,  0.7934],\n",
      "       device='cuda:0')\n",
      "tensor([0.1086, 0.1083, 0.1084, 0.1086, 0.1085, 0.1086, 0.1086, 0.1086, 0.1086,\n",
      "        0.1086, 0.1086, 0.1086, 0.1080, 0.1079, 0.1086, 0.1086, 0.1083, 0.1086,\n",
      "        0.1085, 0.1085, 0.1086, 0.1083, 0.1080, 0.1086, 0.1086, 0.1081, 0.1085,\n",
      "        0.1085, 0.1086, 0.1081, 0.1082, 0.1085], device='cuda:0')\n",
      "tensor([ 0.3556,  0.6147,  0.8769, -1.2371, -1.4853,  0.7548, -1.4719,  0.7842,\n",
      "         0.1888,  0.6984, -1.2121,  0.8696,  0.9961,  0.9640,  0.7418, -1.0630,\n",
      "         0.9458,  0.9473, -1.4531,  0.9031,  0.7642, -1.2414,  0.9898, -1.0278,\n",
      "         0.7207,  0.9336,  0.8449,  0.6015,  0.6042,  0.9334,  0.9606, -1.4883],\n",
      "       device='cuda:0')\n",
      "tensor([0.1081, 0.1079, 0.1086, 0.1083, 0.1086, 0.1086, 0.1086, 0.1086, 0.1086,\n",
      "        0.1077, 0.1086, 0.1084, 0.1086, 0.1086, 0.1080, 0.1086, 0.1087, 0.1085,\n",
      "        0.1086, 0.1080, 0.1086, 0.1080, 0.1084, 0.1086, 0.1085, 0.1086, 0.1086,\n",
      "        0.1087, 0.1086, 0.1086, 0.1081, 0.1082], device='cuda:0')\n",
      "tensor([ 0.6505,  0.9814,  0.6823,  0.9581, -1.1787, -1.2293, -0.0251, -1.6926,\n",
      "         0.7502,  1.0677,  0.7398,  0.3393,  0.6601, -1.0509,  1.0132, -1.2288,\n",
      "         0.8235,  0.7453, -1.3473,  1.0112,  0.7907,  0.9872,  1.1922,  0.7271,\n",
      "        -1.1964,  0.7172,  0.8286, -1.2457, -1.4426,  0.6167,  0.5858,  0.9598],\n",
      "       device='cuda:0')\n",
      "tensor([0.1086, 0.1086, 0.1086, 0.1086, 0.1081, 0.1079, 0.1086, 0.1085, 0.1083,\n",
      "        0.1081, 0.1086, 0.1079, 0.1083, 0.1086, 0.1087, 0.1085, 0.1084, 0.1086,\n",
      "        0.1083, 0.1085, 0.1086, 0.1086, 0.1085, 0.1086, 0.1085, 0.1086, 0.1086,\n",
      "        0.1086, 0.1078, 0.1086, 0.1086, 0.1086], device='cuda:0')\n",
      "tensor([-1.1878,  0.8381,  0.0441,  0.9300,  0.9876,  1.0378,  0.7070,  0.4582,\n",
      "         0.9701,  0.8085, -1.1934,  1.0563,  0.8464, -1.0064,  0.7595,  0.9972,\n",
      "        -1.1213,  0.7019,  1.0211,  0.9297,  0.8826,  0.4042,  0.9660, -0.2098,\n",
      "         0.9042,  1.0842,  0.3829,  0.8033,  0.9050,  0.1609,  0.7209, -0.5288],\n",
      "       device='cuda:0')\n",
      "tensor([0.1081, 0.1084, 0.1084, 0.1080, 0.1085, 0.1086, 0.1084, 0.1086, 0.1082,\n",
      "        0.1084, 0.1086, 0.1084, 0.1086, 0.1085, 0.1084, 0.1086, 0.1076, 0.1085,\n",
      "        0.1087, 0.1078, 0.1084, 0.1086, 0.1082, 0.1086, 0.1086, 0.1084, 0.1087,\n",
      "        0.1085, 0.1084, 0.1087, 0.1084, 0.1084], device='cuda:0')\n",
      "tensor([ 0.9983,  0.8891,  0.8195,  0.9146,  0.7747, -0.8021,  1.0602,  0.5788,\n",
      "         0.9117,  0.8975, -1.0770,  1.0351,  0.1635,  0.7876,  0.6308,  0.8261,\n",
      "         0.8331, -1.1300,  0.8261,  0.9779,  1.0775,  0.7460,  0.9649,  0.6418,\n",
      "         0.8002,  1.1017, -1.3876,  0.6938,  0.9306,  0.8251,  1.0163,  0.9350],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "distr, outpreds = evaluate(model, loss_function, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0537e55-e01a-48a6-8c0a-2a2b7a354a20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 13.,  47., 119., 112.,  97.,  66.,  29.,  14.,   2.,   1.]),\n",
       " array([0.51490718, 0.58987415, 0.66484113, 0.7398081 , 0.81477507,\n",
       "        0.88974205, 0.96470902, 1.03967599, 1.11464297, 1.18960994,\n",
       "        1.26457691]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(distr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809264e6-8b37-4189-a2ca-49351d3acdd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
