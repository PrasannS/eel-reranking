{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddb8bb0-6340-4f6e-b04e-4d6181895de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "hfcache = '/mnt/data1/prasann/latticegen/lattice-generation/hfcache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = hfcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbef25d-0a8f-459d-af90-e58fef8f78fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reverse_meaning_data.txt',\n",
       " 'reverse_sent_data.txt',\n",
       " 'summdoc_data.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'formal_hand_data.txt',\n",
       " 'simplification_data.txt',\n",
       " 'infilling_data.txt',\n",
       " 'informal_data.txt',\n",
       " 'easy_hand_data.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./T0_explore_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c54ce56-fd13-4b5e-9baf-c87d01a5fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\", cache_dir=hfcache)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\", cache_dir=hfcache)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43107a4-a304-41fe-b882-388739b3ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = './T0_explore_data/'\n",
    "\n",
    "def read_input_data (fname):\n",
    "    with open(BASE+fname+\".txt\") as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "    while(\"\" in lines) :\n",
    "        lines.remove(\"\")\n",
    "    \n",
    "    return lines\n",
    "\n",
    "infill_data = read_input_data('infilling_data')\n",
    "informal_data = read_input_data('informal_data')\n",
    "revmean_data = read_input_data('reverse_meaning_data')\n",
    "revsent_data = read_input_data('reverse_sent_data')\n",
    "simplif_data = read_input_data('simplification_data')\n",
    "easy_data = read_input_data('easy_hand_data')\n",
    "summ_data = read_input_data('summdoc_data')\n",
    "formalhand_data = read_input_data('formal_hand_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad13428-71ee-48b2-b692-e349ecb0a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_prompts = [\n",
    "    \"Task: Copy the sentence but replace _ with the correct words. [TEXT]\",\n",
    "    \"Task: replace _ with the correct words. [TEXT]\",\n",
    "    \"[TEXT] What goes in the _ ?\",\n",
    "    \"Task: Fill in the _ in the following sentence. [TEXT]\",\n",
    "]\n",
    "\n",
    "sent_prompts = [\n",
    "    \"Task: what's the opposite of this sentence? [TEXT]\",\n",
    "    \"Copy but say the opposite: [TEXT]\",\n",
    "    \"[TEXT] What is the opposite of this sentence?\",\n",
    "    \"Task: copy but say the opposite emotion. [TEXT]\",\n",
    "    \"Task: copy but say the opposite. [TEXT]\", #\n",
    "]\n",
    "\n",
    "simplif_prompt = [\n",
    "    \"[TEXT] How would I say this in simple words?\",\n",
    "    \"Task: Paraphrase in simpler terms. [TEXT]\",\n",
    "    \"Task: Copy but simplify. [TEXT]\",\n",
    "    \"Task: Simplify the sentence. [TEXT]\"\n",
    "]\n",
    "\n",
    "summ_prompt = [\n",
    "    \"Task: summarize the following paragraph. [TEXT]\",\n",
    "    \"How can I summarize the following? [TEXT]\",\n",
    "]\n",
    "\n",
    "formal_prompt = [\n",
    "    \"Task: How can I say this with more formal language? [TEXT]\",\n",
    "    \"Task: Copy but use formal words. [TEXT]\",\n",
    "    \"[TEXT] How can I rephrase this formally?\",\n",
    "    \"[TEXT] What is a formal way of saying this?\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5024c684-e496-4055-80f0-949c12342ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_T0_output(prompt, raw):\n",
    "    inputstring = get_inputstr(prompt, raw)\n",
    "    inputs = tokenizer.encode(inputstring, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs, max_length=50, num_beams=9, num_return_sequences=9, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    res = []\n",
    "    #print(outputs)\n",
    "    for i in range(0, len(outputs.sequences)):\n",
    "        tmp = {}\n",
    "        tmp['out_toks'] = tokenizer.decode(outputs.sequences[i])\n",
    "        tmp['out_sco'] = outputs.sequences_scores[i]\n",
    "        res.append(tmp)\n",
    "        print(tmp)\n",
    "    out = {}\n",
    "    out['data'] = res\n",
    "    out['input'] = inputstring\n",
    "    return out\n",
    "        \n",
    "def get_inputstr(prompt, raw):\n",
    "    return prompt.replace(\"[TEXT]\", raw)\n",
    "\n",
    "alldat = []\n",
    "\n",
    "def run_all_data (promptlist, data, label):\n",
    "    global alldat\n",
    "    alldata = []\n",
    "    for p in promptlist:\n",
    "        curtmp = {}\n",
    "        curtmp['prompt'] = p\n",
    "        curtmp['examples'] = []\n",
    "        for d in data:\n",
    "            curtmp['examples'].append(get_T0_output(p, d))\n",
    "        alldata.append(curtmp)\n",
    "    alldat = alldata\n",
    "    for a in alldata:\n",
    "        for e in a['examples']:\n",
    "            for d in e['data']:\n",
    "                d['out_sco'] = float(d['out_sco'])\n",
    "    alldatajson = {}\n",
    "    alldatajson['data'] = alldata\n",
    "    with open('./prompt_output/'+label+'.txt', 'w') as f:\n",
    "        json.dump(alldatajson, f, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5a5b6cd-85ee-45ad-be71-bd92ac2ae98b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'out_toks': '<pad> It was a most grueling endeavour.</s>', 'out_sco': tensor(-0.5475, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling undertaking.</s>', 'out_sco': tensor(-0.5571, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavor.</s>', 'out_sco': tensor(-0.5611, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a grueling endeavour.</s><pad>', 'out_sco': tensor(-0.6841, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a grueling endeavor.</s><pad>', 'out_sco': tensor(-0.6927, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most gruelling endeavour.</s>', 'out_sco': tensor(-0.6949, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a grueling undertaking.</s><pad>', 'out_sco': tensor(-0.6972, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most gruelling endeavor.</s>', 'out_sco': tensor(-0.7091, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most gruelling undertaking.</s>', 'out_sco': tensor(-0.7195, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn.</s>', 'out_sco': tensor(-0.3216, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn</s><pad>', 'out_sco': tensor(-0.4925, device='cuda:0')}\n",
      "{'out_toks': '<pad> She had left me forlorn.</s><pad><pad><pad>', 'out_sco': tensor(-0.6382, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s><pad>', 'out_sco': tensor(-0.7440, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left her forlorn.</s>', 'out_sco': tensor(-0.8164, device='cuda:0')}\n",
      "{'out_toks': '<pad> She had left me forlorn.</s><pad><pad>', 'out_sco': tensor(-0.8843, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn...</s>', 'out_sco': tensor(-0.9182, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn</s><pad><pad>', 'out_sco': tensor(-0.9271, device='cuda:0')}\n",
      "{'out_toks': '<pad> She had left me forlorn</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.9752, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking</s><pad><pad><pad>', 'out_sco': tensor(-0.7448, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking.</s><pad><pad>', 'out_sco': tensor(-0.8625, device='cuda:0')}\n",
      "{'out_toks': '<pad> the substance was lacking</s><pad><pad><pad>', 'out_sco': tensor(-1.0148, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking.</s><pad>', 'out_sco': tensor(-1.0363, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance of the article was lacking</s>', 'out_sco': tensor(-1.0608, device='cuda:0')}\n",
      "{'out_toks': '<pad> There was no substance in it.</s>', 'out_sco': tensor(-1.2184, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking in the presentation</s>', 'out_sco': tensor(-1.2395, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance is lacking</s><pad><pad><pad>', 'out_sco': tensor(-1.3082, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking in the article</s>', 'out_sco': tensor(-1.3095, device='cuda:0')}\n",
      "{'out_toks': '<pad> to persist or to vanish ephemerally</s>', 'out_sco': tensor(-0.4010, device='cuda:0')}\n",
      "{'out_toks': '<pad> To persist or to vanish ephemerally</s>', 'out_sco': tensor(-0.4709, device='cuda:0')}\n",
      "{'out_toks': '<pad> vanish ephemerally</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.4991, device='cuda:0')}\n",
      "{'out_toks': '<pad> to vanish ephemerally</s><pad><pad><pad>', 'out_sco': tensor(-0.5280, device='cuda:0')}\n",
      "{'out_toks': '<pad> To persist or not to persist, that is the question</s><pad>', 'out_sco': tensor(-0.6194, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist or to vanish</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.6438, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist or to vanish is the question</s><pad>', 'out_sco': tensor(-0.6464, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist</s><pad><pad><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-1.2152, device='cuda:0')}\n",
      "{'out_toks': '<pad> to persist</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-1.3869, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.1679, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.3289, device='cuda:0')}\n",
      "{'out_toks': '<pad> The Wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.3672, device='cuda:0')}\n",
      "{'out_toks': '<pad> He whittled the wood wisely.</s><pad><pad>', 'out_sco': tensor(-0.4264, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittles the wood wisely.</s>', 'out_sco': tensor(-0.4285, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled the wood wisely</s><pad>', 'out_sco': tensor(-0.4377, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood.</s>', 'out_sco': tensor(-0.4415, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood</s><pad>', 'out_sco': tensor(-0.5169, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wood was whittled wisely.</s><pad><pad>', 'out_sco': tensor(-0.5261, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling endeavour.</s>', 'out_sco': tensor(-0.2688, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling endeavor.</s>', 'out_sco': tensor(-0.3430, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling undertaking.</s>', 'out_sco': tensor(-0.3794, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most gruelling endeavour.</s>', 'out_sco': tensor(-0.4050, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most gruelling endeavor.</s>', 'out_sco': tensor(-0.4827, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavour.</s><pad>', 'out_sco': tensor(-0.5123, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most gruelling undertaking.</s>', 'out_sco': tensor(-0.5298, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavor.</s><pad>', 'out_sco': tensor(-0.5612, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling undertaking.</s><pad>', 'out_sco': tensor(-0.5750, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn.</s>', 'out_sco': tensor(-0.2457, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s>', 'out_sco': tensor(-0.3956, device='cuda:0')}\n",
      "{'out_toks': '<pad> The grievances had left me forlorn.</s>', 'out_sco': tensor(-0.4196, device='cuda:0')}\n",
      "{'out_toks': '<pad> My grievances had left me forlorn.</s>', 'out_sco': tensor(-0.4272, device='cuda:0')}\n",
      "{'out_toks': '<pad> She had left me forlorn.</s><pad><pad><pad>', 'out_sco': tensor(-0.4820, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s><pad>', 'out_sco': tensor(-0.5008, device='cuda:0')}\n",
      "{'out_toks': '<pad> She had left me forlorn.</s><pad><pad>', 'out_sco': tensor(-0.5599, device='cuda:0')}\n",
      "{'out_toks': '<pad> Grief had left me forlorn.</s><pad><pad>', 'out_sco': tensor(-0.6175, device='cuda:0')}\n",
      "{'out_toks': '<pad> She left me forlorn.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.6492, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking.</s><pad><pad><pad>', 'out_sco': tensor(-0.5282, device='cuda:0')}\n",
      "{'out_toks': '<pad> Task: Paraphrase in simpler terms.</s>', 'out_sco': tensor(-0.5587, device='cuda:0')}\n",
      "{'out_toks': '<pad> The conclusion was that the substance was lacking</s>', 'out_sco': tensor(-0.6874, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance of the article was lacking.</s>', 'out_sco': tensor(-0.7634, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking.</s><pad><pad>', 'out_sco': tensor(-0.7792, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.8304, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance of the article was lacking</s><pad>', 'out_sco': tensor(-0.9498, device='cuda:0')}\n",
      "{'out_toks': '<pad> Task: Paraphrase in simpler terms</s><pad>', 'out_sco': tensor(-1.0215, device='cuda:0')}\n",
      "{'out_toks': '<pad> Insufficient substance</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-1.2213, device='cuda:0')}\n",
      "{'out_toks': '<pad> To persist or to vanish ephemerally, that is the question</s>', 'out_sco': tensor(-0.3026, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist or to vanish ephemerally</s><pad><pad><pad>', 'out_sco': tensor(-0.3156, device='cuda:0')}\n",
      "{'out_toks': '<pad> The question is whether to persist or to vanish ephemerally.</s>', 'out_sco': tensor(-0.3612, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist or to vanish ephemerally is the question</s>', 'out_sco': tensor(-0.3669, device='cuda:0')}\n",
      "{'out_toks': '<pad> To persist or to vanish ephemerally?</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.5455, device='cuda:0')}\n",
      "{'out_toks': '<pad> To persist or not to persist, that is the question.</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.5654, device='cuda:0')}\n",
      "{'out_toks': '<pad> To persist or not to persist, that is the question</s><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.6302, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist or to vanish</s><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.7323, device='cuda:0')}\n",
      "{'out_toks': '<pad> ephemeral</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.9093, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.0881, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood.</s>', 'out_sco': tensor(-0.2045, device='cuda:0')}\n",
      "{'out_toks': '<pad> The Wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.2847, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.3279, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood</s><pad>', 'out_sco': tensor(-0.4003, device='cuda:0')}\n",
      "{'out_toks': '<pad> The Wanderer wisely whittled the wood.</s>', 'out_sco': tensor(-0.4011, device='cuda:0')}\n",
      "{'out_toks': '<pad> He whittled the wood wisely.</s><pad><pad>', 'out_sco': tensor(-0.4038, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittles the wood wisely.</s>', 'out_sco': tensor(-0.4299, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wood was whittled wisely.</s><pad><pad>', 'out_sco': tensor(-0.5329, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavour.</s>', 'out_sco': tensor(-0.6644, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavor.</s>', 'out_sco': tensor(-0.7191, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling undertaking.</s>', 'out_sco': tensor(-0.7264, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most gruelling endeavour.</s>', 'out_sco': tensor(-0.7562, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most gruelling endeavor.</s>', 'out_sco': tensor(-0.8126, device='cuda:0')}\n",
      "{'out_toks': '<pad> The task was to copy but simplify.</s><pad><pad><pad>', 'out_sco': tensor(-0.8252, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most gruelling undertaking.</s>', 'out_sco': tensor(-0.8297, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a grueling endeavour.</s><pad>', 'out_sco': tensor(-0.8963, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a grueling undertaking.</s><pad>', 'out_sco': tensor(-0.9308, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn.</s><pad>', 'out_sco': tensor(-0.2214, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn.</s>', 'out_sco': tensor(-0.2528, device='cuda:0')}\n",
      "{'out_toks': '<pad> The grievances had left me forlorn.</s><pad>', 'out_sco': tensor(-0.4217, device='cuda:0')}\n",
      "{'out_toks': '<pad> The grievances had left me forlorn.</s>', 'out_sco': tensor(-0.4768, device='cuda:0')}\n",
      "{'out_toks': '<pad> She had left me forlorn.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.5186, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn</s><pad><pad>', 'out_sco': tensor(-0.5399, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s><pad>', 'out_sco': tensor(-0.5868, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s><pad><pad>', 'out_sco': tensor(-0.6006, device='cuda:0')}\n",
      "{'out_toks': '<pad> Grief had left me forlorn.</s><pad><pad><pad>', 'out_sco': tensor(-0.6019, device='cuda:0')}\n",
      "{'out_toks': '<pad> The task was to copy but simplify</s>', 'out_sco': tensor(-0.7031, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking.</s><pad><pad>', 'out_sco': tensor(-0.7253, device='cuda:0')}\n",
      "{'out_toks': '<pad> The task was copy but simplify.</s>', 'out_sco': tensor(-0.8953, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance was lacking</s><pad><pad><pad>', 'out_sco': tensor(-0.9282, device='cuda:0')}\n",
      "{'out_toks': '<pad> The task was copy but simplify</s><pad>', 'out_sco': tensor(-1.0479, device='cuda:0')}\n",
      "{'out_toks': '<pad> The substance of the article was lacking</s>', 'out_sco': tensor(-1.1923, device='cuda:0')}\n",
      "{'out_toks': '<pad> Insufficient information</s><pad><pad><pad><pad>', 'out_sco': tensor(-1.3056, device='cuda:0')}\n",
      "{'out_toks': '<pad> The subject was too complicated</s><pad><pad>', 'out_sco': tensor(-1.4007, device='cuda:0')}\n",
      "{'out_toks': '<pad> There was no substance</s><pad><pad><pad>', 'out_sco': tensor(-1.5002, device='cuda:0')}\n",
      "{'out_toks': '<pad> ephemeral</s>', 'out_sco': tensor(-0.5853, device='cuda:0')}\n",
      "{'out_toks': '<pad> ephemerally</s>', 'out_sco': tensor(-0.7573, device='cuda:0')}\n",
      "{'out_toks': '<pad> ephemerality</s>', 'out_sco': tensor(-0.7581, device='cuda:0')}\n",
      "{'out_toks': '<pad> ephemera</s>', 'out_sco': tensor(-0.8875, device='cuda:0')}\n",
      "{'out_toks': '<pad> copy but simplify</s><pad><pad><pad>', 'out_sco': tensor(-0.9498, device='cuda:0')}\n",
      "{'out_toks': '<pad> the question is whether to persist</s>', 'out_sco': tensor(-1.0471, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist</s><pad><pad>', 'out_sco': tensor(-1.0681, device='cuda:0')}\n",
      "{'out_toks': '<pad> emerald</s><pad>', 'out_sco': tensor(-1.1899, device='cuda:0')}\n",
      "{'out_toks': '<pad> to persist</s><pad><pad><pad><pad>', 'out_sco': tensor(-1.7927, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled the wood wisely.</s><pad>', 'out_sco': tensor(-0.1146, device='cuda:0')}\n",
      "{'out_toks': '<pad> The Wanderer whittled the wood wisely.</s><pad>', 'out_sco': tensor(-0.2878, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittled the wood wisely.</s><pad>', 'out_sco': tensor(-0.3769, device='cuda:0')}\n",
      "{'out_toks': '<pad> He whittled the wood wisely.</s><pad><pad><pad>', 'out_sco': tensor(-0.3860, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittles the wood wisely.</s><pad>', 'out_sco': tensor(-0.3864, device='cuda:0')}\n",
      "{'out_toks': '<pad> The woodsman whittled the wood wisely.</s>', 'out_sco': tensor(-0.3976, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood.</s><pad>', 'out_sco': tensor(-0.4133, device='cuda:0')}\n",
      "{'out_toks': '<pad> The woodcutter whittled the wood wisely.</s>', 'out_sco': tensor(-0.4144, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.4720, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling endeavor.</s>', 'out_sco': tensor(-0.2309, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling endeavour.</s>', 'out_sco': tensor(-0.2360, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling endeavor.</s><pad>', 'out_sco': tensor(-0.2794, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling endeavour.</s><pad>', 'out_sco': tensor(-0.2980, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling undertaking.</s>', 'out_sco': tensor(-0.3154, device='cuda:0')}\n",
      "{'out_toks': '<pad> Tis was a most grueling undertaking.</s><pad>', 'out_sco': tensor(-0.3691, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavor.</s><pad>', 'out_sco': tensor(-0.4044, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavour.</s><pad>', 'out_sco': tensor(-0.4083, device='cuda:0')}\n",
      "{'out_toks': '<pad> It was a most grueling endeavor.</s><pad><pad>', 'out_sco': tensor(-0.4143, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn.</s>', 'out_sco': tensor(-0.1445, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances had left me forlorn.</s><pad>', 'out_sco': tensor(-0.2719, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s><pad>', 'out_sco': tensor(-0.2780, device='cuda:0')}\n",
      "{'out_toks': '<pad> The grievances had left me forlorn.</s>', 'out_sco': tensor(-0.3402, device='cuda:0')}\n",
      "{'out_toks': '<pad> My grievances had left me forlorn.</s>', 'out_sco': tensor(-0.3613, device='cuda:0')}\n",
      "{'out_toks': '<pad> Griefs had left me forlorn.</s><pad>', 'out_sco': tensor(-0.4059, device='cuda:0')}\n",
      "{'out_toks': '<pad> Grief had left me forlorn.</s><pad><pad>', 'out_sco': tensor(-0.4243, device='cuda:0')}\n",
      "{'out_toks': '<pad> Her grievances left me forlorn.</s><pad><pad>', 'out_sco': tensor(-0.4310, device='cuda:0')}\n",
      "{'out_toks': '<pad> The grievances had left me forlorn.</s><pad>', 'out_sco': tensor(-0.4566, device='cuda:0')}\n",
      "{'out_toks': '<pad> The indubitable conclusion was that the substance was lacking.</s>', 'out_sco': tensor(-0.0830, device='cuda:0')}\n",
      "{'out_toks': '<pad> The indisputable conclusion was that the substance was lacking.</s>', 'out_sco': tensor(-0.2443, device='cuda:0')}\n",
      "{'out_toks': '<pad> The indubitable conclusion was that substance was lacking.</s><pad>', 'out_sco': tensor(-0.2482, device='cuda:0')}\n",
      "{'out_toks': '<pad> The conclusion was that the substance was lacking.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.2850, device='cuda:0')}\n",
      "{'out_toks': '<pad> the indubitable conclusion was that the substance was lacking.</s>', 'out_sco': tensor(-0.3073, device='cuda:0')}\n",
      "{'out_toks': '<pad> The indubitable conclusion was that the substance was lacking.</s><pad>', 'out_sco': tensor(-0.3250, device='cuda:0')}\n",
      "{'out_toks': '<pad> The indubitable conclusion is that the substance was lacking.</s>', 'out_sco': tensor(-0.3396, device='cuda:0')}\n",
      "{'out_toks': '<pad> indubitable conclusion was that the substance was lacking.</s><pad>', 'out_sco': tensor(-0.3407, device='cuda:0')}\n",
      "{'out_toks': '<pad> Indubitable conclusion was that the substance was lacking.</s><pad>', 'out_sco': tensor(-0.3460, device='cuda:0')}\n",
      "{'out_toks': '<pad> vanish ephemerally, that is the question</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.2348, device='cuda:0')}\n",
      "{'out_toks': '<pad> vanish ephemerally, that is the question.</s><pad><pad><pad>', 'out_sco': tensor(-0.2509, device='cuda:0')}\n",
      "{'out_toks': '<pad> to persist or to vanish ephemerally, that is the question</s><pad>', 'out_sco': tensor(-0.2982, device='cuda:0')}\n",
      "{'out_toks': '<pad> Whether to persist or vanish ephemerally, that is the question</s>', 'out_sco': tensor(-0.2995, device='cuda:0')}\n",
      "{'out_toks': '<pad> Vanishing ephemerally, that is the question.</s><pad><pad>', 'out_sco': tensor(-0.3271, device='cuda:0')}\n",
      "{'out_toks': '<pad> vanish, ephemerally, that is the question</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.3364, device='cuda:0')}\n",
      "{'out_toks': '<pad> vanish, ephemeral, persist</s><pad><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.4175, device='cuda:0')}\n",
      "{'out_toks': '<pad> to persist or to vanish ephemerally</s><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.5096, device='cuda:0')}\n",
      "{'out_toks': '<pad> vanish ephemerally or persist</s><pad><pad><pad><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.5198, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.1097, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood.</s>', 'out_sco': tensor(-0.1852, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer wisely whittled the wood</s><pad>', 'out_sco': tensor(-0.2822, device='cuda:0')}\n",
      "{'out_toks': '<pad> The Wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.2887, device='cuda:0')}\n",
      "{'out_toks': '<pad> A wanderer whittled the wood wisely.</s>', 'out_sco': tensor(-0.3462, device='cuda:0')}\n",
      "{'out_toks': '<pad> The Wanderer wisely whittled the wood.</s>', 'out_sco': tensor(-0.3618, device='cuda:0')}\n",
      "{'out_toks': '<pad> He whittled the wood wisely.</s><pad><pad>', 'out_sco': tensor(-0.3750, device='cuda:0')}\n",
      "{'out_toks': '<pad> The wanderer whittled wood wisely.</s><pad>', 'out_sco': tensor(-0.4382, device='cuda:0')}\n",
      "{'out_toks': '<pad> Wanderer wisely whittled the wood</s><pad><pad>', 'out_sco': tensor(-0.5274, device='cuda:0')}\n"
     ]
    }
   ],
   "source": [
    "run_all_data(simplif_prompt, formalhand_data, 'simplifhand_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0a0ebd-9a0d-4b31-859d-f3415ab98dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Paraphrase with shakespeare language. The rabbit saw the monkey.\n",
      "{'out_toks': '<pad> The rabbit saw the monkey.</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.2448, device='cuda:0')}\n",
      "{'out_toks': '<pad> The monkey saw the rabbit.</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.2870, device='cuda:0')}\n",
      "{'out_toks': '<pad> The rabbit saw a monkey.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.4586, device='cuda:0')}\n",
      "{'out_toks': '<pad> The rabbit sees the monkey.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.4696, device='cuda:0')}\n",
      "{'out_toks': '<pad> The monkey sees the rabbit.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.5002, device='cuda:0')}\n",
      "{'out_toks': '<pad> A monkey sees a rabbit.</s><pad><pad><pad>', 'out_sco': tensor(-0.6229, device='cuda:0')}\n",
      "{'out_toks': '<pad> A monkey sees a rabbit in the forest.</s>', 'out_sco': tensor(-0.8220, device='cuda:0')}\n",
      "{'out_toks': '<pad> A monkey sees a rabbit and runs away.</s>', 'out_sco': tensor(-0.8323, device='cuda:0')}\n",
      "{'out_toks': '<pad> A monkey and a rabbit are watching each other.</s>', 'out_sco': tensor(-0.8357, device='cuda:0')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': [{'out_toks': '<pad> The rabbit saw the monkey.</s><pad><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.2448, device='cuda:0')},\n",
       "  {'out_toks': '<pad> The monkey saw the rabbit.</s><pad><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.2870, device='cuda:0')},\n",
       "  {'out_toks': '<pad> The rabbit saw a monkey.</s><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.4586, device='cuda:0')},\n",
       "  {'out_toks': '<pad> The rabbit sees the monkey.</s><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.4696, device='cuda:0')},\n",
       "  {'out_toks': '<pad> The monkey sees the rabbit.</s><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.5002, device='cuda:0')},\n",
       "  {'out_toks': '<pad> A monkey sees a rabbit.</s><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.6229, device='cuda:0')},\n",
       "  {'out_toks': '<pad> A monkey sees a rabbit in the forest.</s>',\n",
       "   'out_sco': tensor(-0.8220, device='cuda:0')},\n",
       "  {'out_toks': '<pad> A monkey sees a rabbit and runs away.</s>',\n",
       "   'out_sco': tensor(-0.8323, device='cuda:0')},\n",
       "  {'out_toks': '<pad> A monkey and a rabbit are watching each other.</s>',\n",
       "   'out_sco': tensor(-0.8357, device='cuda:0')}],\n",
       " 'input': 'Task: Paraphrase with shakespeare language. The rabbit saw the monkey.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krishna_prompt = [\n",
    "    \"Task: How would shakespeare say this? [TEXT]\",\n",
    "    \"Task: Paraphrase with shakespeare language. [TEXT]\",\n",
    "    \"Task: Copy but make it sound like a tweet. [TEXT]\",\n",
    "]\n",
    "\n",
    "prompt = krishna_prompt[1]\n",
    "inp = easy_data[12]\n",
    "inputstr = get_inputstr(prompt, inp)\n",
    "print(inputstr)\n",
    "get_T0_output(prompt, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09cec981-3855-4125-8b9a-041646e45eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> The dry sand was hard to grasp.</s><pad>\n",
      "tensor(-0.1610)\n",
      "<pad> The wet sand was hard to grasp.</s>\n",
      "tensor(-0.2598)\n",
      "<pad> The wet sand was easy to grasp.</s>\n",
      "tensor(-0.2707)\n",
      "<pad> The sand was hard to grasp.</s><pad><pad>\n",
      "tensor(-0.3358)\n",
      "<pad> The dry sand was difficult to grasp.</s><pad>\n",
      "tensor(-0.4160)\n"
     ]
    }
   ],
   "source": [
    "#print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a587b82a-ba20-417c-a339-4fba614b6241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72717c185c7c42a7b6019a0a39f7ef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/836 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a841e7f91c294bb395e1ff534b6b0850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/11.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89db479fadce4333b9c3b57fc6065c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b909f73964169ab4114bfc18b2402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae98c709681148d4accb336e74417939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612d96964a5646e3835525c65281184c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea03cf369ebd4b58b5f0d9a191669e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bab021a7804f00a07e311e1fc53731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\", cache_dir=hfcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "744731f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "\"LayerNormKernelImpl\" not implemented for 'Half'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m prompt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn a shocking finding, scientists discovered a herd of unicorns living in a remote, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreviously unexplored valley, in the Andes Mountains. Even more surprising to the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearchers was the fact that the unicorns spoke perfect English.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m input_ids \u001b[38;5;241m=\u001b[39m tokenizer(prompt, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39minput_ids\n\u001b[0;32m----> 7\u001b[0m gen_tokens \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.9\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/autograd/grad_mode.py:28\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m():\n\u001b[0;32m---> 28\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/generation_utils.py:1033\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, input_ids, max_length, min_length, do_sample, early_stopping, num_beams, temperature, top_k, top_p, repetition_penalty, bad_words_ids, bos_token_id, pad_token_id, eos_token_id, length_penalty, no_repeat_ngram_size, encoder_no_repeat_ngram_size, num_return_sequences, max_time, max_new_tokens, decoder_start_token_id, use_cache, num_beam_groups, diversity_penalty, prefix_allowed_tokens_fn, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, forced_bos_token_id, forced_eos_token_id, remove_invalid_values, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1025\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1026\u001b[0m         input_ids,\n\u001b[1;32m   1027\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mnum_return_sequences,\n\u001b[1;32m   1028\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1029\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1030\u001b[0m     )\n\u001b[1;32m   1032\u001b[0m     \u001b[38;5;66;03m# sample\u001b[39;00m\n\u001b[0;32m-> 1033\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1034\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1036\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlogits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1037\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1038\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1039\u001b[0m \u001b[43m        \u001b[49m\u001b[43meos_token_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meos_token_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1040\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_scores\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_scores\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1041\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict_in_generate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1042\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1043\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1044\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_beam_gen_mode:\n\u001b[1;32m   1047\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/generation_utils.py:1547\u001b[0m, in \u001b[0;36mGenerationMixin.sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, logits_warper, max_length, pad_token_id, eos_token_id, output_attentions, output_hidden_states, output_scores, return_dict_in_generate, synced_gpus, **model_kwargs)\u001b[0m\n\u001b[1;32m   1544\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   1546\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 1547\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1548\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1549\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1550\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1551\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1552\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1554\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   1555\u001b[0m     cur_len \u001b[38;5;241m=\u001b[39m cur_len \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:782\u001b[0m, in \u001b[0;36mGPTJForCausalLM.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    774\u001b[0m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    775\u001b[0m \u001b[38;5;124;03mlabels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`):\u001b[39;00m\n\u001b[1;32m    776\u001b[0m \u001b[38;5;124;03m    Labels for language modeling. Note that the labels **are shifted** inside the model, i.e. you can set\u001b[39;00m\n\u001b[1;32m    777\u001b[0m \u001b[38;5;124;03m    ``labels = input_ids`` Indices are selected in ``[-100, 0, ..., config.vocab_size]`` All labels set to\u001b[39;00m\n\u001b[1;32m    778\u001b[0m \u001b[38;5;124;03m    ``-100`` are ignored (masked), the loss is only computed for labels in ``[0, ..., config.vocab_size]``\u001b[39;00m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    780\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m--> 782\u001b[0m transformer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    786\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    793\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    794\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    795\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m transformer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    797\u001b[0m \u001b[38;5;66;03m# Set device for model parallelism\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:636\u001b[0m, in \u001b[0;36mGPTJModel.forward\u001b[0;34m(self, input_ids, past_key_values, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    628\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    629\u001b[0m         create_custom_forward(block),\n\u001b[1;32m    630\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    633\u001b[0m         head_mask[i],\n\u001b[1;32m    634\u001b[0m     )\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 636\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    637\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_past\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_past\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    640\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    641\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    642\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    643\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    645\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/gptj/modeling_gptj.py:279\u001b[0m, in \u001b[0;36mGPTJBlock.forward\u001b[0;34m(self, hidden_states, layer_past, attention_mask, head_mask, use_cache, output_attentions)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    271\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    277\u001b[0m ):\n\u001b[1;32m    278\u001b[0m     residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[0;32m--> 279\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     attn_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattn(\n\u001b[1;32m    281\u001b[0m         hidden_states,\n\u001b[1;32m    282\u001b[0m         layer_past\u001b[38;5;241m=\u001b[39mlayer_past,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    286\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    287\u001b[0m     )\n\u001b[1;32m    288\u001b[0m     attn_output \u001b[38;5;241m=\u001b[39m attn_outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# output_attn: a, present, (attentions)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/normalization.py:189\u001b[0m, in \u001b[0;36mLayerNorm.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/functional.py:2347\u001b[0m, in \u001b[0;36mlayer_norm\u001b[0;34m(input, normalized_shape, weight, bias, eps)\u001b[0m\n\u001b[1;32m   2343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[1;32m   2344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m   2345\u001b[0m         layer_norm, (\u001b[38;5;28minput\u001b[39m, weight, bias), \u001b[38;5;28minput\u001b[39m, normalized_shape, weight\u001b[38;5;241m=\u001b[39mweight, bias\u001b[38;5;241m=\u001b[39mbias, eps\u001b[38;5;241m=\u001b[39meps\n\u001b[1;32m   2346\u001b[0m     )\n\u001b[0;32m-> 2347\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_shape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: \"LayerNormKernelImpl\" not implemented for 'Half'"
     ]
    }
   ],
   "source": [
    "prompt = (\n",
    "    \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \"\n",
    "    \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \"\n",
    "    \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072e1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d4056-5cb6-426b-bef4-3a69ad4c2c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
