{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd758ae-aabd-4aae-87cc-f94295f34075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-08 11:56:24.097906: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-08 11:56:24.097932: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from comet import download_model, load_from_checkpoint\n",
    "from typing import List\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy\n",
    "from mbart_qe import download_mbart_qe, load_mbart_qe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3f1cd9c-23e0-4a75-b41b-708152ee8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "mbartqe_dir = \"./mbartqemodel\"\n",
    "mbartqe_model = \"wmt21-mbart-m2\"\n",
    "cometqe_dir = \"./cometqemodel\"\n",
    "cometqe_model = \"wmt20-comet-qe-da\"\n",
    "cometmodel = \"wmt20-comet-da\"\n",
    "batch_size = 64\n",
    "def load_cands(fname):\n",
    "    data = []\n",
    "    with open(fname, 'r') as file:\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            #print(line)\n",
    "            # if line is empty\n",
    "            # end of file is reached\n",
    "            if not line or len(line)<3:\n",
    "                break\n",
    "\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def process_cands(cand_data):\n",
    "    refs = []\n",
    "    hyps = []\n",
    "    srcs = []\n",
    "    clen = len(cand_data['scores'])\n",
    "    # return refs, hyps, srcs\n",
    "    return [cand_data['ref']]*clen, cand_data['cands'], [cand_data['inp']]*clen\n",
    "        \n",
    "\n",
    "def get_average_score(cand_data, resco):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    s = \"scores\"\n",
    "    if resco:\n",
    "        s = \"rescores\"\n",
    "    for c in cand_data:\n",
    "        scoresum+=sum(c[s])\n",
    "        scoretot+=len(c[s])\n",
    "    return scoresum/scoretot\n",
    "\n",
    "def amax_score(cand_data):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    for c in cand_data:\n",
    "        if len(c['scores'])==0:\n",
    "            continue\n",
    "        scoresum+=max(c['scores'])\n",
    "        scoretot+=1\n",
    "    return scoresum/scoretot\n",
    "\n",
    "def get_average_candlen(cand_data):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    empty = 0\n",
    "    for c in cand_data:\n",
    "        if len(c['scores'])==0:\n",
    "            empty+=1\n",
    "            continue\n",
    "        scoresum+=len(c['scores'])\n",
    "        scoretot+=1\n",
    "    print(\"Are empty :\"+str(empty))\n",
    "    return scoresum/scoretot\n",
    "\n",
    "#get_average_score(lat_cands[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d57d834-69ab-4fd8-9c68-f226e6e3d68c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading wmt21-mbart-m2.tar.gz\n",
      "wmt21-mbart-m2.tar.gz: 1.72GB [02:33, 11.2MB/s]                                                                \n",
      "Extracting ./mbartqemodel/wmt21-mbart-m2.tar.gz\n",
      "Extracted ./mbartqemodel/wmt21-mbart-m2.tar.gz\n",
      "Lock 139850381131392 acquired on /home/prasann/.cache/huggingface/transformers/5d1887643f1664d937a365f07ad9e87e44f2456be32e42f1b9a95b8f8ef5107b.bbe6aec8546fb906918aa82f066790a1ffa07df036c72aedb4ecb75fb20f5945.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddd1c8b18d144c3bd0076ce9df760dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.43k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 139850381131392 released on /home/prasann/.cache/huggingface/transformers/5d1887643f1664d937a365f07ad9e87e44f2456be32e42f1b9a95b8f8ef5107b.bbe6aec8546fb906918aa82f066790a1ffa07df036c72aedb4ecb75fb20f5945.lock\n",
      "Lock 139850381098480 acquired on /home/prasann/.cache/huggingface/transformers/e33fcda1a71396b8475e16e2fe1458cfa62c6013f8cb3787d6aa4364ec5251c6.d802a5ca7720894045dd2c9dcee6069d27aa92fbbe33f52b44d479538dc3ccc3.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4988f0302f0c49e3ad66802cdf39f25e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.44G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 139850381098480 released on /home/prasann/.cache/huggingface/transformers/e33fcda1a71396b8475e16e2fe1458cfa62c6013f8cb3787d6aa4364ec5251c6.d802a5ca7720894045dd2c9dcee6069d27aa92fbbe33f52b44d479538dc3ccc3.lock\n",
      "Some weights of the model checkpoint at facebook/mbart-large-50-many-to-many-mmt were not used when initializing MBartModel: ['final_logits_bias', 'lm_head.weight']\n",
      "- This IS expected if you are initializing MBartModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing MBartModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Lock 139850381046928 acquired on /home/prasann/.cache/huggingface/transformers/31c2f987466a85f8cf625f5ba85274f14abd42cd96b3cf0049d9930c7f6c712b.0fd2865cdcd6c9f10e6294ec92161d30cde315daf8c32729c154a45891c7284a.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6bc88f96b54100a158d0dd6754df8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/529 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 139850381046928 released on /home/prasann/.cache/huggingface/transformers/31c2f987466a85f8cf625f5ba85274f14abd42cd96b3cf0049d9930c7f6c712b.0fd2865cdcd6c9f10e6294ec92161d30cde315daf8c32729c154a45891c7284a.lock\n",
      "Lock 139850111390624 acquired on /home/prasann/.cache/huggingface/transformers/ab53a11de8224594a9e052c44aac899778134a66d5bc3cb3d8f17c6253eefacf.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24422cbf7e824b3a9173268d1472afd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 139850111390624 released on /home/prasann/.cache/huggingface/transformers/ab53a11de8224594a9e052c44aac899778134a66d5bc3cb3d8f17c6253eefacf.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e.lock\n",
      "Lock 139850111607856 acquired on /home/prasann/.cache/huggingface/transformers/4b641f4da1ffa5a28bb384165c3230c2afd9f3215ccf96aa78c1c76952f722d1.ac77c0b56ab82aca841e254aa35803773ca3f42af7b173cc9e56af3bc76083d0.lock\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1274e8b0816485fb29cdad2a6fc35ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/649 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lock 139850111607856 released on /home/prasann/.cache/huggingface/transformers/4b641f4da1ffa5a28bb384165c3230c2afd9f3215ccf96aa78c1c76952f722d1.ac77c0b56ab82aca841e254aa35803773ca3f42af7b173cc9e56af3bc76083d0.lock\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keeping Embeddings Frozen!\n",
      "Keeping Encoder Frozen!\n"
     ]
    }
   ],
   "source": [
    "mbart_path = download_mbart_qe(mbartqe_model, mbartqe_dir)\n",
    "mbart = load_mbart_qe(mbart_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86bbcfb0-a04e-4caf-b51c-1cf477773167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out average token length\n",
    "#lentok = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\", src_lang=\"de_DE\")\n",
    "# beam_cands = load_cands(\"./oldoutputs/candoutputs_v2/beam50fr_en.jsonl\")\n",
    "lat_cands = load_cands(\"./candoutputs/mtn1_fr-en_bfs_recom_1_-1_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7303ec79-bdf5-410e-b54a-9b3672f8b3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data_from_cands(cands):\n",
    "    srcs = []\n",
    "    refs = []\n",
    "    for c in cands:\n",
    "        srcs.append(c['inp'])\n",
    "        refs.append(c['ref'])\n",
    "    res = pd.DataFrame()\n",
    "    res['en'] = refs\n",
    "    res['fr'] = srcs\n",
    "    return res\n",
    "\n",
    "#TODO get to this in a sec\n",
    "make_data_from_cands(lat_cands).to_csv('translation_data/processed/fr_en_301.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e45fff-52cd-4761-9e62-ffe1f0e3ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7061253801690769\n",
      "-0.3560996056881159\n",
      "Are empty :1\n",
      "8.53\n",
      "-0.42656608538404106\n",
      "-0.3551072596013546\n",
      "Are empty :0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "print(get_average_score(lat_cands, False))\n",
    "print(amax_score(lat_cands))\n",
    "print(get_average_candlen(lat_cands))\n",
    "print(get_average_score(beam_cands, False))\n",
    "print(amax_score(beam_cands))\n",
    "print(get_average_candlen(beam_cands))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a5c3ca1-7397-4dea-ae51-b2540677e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 14., 15., 17., 12., 10., 10.,  5.,  3.,  3.]),\n",
       " array([ 7. , 14.6, 22.2, 29.8, 37.4, 45. , 52.6, 60.2, 67.8, 75.4, 83. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#inputs = lentok(beam_cands[0]['ref'])\n",
    "def get_len_distr(cands):\n",
    "    maxlen = 0\n",
    "    totlen = 0\n",
    "    vals = []\n",
    "    for c in cands:\n",
    "        try:\n",
    "            tmp = len(lentok(c['ref'])['input_ids'])\n",
    "        except:\n",
    "            print(\"issue\")\n",
    "            tmp = maxlen\n",
    "        maxlen = max(maxlen, tmp)\n",
    "        totlen+=tmp\n",
    "        vals.append(tmp)\n",
    "    return vals\n",
    "        \n",
    "len_dist = get_len_distr(lat_cands[:100])\n",
    "plt.hist(len_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a57ec7-93f4-4b1a-a1d9-795b6738d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_cand(ind):\n",
    "\n",
    "    print(cand_data[ind]['ref'])\n",
    "    for c in cand_data[ind]['cands']:\n",
    "        print(c)\n",
    "        \n",
    "def find_common(c1, c2list):\n",
    "    for c in c2list:\n",
    "        if c['ref']==c1['ref']:\n",
    "            return c\n",
    "        \n",
    "def get_cometqe_scores(hyps, srcs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt} for src, mt in zip(srcs, hyps)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = model.predict(\n",
    "        cometqe_input, batch_size=40, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs\n",
    "\n",
    "def get_comet_scores(hyps, srcs, refs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt, \"ref\":ref} for src, mt, ref in zip(srcs, hyps, refs)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = comet.predict(\n",
    "        cometqe_input, batch_size=40, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs\n",
    "\n",
    "def test_cometqe(hyp, src):\n",
    "    cqe_input = [{'src':src, 'mt':hyp}]\n",
    "    outputs = model.predict(\n",
    "        cqe_input, batch_size=1, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ef7162-1934-44df-ac02-b18da11ea368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lat_cands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(get_comet_scores([lat_cands[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcands\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]], [lat_cands[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minp\u001b[39m\u001b[38;5;124m'\u001b[39m]], [lat_cands[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mcomp_debug_cand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mcomp_debug_cand\u001b[0;34m(ind, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomp_debug_cand\u001b[39m(ind, k):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlat_cands\u001b[49m[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcands\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lat_cands' is not defined"
     ]
    }
   ],
   "source": [
    "#print(beam_cands[0]['cands'][0])\n",
    "def comp_debug_cand(ind, k):\n",
    "    if len(lat_cands[ind]['cands'])==0:\n",
    "        return\n",
    "    print(\"INPUT\")\n",
    "    print(lat_cands[ind]['inp'])\n",
    "    print(\"REF\")\n",
    "    print(lat_cands[ind]['ref'])\n",
    "    print(\"LATTICE\")\n",
    "    for i in range(0, k):\n",
    "        try:\n",
    "            print(lat_cands[ind]['scores'][i])\n",
    "            print(lat_cands[ind]['cands'][i])\n",
    "        except:\n",
    "            #print(\"NONE\")\n",
    "            \"\"\n",
    "    print(\"BEAM\")\n",
    "    common = find_common(lat_cands[ind], beam_cands)\n",
    "    #print(common)\n",
    "    for i in range(0, k):\n",
    "        print(common['scores'][i])\n",
    "        print(common['cands'][i])\n",
    "    print(\"BEAM\")\n",
    "    print(get_comet_scores([common['cands'][0]], [lat_cands[ind]['inp']], [lat_cands[ind]['ref']]))\n",
    "    print(\"LATTICE\")\n",
    "    print(get_comet_scores([lat_cands[ind]['cands'][0]], [lat_cands[ind]['inp']], [lat_cands[ind]['ref']]))\n",
    "\n",
    "for i in range(1, 20):\n",
    "    comp_debug_cand(i, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b60c24-6d2a-4df3-86d3-1c344240a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wmt20-comet-da is already in cache.\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n"
     ]
    }
   ],
   "source": [
    "comet_path = download_model(cometmodel, \"./cometmodel\")\n",
    "comet = load_from_checkpoint(comet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774229aa-00d4-42b7-bb3c-dd8017827e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\", tgt_lang=\"de_DE\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "model.to(device)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4af83adb-bb45-4dcf-9079-e243661145a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6c26a3-9cde-44f3-aa27-b00ec35b90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (print lengths, track throughout pipeline)\n",
    "\n",
    "def get_mbart_nll(cand, ind, tok, mod):\n",
    "\n",
    "    inp = cand['inp']\n",
    "    out = cand['cands'][ind]\n",
    "    print(out)\n",
    "\n",
    "    inputs = tokenizer(inp).to(device)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(out, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # forward pass\n",
    "    output = model(**inputs, labels=labels.input_ids)\n",
    "    #print(type(labels))\n",
    "    #print(labels.attention_mask)\n",
    "    return output.loss\n",
    "\n",
    "def test_cand(cand, ind):\n",
    "    print(get_mbart_nll(cand, ind))\n",
    "    print(cand['scores'][ind])\n",
    "    \n",
    "def rescore_cands(c_list):\n",
    "    device = \"cuda:3\" if torch.cuda.is_available() else \"cpu\"\n",
    "    mname = \"facebook/mbart-large-50-one-to-many-mmt\"\n",
    "    src_l = \"en_XX\"\n",
    "    tgt_l = \"de_DE\"\n",
    "    tok = tokenizer\n",
    "    mod = model\n",
    "    # tok = AutoTokenizer.from_pretrained(mname, src_lang=src_l, tgt_lang=tgt_l)\n",
    "    # mod = AutoModelForSeq2SeqLM.from_pretrained(mname)\n",
    "    # mod.to(device)\n",
    "    i = 0\n",
    "    for c in c_list:\n",
    "        c['oldsco'] = c['scores']\n",
    "        c['scores'] = []\n",
    "        for can in range(0, len(c['cands'])):\n",
    "            c['scores'].append(float(get_mbart_nll(c, can, tok, mod)))\n",
    "        c['sco_ranks'] = list(numpy.argsort(c['scores']))\n",
    "        print(i)\n",
    "        i+=1\n",
    "    # del tok\n",
    "    # del mod\n",
    "    return c_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36640cde-aa4c-4bf7-85eb-599c858f02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wenn es jedoch um terroristische Aktivit√§ten geht, sind solche Linien schwer zu ziehen.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_mbart_nll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat_cands\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mget_mbart_nll\u001b[0;34m(cand, ind, tok, mod)\u001b[0m\n\u001b[1;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m cand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcands\u001b[39m\u001b[38;5;124m'\u001b[39m][ind]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[0;32m----> 7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n\u001b[1;32m      9\u001b[0m     labels \u001b[38;5;241m=\u001b[39m tokenizer(out, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/file_utils.py:1764\u001b[0m, in \u001b[0;36mtorch_required.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1764\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1766\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` requires PyTorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:744\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:744\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "get_mbart_nll(lat_cands[0], 0, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a61e95-8b02-4889-9da1-80d98f156559",
   "metadata": {},
   "outputs": [],
   "source": [
    "resc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04de376a-2292-46c1-9cb4-ab81baae3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_cands[0]['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c761d22a-ec55-4ea6-a238-26c8f4531817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae6441d6-37c1-4f84-a5ef-f8baa0574777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring Sanity Check\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2fbbee-1307-4ccc-afe7-7397dfcb3687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "mname = \"facebook/mbart-large-50-one-to-many-mmt\"\n",
    "src_l = \"en_XX\"\n",
    "tgt_l = \"de_DE\"\n",
    "tok = AutoTokenizer.from_pretrained(mname, src_lang=src_l, tgt_lang=tgt_l)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "model.to(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a7823fe-c9a0-435b-96d6-682063dbf785",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampinp = [\"Technically speaking, the central pillar of the new debt agreement is a decade-long postponement of payments totaling 96.6 billion ($112.5 billion) that were due to begin in 2023.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "372e49f7-68e2-4a8d-83a1-f17cd2fd01b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = tokenizer(sampinp, return_tensors=\"pt\").to(\"cuda:3\")\n",
    "out = model.generate(\n",
    "    **inps,\n",
    "    forced_bos_token_id=tokenizer.lang_code_to_id[\"de_DE\"],\n",
    "    num_beams=50,\n",
    "    max_length=70, \n",
    "    num_return_sequences=50,\n",
    "    return_dict_in_generate=True,\n",
    "    output_scores=True,\n",
    ")\n",
    "cands = tokenizer.batch_decode(out.sequences, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df70e02c-996c-42db-a290-ebd1da27f82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3065, -0.3084, -0.3094, -0.3126, -0.3160, -0.3175, -0.3182, -0.3198,\n",
       "        -0.3201, -0.3204, -0.3221, -0.3223, -0.3232, -0.3241, -0.3243, -0.3246,\n",
       "        -0.3254, -0.3256, -0.3258, -0.3272, -0.3283, -0.3297, -0.3309, -0.3315,\n",
       "        -0.3322, -0.3322, -0.3327, -0.3339, -0.3341, -0.3342, -0.3343, -0.3352,\n",
       "        -0.3356, -0.3360, -0.3362, -0.3366, -0.3373, -0.3377, -0.3391, -0.3392,\n",
       "        -0.3399, -0.3402, -0.3409, -0.3411, -0.3418, -0.3422, -0.3430, -0.3437,\n",
       "        -0.3444, -0.3450], device='cuda:3')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sequences_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "99545f46-2701-4fbe-bcfe-beb9faa018c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# inputs = tok(sampinp[0], return_tensors=\"pt\").to(\"cuda:3\")\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43msampinp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcuda:3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tok\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n\u001b[1;32m      4\u001b[0m     labels \u001b[38;5;241m=\u001b[39m tok(cands[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:3\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/file_utils.py:1764\u001b[0m, in \u001b[0;36mtorch_required.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1764\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1766\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` requires PyTorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:744\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:744\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "# inputs = tok(sampinp[0], return_tensors=\"pt\").to(\"cuda:3\")\n",
    "inputs = tokenizer(sampinp, return_tensors=\"pt\").to(\"cuda:3\")\n",
    "with tok.as_target_tokenizer():\n",
    "    labels = tok(cands[0], return_tensors=\"pt\").to(\"cuda:3\")\n",
    "\n",
    "# forward pass\n",
    "output = model(**inputs, labels=tmp)\n",
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "99e230c4-cfe1-488b-ba54-e61d82db0604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     2, 250004,  92265,  35206,     47,  34784,  89024,    133,   5204,\n",
      "         132756,      7,   2750,   6777,    959,   1380,    678,  18912,  13133,\n",
      "           2258,      7,      2,      1,      1,      1,      1,      1,      1]],\n",
      "       device='cuda:3')\n",
      "tensor([[250004,  92265,  35206,     47,  34784,  89024,    133,   5204, 132756,\n",
      "              7,   2750,   6777,    959,   1380,    678,  18912,  13133,   2258,\n",
      "              7,      2]], device='cuda:3')\n"
     ]
    }
   ],
   "source": [
    "print(out.sequences[:1])\n",
    "print(labels.input_ids)\n",
    "#print(inputs['input_ids'][0]) \n",
    "#print(inps['input_ids'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f42b2326-4ea7-4c63-ac7b-9102b7464e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = torch.cat((torch.tensor([2]).to(\"cuda:3\"), labels.input_ids[0]))\n",
    "tmp = torch.cat((tmp, (torch.tensor([2]).to(\"cuda:3\"))))\n",
    "\n",
    "tmp = torch.unsqueeze(tmp, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e56aeda4-be5b-4686-8fec-4fdcb96d463b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#\n",
    "scores = [-0.4911, -0.4951, -0.4967, -0.5049, -0.5070, -0.5218, -0.5272, -0.5327,\n",
    "        -0.5333, -0.5343, -0.5345, -0.5355, -0.5382, -0.5382, -0.5386, -0.5387,\n",
    "        -0.5411, -0.5471, -0.5476, -0.5504, -0.5519, -0.5520, -0.5535, -0.5552,\n",
    "        -0.5554, -0.5561, -0.5561, -0.5618, -0.5642, -0.5644, -0.5662, -0.5685,\n",
    "        -0.5685, -0.5689, -0.5690, -0.5698, -0.5714, -0.5749, -0.5754, -0.5756,\n",
    "        -0.5766, -0.5771, -0.5787, -0.5791, -0.5797, -0.5816, -0.5856, -0.5872,\n",
    "        -0.5873, -0.5873]\n",
    "cands = ['French police to arrest Anderlecht supporters who did not come with RSCA cars.',\n",
    " '</s>en_XX The French police will arrest supporters of Anderlecht who came otherwise than with the cars of the RSCA</s><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than with RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than with the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not come with the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not come with RSCA buses</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than in RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than on RSCA buses</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX The French police will arrest supporters of Anderlecht who have come otherwise than with the cars of the RSCA</s>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came in other than RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters not using RSCA cars</s><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not travel with RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police will arrest supporters of Anderlecht who came otherwise than with the RSCA cars</s><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than with RSCA buses</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police will arrest Anderlecht supporters who came otherwise than with the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest supporters of Anderlecht who came otherwise than with the RSCA cars</s><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest supporters of Anderlecht who came otherwise than with RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not come with the RSCA buses</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters not travelling with RSCA cars</s><pad><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX The French police will arrest supporters of Anderlecht who came otherwise than with the RSCA cars</s><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not travel with the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police will arrest Anderlecht supporters who did not come with the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " \"</s>en_XX French police to arrest Anderlecht supporters who didn't come with RSCA cars</s><pad><pad><pad><pad><pad>\",\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than with the RSCA buses</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not travel with RSCA buses</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who do not come with RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than by RSCA bus</s><pad><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police will arrest supporters of Anderlecht who came otherwise than with RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than from RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " \"</s>en_XX French police to arrest Anderlecht supporters who didn't come with the RSCA cars</s><pad><pad><pad><pad>\",\n",
    " '</s>en_XX The French police will arrest supporters of Anderlecht who came otherwise than with the cars of the RSCA.</s>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than by RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who have come otherwise than with RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than on RSCA cars</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who come otherwise than with the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters not travelling with RSCA buses</s><pad><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest supporters of Anderlecht who did not come with RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who have come otherwise than with the RSCA cars</s><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest supporters of Anderlecht who did not come with the RSCA cars</s><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who didn‚Äôt come with RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came in other than RSCA buses</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than by RSCA car</s><pad><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police will arrest supporters of Anderlecht who come otherwise than with the RSCA cars</s><pad><pad><pad><pad>',\n",
    " \"</s>en_XX French police to arrest Anderlecht supporters who didn't come with RSCA buses</s><pad><pad><pad><pad><pad>\",\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who did not travel with the RSCA buses</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who came otherwise than in the RSCA cars</s><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who didn‚Äôt come with the RSCA cars</s><pad><pad><pad><pad>',\n",
    " '</s>en_XX French police to arrest Anderlecht supporters who do not come with RSCA buses</s><pad><pad><pad><pad><pad><pad>',\n",
    " '</s>en_XX The French police will arrest supporters of Anderlecht who have come otherwise than with the RSCA cars</s><pad><pad>',\n",
    " '</s>en_XX The French police will arrest supporters of Anderlecht who came otherwise than with the cars of RSCA</s><pad><pad>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad56ad5e-35a6-4c58-9672-22cf1af50e1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3.6970, device='cuda:3', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#s[0] = out.sequences[0]\n",
    "output = model(**inputs, labels=out.sequences[:1])\n",
    "print(output.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe1b221e-9805-4ca7-8dff-a63ab85088e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = torch.tensor([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd739ab4-3ed3-4328-9188-dea50cde102c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recreating rescore code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fefe9aa-c3b1-4a44-af02-987628c7b3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7188, device='cuda:3', grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5483775f-0b2c-4a9c-8d49-a693d8d97c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a18b3b-a19a-4d52-ae6c-f85919c210b3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
