{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dd758ae-aabd-4aae-87cc-f94295f34075",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-31 05:42:09.846351: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-31 05:42:09.846380: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "from comet import download_model, load_from_checkpoint\n",
    "from typing import List\n",
    "import json\n",
    "from transformers import AutoTokenizer\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b3f1cd9c-23e0-4a75-b41b-708152ee8687",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometqe_dir = \"./cometqemodel\"\n",
    "cometqe_model = \"wmt20-comet-qe-da\"\n",
    "cometmodel = \"wmt20-comet-da\"\n",
    "batch_size = 64\n",
    "def load_cands(fname):\n",
    "    data = []\n",
    "    with open(fname, 'r') as file:\n",
    "        while True:\n",
    "            line = file.readline()\n",
    "            #print(line)\n",
    "            # if line is empty\n",
    "            # end of file is reached\n",
    "            if not line or len(line)<3:\n",
    "                break\n",
    "\n",
    "            data.append(json.loads(line))\n",
    "    return data\n",
    "\n",
    "def process_cands(cand_data):\n",
    "    refs = []\n",
    "    hyps = []\n",
    "    srcs = []\n",
    "    clen = len(cand_data['scores'])\n",
    "    # return refs, hyps, srcs\n",
    "    return [cand_data['ref']]*clen, cand_data['cands'], [cand_data['inp']]*clen\n",
    "        \n",
    "\n",
    "def get_average_score(cand_data, resco):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    s = \"scores\"\n",
    "    if resco:\n",
    "        s = \"rescores\"\n",
    "    for c in cand_data:\n",
    "        scoresum+=sum(c[s])\n",
    "        scoretot+=len(c[s])\n",
    "    return scoresum/scoretot\n",
    "\n",
    "def amax_score(cand_data):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    for c in cand_data:\n",
    "        if len(c['scores'])==0:\n",
    "            continue\n",
    "        scoresum+=max(c['scores'])\n",
    "        scoretot+=1\n",
    "    return scoresum/scoretot\n",
    "\n",
    "def get_average_candlen(cand_data):\n",
    "    scoresum = 0\n",
    "    scoretot = 0\n",
    "    empty = 0\n",
    "    for c in cand_data:\n",
    "        if len(c['scores'])==0:\n",
    "            empty+=1\n",
    "            continue\n",
    "        scoresum+=len(c['scores'])\n",
    "        scoretot+=1\n",
    "    print(\"Are empty :\"+str(empty))\n",
    "    return scoresum/scoretot\n",
    "\n",
    "#get_average_score(lat_cands[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d57d834-69ab-4fd8-9c68-f226e6e3d68c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86bbcfb0-a04e-4caf-b51c-1cf477773167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out average token length\n",
    "#lentok = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\", src_lang=\"de_DE\")\n",
    "beam_cands = load_cands(\"./oldoutputs/candoutputs_v2/beam50fr_en.jsonl\")\n",
    "lat_cands = load_cands(\"./candoutputs/fr-en_bfs_recom_2_-.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2e45fff-52cd-4761-9e62-ffe1f0e3ae96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.7061253801690769\n",
      "-0.3560996056881159\n",
      "Are empty :1\n",
      "8.53\n",
      "-0.42656608538404106\n",
      "-0.3551072596013546\n",
      "Are empty :0\n",
      "50.0\n"
     ]
    }
   ],
   "source": [
    "print(get_average_score(lat_cands, False))\n",
    "print(amax_score(lat_cands))\n",
    "print(get_average_candlen(lat_cands))\n",
    "print(get_average_score(beam_cands, False))\n",
    "print(amax_score(beam_cands))\n",
    "print(get_average_candlen(beam_cands))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a5c3ca1-7397-4dea-ae51-b2540677e9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([11., 14., 15., 17., 12., 10., 10.,  5.,  3.,  3.]),\n",
       " array([ 7. , 14.6, 22.2, 29.8, 37.4, 45. , 52.6, 60.2, 67.8, 75.4, 83. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#inputs = lentok(beam_cands[0]['ref'])\n",
    "def get_len_distr(cands):\n",
    "    maxlen = 0\n",
    "    totlen = 0\n",
    "    vals = []\n",
    "    for c in cands:\n",
    "        try:\n",
    "            tmp = len(lentok(c['ref'])['input_ids'])\n",
    "        except:\n",
    "            print(\"issue\")\n",
    "            tmp = maxlen\n",
    "        maxlen = max(maxlen, tmp)\n",
    "        totlen+=tmp\n",
    "        vals.append(tmp)\n",
    "    return vals\n",
    "        \n",
    "len_dist = get_len_distr(lat_cands[:100])\n",
    "plt.hist(len_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24a57ec7-93f4-4b1a-a1d9-795b6738d09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_cand(ind):\n",
    "\n",
    "    print(cand_data[ind]['ref'])\n",
    "    for c in cand_data[ind]['cands']:\n",
    "        print(c)\n",
    "        \n",
    "def find_common(c1, c2list):\n",
    "    for c in c2list:\n",
    "        if c['ref']==c1['ref']:\n",
    "            return c\n",
    "        \n",
    "def get_cometqe_scores(hyps, srcs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt} for src, mt in zip(srcs, hyps)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = model.predict(\n",
    "        cometqe_input, batch_size=40, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs\n",
    "\n",
    "def get_comet_scores(hyps, srcs, refs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt, \"ref\":ref} for src, mt, ref in zip(srcs, hyps, refs)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = comet.predict(\n",
    "        cometqe_input, batch_size=40, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs\n",
    "\n",
    "def test_cometqe(hyp, src):\n",
    "    cqe_input = [{'src':src, 'mt':hyp}]\n",
    "    outputs = model.predict(\n",
    "        cqe_input, batch_size=1, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95ef7162-1934-44df-ac02-b18da11ea368",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lat_cands' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mprint\u001b[39m(get_comet_scores([lat_cands[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcands\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]], [lat_cands[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minp\u001b[39m\u001b[38;5;124m'\u001b[39m]], [lat_cands[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m'\u001b[39m]]))\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m20\u001b[39m):\n\u001b[0;32m---> 29\u001b[0m     \u001b[43mcomp_debug_cand\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mcomp_debug_cand\u001b[0;34m(ind, k)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcomp_debug_cand\u001b[39m(ind, k):\n\u001b[0;32m----> 3\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mlat_cands\u001b[49m[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcands\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINPUT\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lat_cands' is not defined"
     ]
    }
   ],
   "source": [
    "#print(beam_cands[0]['cands'][0])\n",
    "def comp_debug_cand(ind, k):\n",
    "    if len(lat_cands[ind]['cands'])==0:\n",
    "        return\n",
    "    print(\"INPUT\")\n",
    "    print(lat_cands[ind]['inp'])\n",
    "    print(\"REF\")\n",
    "    print(lat_cands[ind]['ref'])\n",
    "    print(\"LATTICE\")\n",
    "    for i in range(0, k):\n",
    "        try:\n",
    "            print(lat_cands[ind]['scores'][i])\n",
    "            print(lat_cands[ind]['cands'][i])\n",
    "        except:\n",
    "            #print(\"NONE\")\n",
    "            \"\"\n",
    "    print(\"BEAM\")\n",
    "    common = find_common(lat_cands[ind], beam_cands)\n",
    "    #print(common)\n",
    "    for i in range(0, k):\n",
    "        print(common['scores'][i])\n",
    "        print(common['cands'][i])\n",
    "    print(\"BEAM\")\n",
    "    print(get_comet_scores([common['cands'][0]], [lat_cands[ind]['inp']], [lat_cands[ind]['ref']]))\n",
    "    print(\"LATTICE\")\n",
    "    print(get_comet_scores([lat_cands[ind]['cands'][0]], [lat_cands[ind]['inp']], [lat_cands[ind]['ref']]))\n",
    "\n",
    "for i in range(1, 20):\n",
    "    comp_debug_cand(i, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31b60c24-6d2a-4df3-86d3-1c344240a868",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wmt20-comet-da is already in cache.\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n"
     ]
    }
   ],
   "source": [
    "comet_path = download_model(cometmodel, \"./cometmodel\")\n",
    "comet = load_from_checkpoint(comet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "774229aa-00d4-42b7-bb3c-dd8017827e60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\", src_lang=\"en_XX\", tgt_lang=\"de_DE\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/mbart-large-50-one-to-many-mmt\")\n",
    "model.to(device)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4af83adb-bb45-4dcf-9079-e243661145a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del tokenizer\n",
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4f6c26a3-9cde-44f3-aa27-b00ec35b90de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (print lengths, track throughout pipeline)\n",
    "\n",
    "def get_mbart_nll(cand, ind, tok, mod):\n",
    "\n",
    "    inp = cand['inp']\n",
    "    out = cand['cands'][ind]\n",
    "    print(out)\n",
    "\n",
    "    inputs = tokenizer(inp).to(device)\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(out, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    # forward pass\n",
    "    output = model(**inputs, labels=labels.input_ids)\n",
    "    #print(type(labels))\n",
    "    #print(labels.attention_mask)\n",
    "    return output.loss\n",
    "\n",
    "def test_cand(cand, ind):\n",
    "    print(get_mbart_nll(cand, ind))\n",
    "    print(cand['scores'][ind])\n",
    "    \n",
    "def rescore_cands(c_list):\n",
    "    device = \"cuda:2\" if torch.cuda.is_available() else \"cpu\"\n",
    "    mname = \"facebook/mbart-large-50-one-to-many-mmt\"\n",
    "    src_l = \"en_XX\"\n",
    "    tgt_l = \"de_DE\"\n",
    "    tok = tokenizer\n",
    "    mod = model\n",
    "    # tok = AutoTokenizer.from_pretrained(mname, src_lang=src_l, tgt_lang=tgt_l)\n",
    "    # mod = AutoModelForSeq2SeqLM.from_pretrained(mname)\n",
    "    # mod.to(device)\n",
    "    i = 0\n",
    "    for c in c_list:\n",
    "        c['oldsco'] = c['scores']\n",
    "        c['scores'] = []\n",
    "        for can in range(0, len(c['cands'])):\n",
    "            c['scores'].append(float(get_mbart_nll(c, can, tok, mod)))\n",
    "        c['sco_ranks'] = list(numpy.argsort(c['scores']))\n",
    "        print(i)\n",
    "        i+=1\n",
    "    # del tok\n",
    "    # del mod\n",
    "    return c_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36640cde-aa4c-4bf7-85eb-599c858f02e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wenn es jedoch um terroristische Aktivitäten geht, sind solche Linien schwer zu ziehen.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'to'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_mbart_nll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat_cands\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36mget_mbart_nll\u001b[0;34m(cand, ind, tok, mod)\u001b[0m\n\u001b[1;32m      4\u001b[0m out \u001b[38;5;241m=\u001b[39m cand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcands\u001b[39m\u001b[38;5;124m'\u001b[39m][ind]\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(out)\n\u001b[0;32m----> 7\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minp\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tokenizer\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n\u001b[1;32m      9\u001b[0m     labels \u001b[38;5;241m=\u001b[39m tokenizer(out, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/file_utils.py:1764\u001b[0m, in \u001b[0;36mtorch_required.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1761\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[1;32m   1762\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[0;32m-> 1764\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1765\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1766\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` requires PyTorch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:744\u001b[0m, in \u001b[0;36mBatchEncoding.to\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:744\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;66;03m# This check catches things like APEX blindly calling \"to\" on all inputs to a module\u001b[39;00m\n\u001b[1;32m    741\u001b[0m \u001b[38;5;66;03m# Otherwise it passes the casts down and casts the LongTensor containing the token idxs\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \u001b[38;5;66;03m# into a HalfTensor\u001b[39;00m\n\u001b[1;32m    743\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m _is_torch_device(device) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, \u001b[38;5;28mint\u001b[39m):\n\u001b[0;32m--> 744\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m {k: \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m(device\u001b[38;5;241m=\u001b[39mdevice) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    746\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempting to cast a BatchEncoding to type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(device)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. This is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'to'"
     ]
    }
   ],
   "source": [
    "get_mbart_nll(lat_cands[0], 0, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a61e95-8b02-4889-9da1-80d98f156559",
   "metadata": {},
   "outputs": [],
   "source": [
    "resc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "04de376a-2292-46c1-9cb4-ab81baae3f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_cands[0]['scores'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c761d22a-ec55-4ea6-a238-26c8f4531817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.mbart.modeling_mbart.MBartForConditionalGeneration"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a42018b-308b-49e9-aaec-2a03da7390a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b1c49a-9660-4167-8c15-d959c2b104d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
