{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0277c5-597c-40bf-9ef6-8916d34e067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-30 16:34:21.050216: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-10-30 16:34:21.050237: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from efficient_rerank import *\n",
    "import torch\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.recom_search.model.beam_node_reverse import ReverseNode\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1301527-510a-4937-8e1b-04e84ed98188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1112257024"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model, for french\n",
    "#del model\n",
    "model = XLMCometEmbeds(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/maskedcont4.pt\"))\n",
    "model.eval()\n",
    "torch.cuda.memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241836e0-2116-4891-8ff1-983630db4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds = pd.read_csv('frenchlatpreds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571b64e2-a3a1-4dd2-b7ef-ea8816d08334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' After all, as an investigative reporter in the countryside, she has ensnared many other people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, who she has accused of conducting a ransom-abduction policy.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frpreds.loc[0]['ahyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6bc6e7c-a8eb-4b3d-88cd-4da20d8df328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'After all, as a campaigning investigative journalist she made many people angry besides Putin, not least of which is the current Chechen Prime Minister, Ramzan Kadyrov, whom she accused of a policy of kidnapping for ransom. '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frpreds.loc[0]['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daedc160-cab5-40d6-bdad-e48eb0c1ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\"\n",
    "def test_graph_ind(ind, basedir):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    try:\n",
    "        return g['input'], g['ref'], er.run_pipeline(g, model)\n",
    "    except:\n",
    "        return None, None, None\n",
    "    \n",
    "def get_all_preds(basedir):\n",
    "    l = len(os.listdir(basedir))\n",
    "    res = []\n",
    "    for i in range(l):\n",
    "        i, r, p = test_graph_ind(i, basedir)\n",
    "        res.append({\n",
    "            'src':i,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    res = pd.DataFrame(res)\n",
    "    res.to_csv(\"latfound\"+basedir[:-4]+\".csv\")\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f782f43a-60c8-4bc7-b9c3-d77ca977b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1001, device='cuda:1')\n",
      "SRC - Une autre variable réside dans la question de savoir dans quelle mesure les politiques monétaires des autres pays développés s’assoupliront. \n",
      "PRED - <s> Une autre variable réside dans la question de savoir dans quelle mesure les politiques monétaires des autres pays développés s’assoupliront.</s><s> The other variable is the extent to which other developed economies’ monetary policies will become more liberal.\n",
      "REF - Another variable is how much easier monetary policies in other developed countries will become. \n"
     ]
    }
   ],
   "source": [
    "i, r, ppres = test_graph_ind(2, base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6cd478df-c770-45a7-b594-10694934c039",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ppres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccfec1-1237-4959-9db8-39c9590212b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds = get_all_preds(\"frtest_reversed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a9268-4d4c-4c76-8848-14d3c1900826",
   "metadata": {},
   "outputs": [],
   "source": [
    "depreds = get_all_preds(\"detest_reversed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a033cea6-d17a-4d5a-a192-e2f4f3fd0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"frtest_reversed/\"\n",
    "l = len(os.listdir(basedir))\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693b273-1868-4eea-b570-4afaac3eacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(l):\n",
    "    i, r, p = test_graph_ind(i, basedir)\n",
    "    if i==None:\n",
    "        continue\n",
    "    res.append({\n",
    "        'src':i,\n",
    "        'hyp':p,\n",
    "        'ref':r\n",
    "    })\n",
    "    print(i)\n",
    "resdf = pd.DataFrame(res)\n",
    "frpreds = resdf\n",
    "#resdf.to_csv(\"frenchlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c78d6-9dbb-47be-9c4c-4796f4fc943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = er.XLMCometEmbeds(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/germanlat0.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd515659-0416-42a2-86da-3895978bba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"detest_reversed/\"\n",
    "l = len(os.listdir(basedir))\n",
    "res = []\n",
    "for i in range(l):\n",
    "    i, r, p = test_graph_ind(i, basedir)\n",
    "    res.append({\n",
    "        'src':i,\n",
    "        'hyp':p,\n",
    "        'ref':r\n",
    "    })\n",
    "    print(i)\n",
    "resdf = pd.DataFrame(res)\n",
    "depreds = resdf.to_csv(\"germanlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72698460-e7c3-4a22-8f00-82fbc73e08b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>By the time Mao Zedong died, in 1976, the rura...</td>\n",
       "      <td>&lt;s&gt; By the time Mao Zedong died, in 1976, the ...</td>\n",
       "      <td>Als Mao Tse-Tung im Jahr 1976 starb, lag die W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(If the TTIP was opened to other economies – s...</td>\n",
       "      <td>&lt;s&gt; (If the TTIP was opened to other economies...</td>\n",
       "      <td>(Würde TTIP für andere Volkswirtschaften – wie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>On the other hand, China remains trapped by a ...</td>\n",
       "      <td>&lt;s&gt; On the other hand, China remains trapped b...</td>\n",
       "      <td>Auf der anderen Seite bleibt China seiner Verg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Simonyi wrote the Microsoft Word program, and...</td>\n",
       "      <td>&lt;s&gt; (Simonyi wrote the Microsoft Word program,...</td>\n",
       "      <td>(Simonyi entwickelte das Programm Microsoft Wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Everyone agrees that Iran has the right to do ...</td>\n",
       "      <td>&lt;s&gt; Everyone agrees that Iran has the right to...</td>\n",
       "      <td>Alle sind sich einig, dass dem Iran das Recht ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1072</th>\n",
       "      <td>But this does not mean that we should just cut...</td>\n",
       "      <td>&lt;s&gt; But this does not mean that we should just...</td>\n",
       "      <td>Aber das heißt nicht, dass wir einfach auf all...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>It might seem from these numbers that Europe h...</td>\n",
       "      <td>&lt;s&gt; It might seem from these numbers that Euro...</td>\n",
       "      <td>Aus diesen Zahlen könnte man ableiten, dass di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>In other words, the structures that companies ...</td>\n",
       "      <td>&lt;s&gt; In other words, the structures that compan...</td>\n",
       "      <td>Anders ausgedrückt: Die Strukturen, die Untern...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>On October 24, you can stand up against this i...</td>\n",
       "      <td>&lt;s&gt; On October 24, you can stand up against th...</td>\n",
       "      <td>Am 24. Oktober besteht die Möglichkeit, gegen ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>Perhaps most importantly, competition is a pow...</td>\n",
       "      <td>&lt;s&gt; Perhaps most importantly, competition is a...</td>\n",
       "      <td>Am wichtigsten ist vielleicht, dass der Wettbe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1077 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    src  \\\n",
       "0     By the time Mao Zedong died, in 1976, the rura...   \n",
       "1     (If the TTIP was opened to other economies – s...   \n",
       "2     On the other hand, China remains trapped by a ...   \n",
       "3     (Simonyi wrote the Microsoft Word program, and...   \n",
       "4     Everyone agrees that Iran has the right to do ...   \n",
       "...                                                 ...   \n",
       "1072  But this does not mean that we should just cut...   \n",
       "1073  It might seem from these numbers that Europe h...   \n",
       "1074  In other words, the structures that companies ...   \n",
       "1075  On October 24, you can stand up against this i...   \n",
       "1076  Perhaps most importantly, competition is a pow...   \n",
       "\n",
       "                                                    hyp  \\\n",
       "0     <s> By the time Mao Zedong died, in 1976, the ...   \n",
       "1     <s> (If the TTIP was opened to other economies...   \n",
       "2     <s> On the other hand, China remains trapped b...   \n",
       "3     <s> (Simonyi wrote the Microsoft Word program,...   \n",
       "4     <s> Everyone agrees that Iran has the right to...   \n",
       "...                                                 ...   \n",
       "1072  <s> But this does not mean that we should just...   \n",
       "1073  <s> It might seem from these numbers that Euro...   \n",
       "1074  <s> In other words, the structures that compan...   \n",
       "1075  <s> On October 24, you can stand up against th...   \n",
       "1076  <s> Perhaps most importantly, competition is a...   \n",
       "\n",
       "                                                    ref  \n",
       "0     Als Mao Tse-Tung im Jahr 1976 starb, lag die W...  \n",
       "1     (Würde TTIP für andere Volkswirtschaften – wie...  \n",
       "2     Auf der anderen Seite bleibt China seiner Verg...  \n",
       "3     (Simonyi entwickelte das Programm Microsoft Wo...  \n",
       "4     Alle sind sich einig, dass dem Iran das Recht ...  \n",
       "...                                                 ...  \n",
       "1072  Aber das heißt nicht, dass wir einfach auf all...  \n",
       "1073  Aus diesen Zahlen könnte man ableiten, dass di...  \n",
       "1074  Anders ausgedrückt: Die Strukturen, die Untern...  \n",
       "1075  Am 24. Oktober besteht die Möglichkeit, gegen ...  \n",
       "1076  Am wichtigsten ist vielleicht, dass der Wettbe...  \n",
       "\n",
       "[1077 rows x 3 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a8fbb45d-e007-49d0-a5c5-052e2f4efc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds = pd.read_csv(\"frenchlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cc8106d2-9ebf-4bb9-8efa-3c1506c45410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s> By the time Mao Zedong died, in 1976, the rural economy was a shambles.</s><s> de_DE Bei der Todestagszeit Mao Zedongs, im Jahr 1976, war die ländliche Wirtschaft in einem Schlamm.'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depreds.loc[0]['hyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e17e471f-3c24-4013-b944-0a4629e5baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_hyps(hyplist, cutoff):\n",
    "    res = []\n",
    "    for h in hyplist:\n",
    "        cind = h[3:].index(cutoff)+len(cutoff)+3\n",
    "        res.append(h[cind:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1f2eab03-5dda-47b4-aa6f-34d4dda63220",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds['ahyp'] = get_act_hyps(frpreds['hyp'], \"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39931db3-4144-498d-b86d-5d4ac6b398c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>hyp</th>\n",
       "      <th>ref</th>\n",
       "      <th>ahyp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>&lt;s&gt; Après tout, en tant que journaliste d'inve...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>After all, as an investigative reporter in th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Au fur et à mesure que l’Iran a cherché à éten...</td>\n",
       "      <td>&lt;s&gt; Au fur et à mesure que l’Iran a cherché à ...</td>\n",
       "      <td>As Iran seeks to assert its influence and inte...</td>\n",
       "      <td>As Iran sought to extend its influence and ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Une autre variable réside dans la question de ...</td>\n",
       "      <td>&lt;s&gt; Une autre variable réside dans la question...</td>\n",
       "      <td>Another variable is how much easier monetary p...</td>\n",
       "      <td>The other variable is the extent to which oth...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Il nous faut négocier un nouvel accord de part...</td>\n",
       "      <td>&lt;s&gt; Il nous faut négocier un nouvel accord de ...</td>\n",
       "      <td>A new Partnership and Cooperation Agreement (P...</td>\n",
       "      <td>We need to negotiate a new partnership and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Et lorsqu’une région du monde conçoit une meil...</td>\n",
       "      <td>&lt;s&gt; Et lorsqu’une région du monde conçoit une ...</td>\n",
       "      <td>And as one region in one part of the world des...</td>\n",
       "      <td>And when a region of the world devises better...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>839</td>\n",
       "      <td>Au moment même de lire ces lignes, des personn...</td>\n",
       "      <td>&lt;s&gt; Au moment même de lire ces lignes, des per...</td>\n",
       "      <td>As you read this, perfectly ordinary people so...</td>\n",
       "      <td>At the very time of reading these lines, perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>840</th>\n",
       "      <td>840</td>\n",
       "      <td>C’est ainsi que les médias traditionnels se so...</td>\n",
       "      <td>&lt;s&gt; C’est ainsi que les médias traditionnels s...</td>\n",
       "      <td>As a result, mainstream media are being margin...</td>\n",
       "      <td>As a result, the traditional media have progr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>841</th>\n",
       "      <td>841</td>\n",
       "      <td>Un troisième impératif est de construire un mo...</td>\n",
       "      <td>&lt;s&gt; Un troisième impératif est de construire u...</td>\n",
       "      <td>A third imperative is building a safer and mor...</td>\n",
       "      <td>A third imperative is the building of a safer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>842</th>\n",
       "      <td>842</td>\n",
       "      <td>Une approche « portefeuille » du changement cl...</td>\n",
       "      <td>&lt;s&gt; Une approche « portefeuille » du changemen...</td>\n",
       "      <td>A “Portfolio” Approach to Climate Change</td>\n",
       "      <td>A \"portfolio \" approach to global climate cha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>843</th>\n",
       "      <td>843</td>\n",
       "      <td>Au plan intérieur également, une méfiance géné...</td>\n",
       "      <td>&lt;s&gt; Au plan intérieur également, une méfiance ...</td>\n",
       "      <td>At home, too, massive distrust will further co...</td>\n",
       "      <td>Internally, too, widespread distrust will mak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>844 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                                src  \\\n",
       "0             0  Après tout, en tant que journaliste d'investig...   \n",
       "1             1  Au fur et à mesure que l’Iran a cherché à éten...   \n",
       "2             2  Une autre variable réside dans la question de ...   \n",
       "3             3  Il nous faut négocier un nouvel accord de part...   \n",
       "4             4  Et lorsqu’une région du monde conçoit une meil...   \n",
       "..          ...                                                ...   \n",
       "839         839  Au moment même de lire ces lignes, des personn...   \n",
       "840         840  C’est ainsi que les médias traditionnels se so...   \n",
       "841         841  Un troisième impératif est de construire un mo...   \n",
       "842         842  Une approche « portefeuille » du changement cl...   \n",
       "843         843  Au plan intérieur également, une méfiance géné...   \n",
       "\n",
       "                                                   hyp  \\\n",
       "0    <s> Après tout, en tant que journaliste d'inve...   \n",
       "1    <s> Au fur et à mesure que l’Iran a cherché à ...   \n",
       "2    <s> Une autre variable réside dans la question...   \n",
       "3    <s> Il nous faut négocier un nouvel accord de ...   \n",
       "4    <s> Et lorsqu’une région du monde conçoit une ...   \n",
       "..                                                 ...   \n",
       "839  <s> Au moment même de lire ces lignes, des per...   \n",
       "840  <s> C’est ainsi que les médias traditionnels s...   \n",
       "841  <s> Un troisième impératif est de construire u...   \n",
       "842  <s> Une approche « portefeuille » du changemen...   \n",
       "843  <s> Au plan intérieur également, une méfiance ...   \n",
       "\n",
       "                                                   ref  \\\n",
       "0    After all, as a campaigning investigative jour...   \n",
       "1    As Iran seeks to assert its influence and inte...   \n",
       "2    Another variable is how much easier monetary p...   \n",
       "3    A new Partnership and Cooperation Agreement (P...   \n",
       "4    And as one region in one part of the world des...   \n",
       "..                                                 ...   \n",
       "839  As you read this, perfectly ordinary people so...   \n",
       "840  As a result, mainstream media are being margin...   \n",
       "841  A third imperative is building a safer and mor...   \n",
       "842          A “Portfolio” Approach to Climate Change    \n",
       "843  At home, too, massive distrust will further co...   \n",
       "\n",
       "                                                  ahyp  \n",
       "0     After all, as an investigative reporter in th...  \n",
       "1     As Iran sought to extend its influence and ad...  \n",
       "2     The other variable is the extent to which oth...  \n",
       "3     We need to negotiate a new partnership and co...  \n",
       "4     And when a region of the world devises better...  \n",
       "..                                                 ...  \n",
       "839   At the very time of reading these lines, perf...  \n",
       "840   As a result, the traditional media have progr...  \n",
       "841   A third imperative is the building of a safer...  \n",
       "842   A \"portfolio \" approach to global climate cha...  \n",
       "843   Internally, too, widespread distrust will mak...  \n",
       "\n",
       "[844 rows x 5 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "85c53317-3d89-4ee7-92f1-c7300d24d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comet_scores(hyps, srcs, refs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt, \"ref\":ref} for src, mt, ref in zip(srcs, hyps, refs)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = comet.predict(\n",
    "        cometqe_input, batch_size=32, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "71cd529d-651b-4c35-be71-4a02b2215d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometqe_dir = \"./cometqemodel\"\n",
    "# can alternatively use wmt21-comet-qe-mqm\n",
    "cometqe_model = \"wmt20-comet-qe-da\"\n",
    "cometmodel = \"wmt20-comet-da\"\n",
    "batch_size = 64\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "eb818c35-c952-4abe-8f40-36525db80650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb564d2a-71a8-45b5-94bd-fa6febff5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_path = download_model(cometmodel, \"./cometmodel\")\n",
    "comet = load_from_checkpoint(comet_path)\n",
    "comet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a95f2c3f-e859-40af-a1c8-46969d4b9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441afbe0-62a4-4e58-88d8-c1364bbb8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "scos = get_comet_scores(frpreds['ahyp'], frpreds['src'], frpreds['ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7cab774-12cf-4eec-b8db-074c56af3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds['scos'] = scos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8b473785-da12-4209-a20a-12f9c6a3d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds.to_csv(\"frenchlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "accf2281-f9ee-4281-8bb3-b6f146e38e1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Already nearly everybody in the North Atlantic region has enough food to avoid hunger, enough clothing to stay warm, enough shelter to remain dry. And yet we want more, feel resentful when we do not get it, and are self-aware enough to know that luxuries turn into conveniences, and then into necessities – and that we are very good at inventing new luxuries after which to strive. '"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frpreds[frpreds['scos']<0].loc[25]['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "33354134-a51e-48f2-9875-2f980a3479a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03813996849133665"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(depreds['scos'])/1077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4cd7acd6-4f7f-41a5-89b8-d3dff858f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a734ac70-7e88-48c0-8d65-5c3df8e21f2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  3.,   8.,  28.,  12.,  14.,  14.,  64., 110., 374., 217.]),\n",
       " array([-1.84165907, -1.55159155, -1.26152403, -0.97145652, -0.681389  ,\n",
       "        -0.39132148, -0.10125396,  0.18881356,  0.47888107,  0.76894859,\n",
       "         1.05901611]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(frpreds['scos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d3ed32b-55a6-4577-a50b-6907a4059c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = fl.bert_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea7fd36b-78cb-4c21-9dc4-0d0098ccb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pickle.load(open(base+str(2), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1ec2b19-50a8-459a-b14f-d7de1a28554f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReverseNode' object has no attribute 'prevs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mgraph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mroot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprevs\u001b[49m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReverseNode' object has no attribute 'prevs'"
     ]
    }
   ],
   "source": [
    "graph['root'].prevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cbc3dd1b-68ac-437f-864e-0980f0bdf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging stuff out \n",
    "# override this function\n",
    "# TODO will need to update if there are new changes\n",
    "flattened = fl.flatten_lattice(graph)\n",
    "ppinput = prepend_input(flattened, graph['input'])\n",
    "flattened = ppinput[0]\n",
    "covered = fl.get_cover_paths(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "be63935f-f6fb-418f-b5a0-01637bf91277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another\n",
      "335\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[335]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_tind(ftd, val):\n",
    "    finds = []\n",
    "    ind = 0\n",
    "    for t in ftd:\n",
    "        if val in tok.decode(t['token_idx']):\n",
    "            print(tok.decode(t['token_idx']))\n",
    "            print(ind)\n",
    "            finds.append(ind)\n",
    "            \n",
    "        ind+=1\n",
    "    return finds\n",
    "\n",
    "def find_byid(ftd, idval):\n",
    "    i = 0\n",
    "    for t in ftd:\n",
    "        \n",
    "        if t['id']==idval:\n",
    "            print(i)\n",
    "            return t\n",
    "        i+=1\n",
    "    return None\n",
    "\n",
    "def track_to_end(ftd, tstart):\n",
    "    cur = tstart\n",
    "    while len(cur['nexts'])>0:\n",
    "        print(tok.decode(cur['token_idx']))\n",
    "        #print(len(cur['nexts']))\n",
    "        itmp = -1\n",
    "        while find_byid(ftd, cur['nexts'][itmp]) is None:\n",
    "            itmp-=1\n",
    "        cur = find_byid(ftd, cur['nexts'][itmp])\n",
    "find_tind(flattened, \"Another\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0ec4139-e8b4-452f-9c42-281223c9cbca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_idx': 44930,\n",
       " 'pos': 42,\n",
       " 'id': '44930 42',\n",
       " 'nexts': ['2 43'],\n",
       " 'score': tensor(-0.0026, device='cuda:1'),\n",
       " 'bestsco': tensor(-0.0026, device='cuda:1'),\n",
       " 'plist': [0]}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened[351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dcbf462a-fcb7-428e-aaf1-a0bb48511312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Another\n",
      "336\n",
      "336\n",
      "variable\n",
      "337\n",
      "337\n",
      "is\n",
      "338\n",
      "338\n",
      "the\n",
      "344\n",
      "344\n",
      "degree\n",
      "345\n",
      "345\n",
      "to\n",
      "346\n",
      "346\n",
      "which\n",
      "349\n",
      "349\n",
      "monetar\n",
      "350\n",
      "350\n",
      "y\n",
      "351\n",
      "351\n",
      "policy\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrack_to_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43mflattened\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflattened\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m335\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36mtrack_to_end\u001b[0;34m(ftd, tstart)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#print(len(cur['nexts']))\u001b[39;00m\n\u001b[1;32m     28\u001b[0m itmp \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 29\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m find_byid(ftd, \u001b[43mcur\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnexts\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitmp\u001b[49m\u001b[43m]\u001b[49m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     30\u001b[0m     itmp\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     31\u001b[0m cur \u001b[38;5;241m=\u001b[39m find_byid(ftd, cur[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnexts\u001b[39m\u001b[38;5;124m'\u001b[39m][itmp])\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "track_to_end(flattened, flattened[335])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "602bb659-fe20-43aa-8347-0391ace0a236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'token_idx': 3789,\n",
       " 'pos': 40,\n",
       " 'id': '3789 40',\n",
       " 'nexts': ['2 41'],\n",
       " 'score': tensor(-0.0026, device='cuda:1'),\n",
       " 'bestsco': tensor(-0.0026, device='cuda:1'),\n",
       " 'plist': [3]}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_byid(flattened, '3789 40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "99a7a5fc-7c8b-4d5e-a3d6-89eebe49ef60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2961f373-1996-4ff1-b027-8cd561640203",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "352"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flattened)\n",
    "# We want - Another variable is the degree to which other developed countries’ monetary policies will ease.\n",
    "# We got - The other variable is the extent to which other developed economies’ monetary policies will become more liberal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6d899d4-6e03-4f8c-b08d-0186bfdaf61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1001, device='cuda:1')\n",
      "SRC - Une autre variable réside dans la question de savoir dans quelle mesure les politiques monétaires des autres pays développés s’assoupliront. \n",
      "PRED - <s> Une autre variable réside dans la question de savoir dans quelle mesure les politiques monétaires des autres pays développés s’assoupliront.</s><s> The other variable is the extent to which other developed economies’ monetary policies will become more liberal.\n",
      "REF - Another variable is how much easier monetary policies in other developed countries will become. \n"
     ]
    }
   ],
   "source": [
    "posadd = ppinput[1]\n",
    "mask = causal_mask(flattened, posadd)\n",
    "sents, posids = create_inputs([flattened])\n",
    "with torch.no_grad():\n",
    "    pred = model(sents, posids, mask.unsqueeze(0).to(device))\n",
    "fls = [flattened]\n",
    "prepared_pgraphs = prepare_pgraphs(fls, pred[0])\n",
    "bestpath = dp_pgraph(prepared_pgraphs[0])\n",
    "best = xlm_tok.decode(bestpath)\n",
    "print(\"SRC - \"+graph['input'])\n",
    "print(\"PRED - \"+best)\n",
    "print(\"REF - \"+graph['ref'])\n",
    "# return best, covered, flattened, prepared_pgraphs, mask, sents, posids, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17edc620-4d49-4181-8d71-72261679e912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'policyy monetar other the which to degree to extent the of question the is variable Another more becoming are. flexible more becomes economie more become more be willtions na developed countries be wills economie advanced other other more become more be.ase e will world developed the of rest the in developed other the of more be will policiess economie developed others economie developed other the in are become would. flexible more become may countries developed other in flexible more be will policyy monetar more be more become will policyy monetar’. policiesy monetar theirase e will countries.tive accommoda.ed relax. liberal more. flexible less.ser loo become.tive accommoda.ed relax. liberal more. flexible.ed relax.ingas e.ser loo be.se acembra  e. relax will. flexible more become more becoming are. flexible more become more be would policiesy monetar’s economie developed others economie developed become be will countries advanced other are become countries.tive accommoda more become.tive accommoda more.ed relax. flexible be.ase e. relax wills economie developed other the of policies. flexible.tive accommoda.ed relax. liberal. elastic more. flexible. rigid less.ser loo.ed relax become. flexible.tive accommoda.ed relax. liberal more.ed relax. flexible.ingas e. flexible more made be.se a.ity flexibilcembra  e. relax.ize liberal will. flexible more becoming are. flexible more become. flexible more be would countries developed other of policyy monetar the which to extent the is variable other The<s></s>.rontliupasso’ ss développé pays autres desairesét mon politiques les mesure quelle dans savoir de question la dansside ré variable autre Une<s>'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok.decode([t['token_idx'] for t in prepared_pgraphs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0a17fe5c-d42e-4e5e-939d-8da7ade66362",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist[0].nextlist[1].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "1015a08c-4010-419c-9b8a-059eb443b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_node(node):\n",
    "    for no in node.nextlist:\n",
    "        print(no.token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "29ab4442-fe8c-4c74-a92c-38af47367b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n"
     ]
    }
   ],
   "source": [
    "# We want - Another variable is the degree to which other developed countries’ monetary policies will ease.\n",
    "vis_node(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91ee3b89-f9ca-4ce1-9da0-8c5c6b70f648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8566898107528687"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b24ea03-b25b-486c-991f-774b24627325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLReverseNode():\n",
    "    def __init__(self, oldnode):\n",
    "        self.uid = oldnode.uid\n",
    "        self.prob = oldnode.prob\n",
    "        self.token_idx = oldnode.token_idx\n",
    "        self.token_str = oldnode.token_str\n",
    "        self.nextlist = oldnode.nextlist\n",
    "        self.next_scores = oldnode.next_scores\n",
    "        self.next_ids = oldnode.next_ids\n",
    "        self.prevs = []\n",
    "        self.detoks = []\n",
    "        self.pos = -1\n",
    "        self.canvpos = 1000\n",
    "        if oldnode.pos>0:\n",
    "            self.prevs = oldnode.prevs\n",
    "            self.pos = oldnode.pos\n",
    "            self.detoks = oldnode.detoks\n",
    "            self.canvpos = oldnode.canvpos\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "48e080d3-f4af-497f-92b2-a7db2f66db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dblgrph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff0780c1-d518-4e3c-9286-9a7c7c275fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\"\n",
    "toker = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "detok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "92e3d7ca-f897-44d1-a14e-bea8eda63689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO later on just move this to the initial graph reversal\n",
    "def get_dbl_graph(grph):\n",
    "    newgrph = {}\n",
    "    for g in grph.keys():\n",
    "        if g==\"input\" or g== \"ref\" or g== \"rootid\":\n",
    "            continue\n",
    "        tmp = DLReverseNode(grph[g])\n",
    "        newgrph[g] = tmp\n",
    "    for gk in newgrph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        # this should handle everything having a previous list\n",
    "        newgrph[gk].nextlist = None\n",
    "        newgrph[gk].nextlist = [newgrph[idl] for idl in newgrph[gk].next_ids]\n",
    "    for gk in newgrph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        for n in newgrph[gk].nextlist:\n",
    "            n.prevs.append(newgrph[gk])\n",
    "        newgrph[gk].token_idx = [newgrph[gk].token_idx]\n",
    "    # TODO do something to update scores on word graph\n",
    "    return newgrph\n",
    "\n",
    "# greedily traverse graph, run function on each node\n",
    "def greedy_traverse(gr, fun, norev=True):\n",
    "    queue = []\n",
    "    queue.append(gr['root'])\n",
    "    visited = []\n",
    "    while len(queue)>0:\n",
    "        cur = queue.pop()\n",
    "        fun(cur, gr)\n",
    "        order = np.argsort([n.prob for n in cur.nextlist])\n",
    "        # highest prob gets popped off first\n",
    "        for o in order:\n",
    "            if cur.uid not in visited:\n",
    "                queue.append(cur.nextlist[o])\n",
    "        visited.append(cur.uid)\n",
    "                \n",
    "# make so graph has word-only nodes, check tokenization at different node boundaries\n",
    "# update pointers afterwards\n",
    "def combine_nodes(gr):\n",
    "    dblgrph = get_dbl_graph(gr)\n",
    "    #print(\"Doubly Linked - \", len(dblgrph.keys()))\n",
    "    greedy_traverse(dblgrph, consolidate_node)\n",
    "    rmlist = []\n",
    "    for d in dblgrph.keys():\n",
    "        if d==\"input\" or d== \"ref\" or \"root\" in d:\n",
    "            continue\n",
    "        if len(dblgrph[d].prevs)==0:\n",
    "            rmlist.append(d)\n",
    "    for r in rmlist:\n",
    "        del dblgrph[r]\n",
    "    return dblgrph\n",
    "\n",
    "# do this on every node greedily to get flattened lattice canvas\n",
    "def add_to_flat(node, grph):\n",
    "    global flat\n",
    "    if node.canvpos<1000:\n",
    "        return\n",
    "    flat.append(node)\n",
    "    # get detokenization\n",
    "    detok_tmp = detok(node.token_str).input_ids[1:-1]\n",
    "    # update pos on first greedy hit\n",
    "    if len(node.prevs)==0:\n",
    "        node.pos = -1 + len(detok_tmp)\n",
    "    if node.pos==-1:\n",
    "        node.pos = max([n.pos for n in node.prevs])+len(detok_tmp)\n",
    "    node.detoks = detok_tmp\n",
    "    node.canvpos = len(flat)-2+ len(detok_tmp)\n",
    "    \n",
    "flat = []\n",
    "def get_flat_lattice(gr):\n",
    "    global flat\n",
    "    flat = []\n",
    "    wordgraph = combine_nodes(gr)\n",
    "    print(\"Combined nodes - \", len(wordgraph))\n",
    "    # clear out prevs\n",
    "    for gk in wordgraph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        wordgraph[gk].prevs = []\n",
    "    # reset prevs\n",
    "    for gk in wordgraph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        for n in wordgraph[gk].nextlist:\n",
    "            n.prevs.append(wordgraph[gk])\n",
    "    greedy_traverse(wordgraph, add_to_flat)\n",
    "    print(\"Greedy traversal - \", len(flat))\n",
    "    cp = [f for f in flat]\n",
    "    return cp\n",
    "\n",
    "def split_dl_node(node):\n",
    "    if len(node.detoks)==1:\n",
    "        return [node]\n",
    "    res = []\n",
    "    # update previous of nodes\n",
    "    for i in range(len(node.detoks)):\n",
    "        n = node.detoks[i]\n",
    "        # make a copy of our base node\n",
    "        tmp = DLReverseNode(node)\n",
    "        if i>0:\n",
    "            tmp.prevs = [res[-1]]\n",
    "            # only have probability on 1\n",
    "            tmp.prob = 1\n",
    "        tmp.uid = tmp.uid+str(i)\n",
    "        tmp.pos = tmp.pos - (len(node.detoks)-i-1)\n",
    "        tmp.canvpos = tmp.canvpos - (len(node.detoks)-i-1)\n",
    "        tmp.token_idx = n\n",
    "        tmp.token_str = detok.decode(n)\n",
    "        res.append(tmp)\n",
    "    # update next connection of nodes\n",
    "    for i in range(len(res)-1):\n",
    "        if i<(len(node.detoks)-1):\n",
    "            res[i].next_ids = [res[i+1].uid]\n",
    "            res[i].nexts = [res[i+1]]\n",
    "    return res\n",
    "        \n",
    "def tokenize_flat_lattice(gr):\n",
    "    # get rid of first token, usually en_XX for french\n",
    "    print(\"original nodes - \", len(gr.keys()))\n",
    "    tmplist = gr['root'].nextlist[0].nextlist\n",
    "    tmpids = gr['root'].nextlist[0].next_ids\n",
    "    gr['root'].nextlist = tmplist\n",
    "    gr['root'].next_ids = tmpids\n",
    "    flatlat = get_flat_lattice(gr)\n",
    "    res = []\n",
    "    print(\"flatlat - \", len(flatlat))\n",
    "\n",
    "    for f in flatlat:\n",
    "        res.extend(split_dl_node(f))\n",
    "    print(\"final detokd - \", len(res))\n",
    "    return res\n",
    "    # we need to go through and convert this into lattices compatible \n",
    "    # with the format further into the pipeline, need to tokenize again with BERT\n",
    "    \n",
    "# disconnect / throw away node\n",
    "def throw_garbage(node, grph, lprevs=False):\n",
    "    assert len(node.prevs)==0 or len(node.nextlist)==0\n",
    "    for pre in node.prevs:\n",
    "        if node in pre.nextlist:\n",
    "            pre.nextlist.remove(node)\n",
    "        if node.uid in pre.next_ids:\n",
    "            pre.next_ids.remove(node.uid)\n",
    "\n",
    "    if lprevs:\n",
    "        for n in node.nextlist:\n",
    "            n.prevs.remove(node)\n",
    "    if node.uid not in grph.keys():\n",
    "        #print(\"w\")\n",
    "        \"\"\n",
    "    else:\n",
    "        del grph[node.uid]\n",
    "        \n",
    "# assume that previous nodes are consolidated, \n",
    "def consolidate_node(node, grph):\n",
    "    if node.uid not in grph.keys():\n",
    "        return\n",
    "    goneprevs = []\n",
    "    # check relationship with all previous nodes\n",
    "    for prev in node.prevs:\n",
    "        # it's a word boundary, no changes\n",
    "        comb = toker.decode(prev.token_idx+node.token_idx)\n",
    "        if \" \" in comb or \"</s>\" in comb:\n",
    "            continue\n",
    "        else:\n",
    "            # need to make new node, add necessary stuff\n",
    "            #print(comb)\n",
    "            tmp = DLReverseNode(node)\n",
    "            tmp.token_str = comb\n",
    "            tmp.token_idx = prev.token_idx+node.token_idx\n",
    "            tmp.prob = prev.prob*node.prob\n",
    "            tmp.prevs = []\n",
    "            tmp.prevs.extend(prev.prevs)\n",
    "            tmp.uid = prev.uid+node.uid\n",
    "            \n",
    "            # connect previous nodes\n",
    "            for pre in tmp.prevs:\n",
    "                pre.nextlist.append(tmp)\n",
    "                pre.next_ids.append(tmp.uid)\n",
    "            \n",
    "            grph[tmp.uid] = tmp\n",
    "            # cut off from others where necessary\n",
    "            goneprevs.append(prev)\n",
    "            \n",
    "            if node in prev.nextlist:\n",
    "                prev.nextlist.remove(node)\n",
    "                if node.uid in prev.next_ids:\n",
    "                    prev.next_ids.remove(node.uid)\n",
    "            \n",
    "            for t in tmp.nextlist:\n",
    "                t.prevs.append(tmp)\n",
    "            # prev now garbage, delete it\n",
    "            if len(prev.nextlist)==0:\n",
    "                throw_garbage(prev, grph, True)\n",
    "            \"\"\"\n",
    "            if comb==\"China’\":\n",
    "                print(\"nexts after\", len(tmp.nextlist))\n",
    "                print(tmp.uid)\n",
    "                print(tmp.nextlist[0].prevs[1].uid)\n",
    "            \"\"\"\n",
    "            \n",
    "    for g in goneprevs:\n",
    "        node.prevs.remove(g)\n",
    "    if len(node.prevs)==0:\n",
    "        throw_garbage(node, grph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dae76c-4ef0-4e8a-a981-9e9f0d2ca8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(75):\n",
    "    IND = 7\n",
    "    graph = pickle.load(open(base+str(i), 'rb'))\n",
    "    flatlat = tokenize_flat_lattice(graph)\n",
    "    print(len(flatlat))\n",
    "    #combnodes = combine_nodes(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e47080ef-7cfd-41d3-874e-7ce6c818d421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "616"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "648bf118-f865-48c4-a5e9-e2f305ff999a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.DLReverseNode at 0x7f1dd3336550>]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combnodes['root'].nextlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "005c1deb-474a-4a32-95ac-008cdc12271b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'China’s'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toker.decode([9098, 26, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e547b479-26a5-4bec-8391-30bce275d0d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9098"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e5a8f463-73b1-4ba8-a63c-4fc1144a5a8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "</s>\n",
      "5.7%.\n",
      ".\n",
      "percent.\n",
      "percent.\n",
      "11.2%.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "period.\n",
      "5.7%.\n",
      "11.2%.\n",
      "cent.\n",
      "11.2%.\n"
     ]
    }
   ],
   "source": [
    "for gk in combnodes.keys():\n",
    "    if len(combnodes[gk].nextlist)==0:\n",
    "        print(combnodes[gk].token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d9f47d2a-2da2-48f0-b8e1-7a8d874a1168",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(flatlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "defa2eff-9fba-461b-b084-5e089a27dcb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> 0',\n",
       " 'According 1',\n",
       " 'to 2',\n",
       " 'the 3',\n",
       " 'IMF 4',\n",
       " ', 5',\n",
       " 'annual 6',\n",
       " 'growth 7',\n",
       " 'in 8',\n",
       " 'China 9',\n",
       " '’ 10',\n",
       " 'China 6',\n",
       " '’ 7']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.token_str+\" \"+str(f.pos) for f in flatlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8807fb4e-a17b-479b-96b8-4148fe45d1f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'18NJKKHSH23R9FVYO1QW'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gra \u001b[38;5;241m=\u001b[39m \u001b[43mcombine_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m weirds \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(gra\u001b[38;5;241m.\u001b[39mkeys()))\n",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36mcombine_nodes\u001b[0;34m(gr)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_nodes\u001b[39m(gr):\n\u001b[0;32m---> 42\u001b[0m     dblgrph \u001b[38;5;241m=\u001b[39m \u001b[43mget_dbl_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#print(\"Doubly Linked - \", len(dblgrph.keys()))\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     greedy_traverse(dblgrph, consolidate_node)\n",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36mget_dbl_graph\u001b[0;34m(grph)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# this should handle everything having a previous list\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     newgrph[gk]\u001b[38;5;241m.\u001b[39mnextlist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     newgrph[gk]\u001b[38;5;241m.\u001b[39mnextlist \u001b[38;5;241m=\u001b[39m [newgrph[idl] \u001b[38;5;28;01mfor\u001b[39;00m idl \u001b[38;5;129;01min\u001b[39;00m newgrph[gk]\u001b[38;5;241m.\u001b[39mnext_ids]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gk \u001b[38;5;129;01min\u001b[39;00m newgrph\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gk\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m gk\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m gk\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrootid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# this should handle everything having a previous list\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     newgrph[gk]\u001b[38;5;241m.\u001b[39mnextlist \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m     newgrph[gk]\u001b[38;5;241m.\u001b[39mnextlist \u001b[38;5;241m=\u001b[39m [\u001b[43mnewgrph\u001b[49m\u001b[43m[\u001b[49m\u001b[43midl\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idl \u001b[38;5;129;01min\u001b[39;00m newgrph[gk]\u001b[38;5;241m.\u001b[39mnext_ids]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m gk \u001b[38;5;129;01min\u001b[39;00m newgrph\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gk\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m gk\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m gk\u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrootid\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: '18NJKKHSH23R9FVYO1QW'"
     ]
    }
   ],
   "source": [
    "gra = combine_nodes(graph)\n",
    "weirds = []\n",
    "print(len(gra.keys()))\n",
    "for gk in gra.keys():\n",
    "    if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "        continue\n",
    "    print(gra[gk])\n",
    "    if len(gra[gk].nextlist)==0:\n",
    "        \n",
    "        weirds.append(gra[gk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "38f0ecb8-688e-4a3b-9db7-44596967cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want - Another variable is the degree to which other developed countries’ monetary policies will ease.\n",
    "node = gra['root'].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[2].nextlist[0].nextlist[0].nextlist[1].nextlist[0].nextlist[1].nextlist[0].nextlist[0].nextlist[0].nextlist[2]\n",
    "for n in node.nextlist:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "55ca898e-7f70-4b45-8f66-a41fb6ad510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toker = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e69abd10-c62a-4dd0-8b2d-25e1a1b0074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublegraph = get_dbl_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8142d22a-c599-40bf-ab43-25f2f067dac6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<__main__.DLReverseNode at 0x7efc32d8bdc0>]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doublegraph['root'].nextlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d4fb132-0782-4f76-8909-2fc6aa1149c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ReverseNode' object has no attribute 'prevs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [28]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombine_nodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mcombine_nodes\u001b[0;34m(gr)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombine_nodes\u001b[39m(gr):\n\u001b[1;32m     88\u001b[0m     dblgrph \u001b[38;5;241m=\u001b[39m get_dbl_graph(gr)\n\u001b[0;32m---> 89\u001b[0m     \u001b[43mgreedy_traverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdblgrph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate_node\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dblgrph\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mgreedy_traverse\u001b[0;34m(gr, fun)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(queue)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     76\u001b[0m     cur \u001b[38;5;241m=\u001b[39m queue\u001b[38;5;241m.\u001b[39mpop()\n\u001b[0;32m---> 77\u001b[0m     \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcur\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     order \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(cur\u001b[38;5;241m.\u001b[39mnext_scores)\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# highest prob gets popped off first\u001b[39;00m\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mconsolidate_node\u001b[0;34m(node, grph)\u001b[0m\n\u001b[1;32m     66\u001b[0m     node\u001b[38;5;241m.\u001b[39mprevs\u001b[38;5;241m.\u001b[39mremove(g)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mprevs)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 68\u001b[0m     \u001b[43mthrow_garbage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrph\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [27]\u001b[0m, in \u001b[0;36mthrow_garbage\u001b[0;34m(node, grph)\u001b[0m\n\u001b[1;32m     29\u001b[0m     pre\u001b[38;5;241m.\u001b[39mnext_ids\u001b[38;5;241m.\u001b[39mremove(node\u001b[38;5;241m.\u001b[39muid)\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m node\u001b[38;5;241m.\u001b[39mnextlist:\n\u001b[0;32m---> 31\u001b[0m     \u001b[43mn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprevs\u001b[49m\u001b[38;5;241m.\u001b[39mremove(node)\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m grph[node\u001b[38;5;241m.\u001b[39muid]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ReverseNode' object has no attribute 'prevs'"
     ]
    }
   ],
   "source": [
    "combine_nodes(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4400970-2136-44e1-a7b0-a46e07bfb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO delete if not useful\n",
    "def update_node_prevs(dblgraph, node):\n",
    "    # check if already in existing nodes\n",
    "    if node.uid in dblgraph.keys():\n",
    "        return\n",
    "    # TODO make sure to use the right kind of node\n",
    "    cur = node\n",
    "    while len(cur.nextlist)==1:\n",
    "        if cur.nextlist[0].uid in dblgraph.keys():\n",
    "            tmp = dblgraph[cur.nextlist[0].uid]\n",
    "        else:\n",
    "            tmp = DLReverseNode(cur.nextlist[0])\n",
    "        tmp.prevs.append(cur)\n",
    "        # don't keep going if we've already done this node at some point\n",
    "        if cur.nextlist[0].uid in dblgraph.keys():\n",
    "            return \n",
    "        dblgraph[cur.nextlist[0].uid] = tmp\n",
    "        cur = tmp\n",
    "    # hit the end of segment, multiple choices now\n",
    "    if len(cur.nextlist)>1:\n",
    "        for n in cur.nextlist:\n",
    "            if n.uid in dblgraph.keys():\n",
    "                nnode = dblgraph[n.uid]\n",
    "            else:\n",
    "                nnode = DLReverseNode(n)\n",
    "            nnode.prevs.append(cur)\n",
    "            dblgraph[n.uid] = nnode\n",
    "            update_node_prevs(dblgraph, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "341f4c18-f49b-4ab8-ba04-e465e5a22e93",
   "metadata": {},
   "source": [
    "graph = get_dbl_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8958800f-412b-4354-96a5-0e9bdd409345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'</s>'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist[0].prevs[1].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb7663-5c87-43ef-8d6f-7de7f028143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten out lattice \n",
    "def flatten_lattice(graph):\n",
    "    tokdicts = []\n",
    "    visited = []\n",
    "    prev_contig = []\n",
    "    greedy_flatten(tokdicts, visited, graph['root'], 0, prev_contig, set())\n",
    "    #greedy_flat_old(tokdicts, visited, graph['root'], 0)\n",
    "    return tokdicts\n",
    "\n",
    "max_splits = -1\n",
    "splits_hit = 0\n",
    "# flattens graph by position, ignores </s> and en_XX tokens for greater BERT compatibility\n",
    "# TODO set up to use mbart tokenization\n",
    "def greedy_flatten(tdicts, visited, node, pos, prev_cont, added_ids, branch_start=None):\n",
    "    global splits_hit\n",
    "    if node.uid in visited:\n",
    "        return\n",
    "    if node.token_idx==2 or node.token_idx==250004:\n",
    "        npos = pos\n",
    "    else:\n",
    "        node.pos = pos\n",
    "        \n",
    "        visited.append(node.uid)\n",
    "        npos = pos+1\n",
    "        s = node.token_str\n",
    "        prev_cont.append(node)\n",
    "    \n",
    "    olen = len(tdicts)\n",
    "    # we're hitting a branch or an ending, update to bert tokenization and add to visited\n",
    "    # should be ok to do this since branching / merging only happens at word boundaries (presumably)\n",
    "    branched = (len(node.next_scores)>1)\n",
    "    end = (len(node.next_scores)==0)\n",
    "    merge = end==False and node.nextlist[0].uid in visited\n",
    "    if branched or merge or end:\n",
    "        if len(prev_cont)>0:\n",
    "            errorflag = False\n",
    "            \n",
    "            prev_update = []\n",
    "            for p in prev_cont:\n",
    "                if p.uid in added_ids:\n",
    "                    continue\n",
    "                else:\n",
    "                    prev_update.append(p)\n",
    "                    added_ids.add(p.uid)\n",
    "            \n",
    "            if len(prev_update)>0:\n",
    "                toktmp = get_toklist(prev_update)\n",
    "                for i in range(1, len(prev_update)):\n",
    "                    if prev_update[-(i+1)].pos>=prev_update[-i].pos:\n",
    "                        errorflag = True\n",
    "                        break\n",
    "                decstr = mbart_tok.decode(toktmp)\n",
    "                if errorflag:\n",
    "                    #print(decstr)\n",
    "                    #print([p.pos for p in prev_update])\n",
    "                    \"\"\n",
    "                bert_toks = bert_tok(decstr).input_ids\n",
    "                curpos = prev_update[0].pos\n",
    "                # TODO add logic that tracks scores / next nodes\n",
    "                otdlen = len(tdicts)\n",
    "                for bind in range(0, len(bert_toks)):\n",
    "                    b = bert_toks[bind]\n",
    "                    # change to 101, 102 for bert, change to 0, 2 for xlm\n",
    "                    if b==0 or b==2:\n",
    "                        continue\n",
    "                    nid = str(b)+\" \"+str(curpos)\n",
    "                    # if we're at the start, add this node to next of branch node\n",
    "                    if len(tdicts)==otdlen and branch_start is not None:\n",
    "                        branch_start['nexts'].append(nid)\n",
    "\n",
    "                    if bind<len(bert_toks)-1:\n",
    "                        tdicts.append({\n",
    "                            'token_idx':b,\n",
    "                            'pos':curpos, \n",
    "                            'id': nid,\n",
    "                            'nexts': [str(bert_toks[bind+1])+\" \"+str(curpos+1)], \n",
    "                            'score': 0\n",
    "                        })\n",
    "                    else:\n",
    "                        tdicts.append({\n",
    "                            'token_idx':b,\n",
    "                            'pos':curpos, \n",
    "                            'id': str(b)+\" \"+str(pos),\n",
    "                            'nexts': [], \n",
    "                            'score': 0\n",
    "                        })\n",
    "                    curpos+=1\n",
    "                if merge or end:\n",
    "                    splits_hit+=1\n",
    "            \n",
    "    if len(tdicts)>olen:\n",
    "        del prev_cont\n",
    "        prev_cont = []\n",
    "        \n",
    "    # end things early if we want to limit paths\n",
    "    if max_splits>=0 and splits_hit>=max_splits:\n",
    "        return \n",
    "    \n",
    "    scosort = list(np.argsort(node.next_scores))\n",
    "    if branched and len(tdicts)>0:\n",
    "        branch_start=tdicts[-1]\n",
    "    # TODO check which direction we need to go from argsort\n",
    "    for i in range(0, len(scosort)):\n",
    "        greedy_flatten(tdicts, visited, node.nextlist[scosort[i]], npos, prev_cont, added_ids, branch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ff318-1019-447f-aa3d-425712aa1265",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
