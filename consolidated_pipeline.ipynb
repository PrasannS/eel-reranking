{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b0277c5-597c-40bf-9ef6-8916d34e067c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-20 13:22:15.490820: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-20 13:22:15.490843: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from efficient_rerank import run_pipeline, XLMCometEmbeds\n",
    "import torch\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.recom_search.model.beam_node_reverse import ReverseNode\n",
    "import numpy as np\n",
    "import math \n",
    "from new_flatten_lattice import get_dictlist\n",
    "import flatten_lattice as fl\n",
    "xlm_tok = fl.bert_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fc252b0-4c3e-42ff-b48e-54c335ac8bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5017861b-fbeb-4215-954e-2f0c3347df82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7bb58312-1bf6-4af2-a53f-94b27d2b4ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'_26267_3445_38', '_10_4127_3445', '_10_26267_3445', '_444_10_26267', '_87_444_10', '_10_6957_3445', '_4127_3445_38', '_6957_3445_38', '_444_10_4127', '_444_10_6957', '_0_87_444'}\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "testcands = [\n",
    "    \"I am a nice person!\",\n",
    "    \"I am a big person!\",\n",
    "    \"I am a good person!\"\n",
    "]\n",
    "cn = cand_unique_ngrams(testcands, xlm_tok, 3)\n",
    "print(cn)\n",
    "print(len(cn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72b5db28-8b38-4e95-9987-4c25479f423f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 87, 444, 10, 6782, 3445, 38, 2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'_0_87_444', '_10_6782_3445', '_444_10_6782', '_6782_3445_38', '_87_444_10'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_unique_ngrams(\"I am a great person!\", xlm_tok, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78bed72-189c-4aec-9fe8-a35ca44ba4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from new_mask_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1301527-510a-4937-8e1b-04e84ed98188",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load in model, for french\n",
    "#del model\n",
    "model = XLMCometEmbeds(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/maskedcont4.pt\"))\n",
    "model.eval()\n",
    "torch.cuda.memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "241836e0-2116-4891-8ff1-983630db4455",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds = pd.read_csv('torchsaved/frenchlatpreds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "571b64e2-a3a1-4dd2-b7ef-ea8816d08334",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' After all, as an investigative reporter in the countryside, she has ensnared many other people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, who she has accused of conducting a ransom-abduction policy.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frpreds.loc[0]['ahyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc6e7c-a8eb-4b3d-88cd-4da20d8df328",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds.loc[0]['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daedc160-cab5-40d6-bdad-e48eb0c1ffb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\"\n",
    "\n",
    "def test_flatten(ind, basedir):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    return get_dictlist(g, True)\n",
    "\n",
    "def test_graph_ind(ind, basedir, scofunct):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    return g['input'], g['ref'], run_pipeline(g, model, scofunct, False, 10)\n",
    "    #flattened, flnodes\n",
    "    \n",
    "def test_graph_verb(ind, basedir, scofunct):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    return run_pipeline(g, model, scofunct, True)\n",
    "\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    #res.to_csv(\"latfound2\"+basedir[:-4]+\".csv\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f84a9fc2-9bf0-4d46-9a1b-6200ffe7ecfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def default_scofunct (node, unused):\n",
    "    global pcnt\n",
    "    try:\n",
    "        return node.score\n",
    "    except:\n",
    "        pcnt+=1\n",
    "        return 0\n",
    "\n",
    "#npcnt = 0\n",
    "def addprob (node, unused):\n",
    "    global pcnt, npcnt\n",
    "    if \"prob\" in node.keys():\n",
    "        #pcnt+=1\n",
    "        return math.log(node['prob']) + node['score']\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "\n",
    "WEIGHT=50\n",
    "def weightaddprob (node, unused):\n",
    "    global pcnt, npcnt\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "DIVWEIGHT = 1\n",
    "# should this be more complex\n",
    "def weightadddiverse (node, used):\n",
    "    global usedlist\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node.token_idx in used:\n",
    "            # TODO maybe we need to add an element that factors in position as well\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "\n",
    "def multprob (node):\n",
    "    if \"prob\" in node.keys():\n",
    "        #pcnt+=1\n",
    "        return node['prob'] * node['score']\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "38fae46c-ccb7-44dc-8a13-8869d068aced",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original nodes -  682\n",
      "final detokd -  706\n",
      "maxend , 56\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "maxend , 57\n",
      "SRC - Apr√®s tout, en tant que journaliste d'investigation en campagne, elle a enrag√© beaucoup d'autres gens outre Poutine, parmi lesquels l'actuel Premier ministre tch√©tch√®ne Ramzan Kadyrov n'est pas des moindres, qu'elle a accus√© de mener une politique d'enl√®vements contre ran√ßons. \n",
      "PRED - </s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.\n",
      "REF - After all, as a campaigning investigative journalist she made many people angry besides Putin, not least of which is the current Chechen Prime Minister, Ramzan Kadyrov, whom she accused of a policy of kidnapping for ransom. \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(\"Apr√®s tout, en tant que journaliste d'investigation en campagne, elle a enrag√© beaucoup d'autres gens outre Poutine, parmi lesquels l'actuel Premier ministre tch√©tch√®ne Ramzan Kadyrov n'est pas des moindres, qu'elle a accus√© de mener une politique d'enl√®vements contre ran√ßons. \",\n",
       " 'After all, as a campaigning investigative journalist she made many people angry besides Putin, not least of which is the current Chechen Prime Minister, Ramzan Kadyrov, whom she accused of a policy of kidnapping for ransom. ',\n",
       " ['</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has ensnared many others besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, whom she has accused of pursuing a policy.',\n",
       "  '</s> After all, as a field investigating the countryside, she has in many other people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as an investigative journalist working in the field, she in many other people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.',\n",
       "  '</s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, the least of kidnapping for ransom.'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_graph_ind(0, base, weightadddiverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e60ec539-66d0-48fc-978c-f8e5152b98f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mt_scores import get_scores_auto\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a688977f-e6e8-4848-9fe1-054dc94be324",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(listvals):\n",
    "    return sum(listvals)/len(listvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37dac549-b550-46e1-93ca-08f33ee5e14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e3beca-7673-4f7d-823f-83eee23ecf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#defpreds = get_all_preds(base, default_scofunct)\n",
    "#multpreds = get_all_preds(base, multprob)\n",
    "#WEIGHT=20\n",
    "#weightaddprob = get_all_preds(base, weightaddprob)\n",
    "#weightaddprob.to_csv(\"waddpredsw20.csv\")\n",
    "WEIGHT=24\n",
    "starttime = time.time()\n",
    "weightaddprobdf = get_all_preds(base, weightadddiverse)\n",
    "totaltime = round((time.time() - starttime), 2)\n",
    "#weightaddprobdf.to_csv(\"scontcompressedwadd.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f5747567-46f2-4cb4-83dd-674b2ae07ca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> There is good reason to fearing that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.',\n",
       " '</s> There is good reason to fear that these increasingly marked divisions will find their way into the new composition of the majority in the European Parliament, making governance difficult, not to say impossible.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weightaddprobdf.loc[5]['hyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c12d5e89-26ba-434a-84ec-cefa2ee6c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# waddpreds1 has weight of 50 on scores\n",
    "# waddpreds2 has weight of 100 on scores\n",
    "# 3 has weight of 100, new pipeline\n",
    "# 4 has weight of 50, new pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a363120-c2df-4d59-b622-2716165d1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "defpreds.to_csv(\"defpreds.csv\")\n",
    "multpreds.to_csv(\"multpreds.csv\")\n",
    "weightaddprob.to_csv(\"waddpreds.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b8cda5-9eff-4b0b-b534-f153f8c0b535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ISSUE using the whole thing during DP as opposed to just what's necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa0653b-5882-4b15-98e2-df62efa0382b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pnodes = prepare_nodes([flnodes[:512-(posadd)]], pred[0], posadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a28029f-2efc-4b5c-8203-7430327909bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath, beplist, besclist = dynamic_path(pnodes[0], weightaddprob, posadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfaa428-984e-484d-b8b6-66c845d4d628",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlm_tok.decode([dp.token_idx for dp in dpath])\n",
    "#[dp.token_str for dp in dpath]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35291e33-54d8-4e2e-b62c-4fb073c669b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "besclist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891bd23-fb96-4d62-8696-a6ca332effde",
   "metadata": {},
   "outputs": [],
   "source": [
    "flnodes[:512-(posadd)][-1].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5185b158-67fe-491d-aeea-6d1775e7129f",
   "metadata": {},
   "outputs": [],
   "source": [
    "topo_sort_nodes(flnodes[:512-(posadd)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e54bec-89bb-4542-b2e4-3d2128350b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened[:512][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee53e102-5ab5-4576-a705-916349d7b0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.token_str for f in pnodes[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ae9f60-99fd-4adf-b62b-f47dae3683f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check to make sure sorting is happening correctly\n",
    "res = []\n",
    "for f in pnodes[0]:\n",
    "    dpposes = []\n",
    "    for prev in f.prevs:\n",
    "        if prev.dppos>f.dppos:\n",
    "            dpposes.append(prev.token_str)\n",
    "        #print(f.dppos)\n",
    "    dpposes.append(f.token_str)\n",
    "    res.append(dpposes)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fdf877-1b34-4b8d-93fd-b4265294338f",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = [0]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d51fba-13d7-49e0-a777-5308343e6602",
   "metadata": {},
   "outputs": [],
   "source": [
    "posadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06a0b59e-8d58-47b8-84b0-a6141fb11ef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 41., 111., 107.,  89.,  44.,  35.,  17.,   6.,   5.,   2.]),\n",
       " array([ 66., 130., 194., 258., 322., 386., 450., 514., 578., 642., 706.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(totdistr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed6f9e-f6ca-4b82-ba73-da19f71801f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "totdistr = []\n",
    "for i in range(0, 457):\n",
    "    best , flattened, prepared_pgraphs, mask, sents, posids, pred, posadd, flnodes, bp, beplist, besclist, nolen = test_graph_verb(i, base, weightaddprob)\n",
    "    totdistr.append(nolen+posadd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f782f43a-60c8-4bc7-b9c3-d77ca977b1d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original nodes -  429\n",
      "final detokd -  438\n",
      "maxend , 16\n",
      "suboptimal,  ['</s>', 'A', 'prudent', 'fiscal', 'policy', 'approach', ',', 'introduce', 's', 'the', 'space', 'for', 'lower', 'social', 'contribution', '.']\n",
      "SRC - Une d√©marche fiscale prudente mise en place alors que l'√©conomie reprenait et que les taux d'int√©r√™ts baissaient cr√©a l'espace n√©cessaire √† une fiscalit√© r√©duite et √† la baisse des cotisations sociales. \n",
      "PRED - </s> A prudent fiscal policy approach, introduces the space for lower social contribution.\n",
      "REF - A prudent fiscal stance, pursued while the economy recovered and interest rates fell, created room for big cuts in taxes and social contributions. \n",
      "285\n",
      "236\n",
      "236\n"
     ]
    }
   ],
   "source": [
    "pcnt = 0\n",
    "IND = 46\n",
    "best , flattened, prepared_pgraphs, mask, sents, posids, pred, posadd, flnodes, bp, beplist, besclist, nolen = test_graph_verb(IND, base, weightaddprob)\n",
    "print(len(flattened))\n",
    "print(len(prepared_pgraphs[0]))\n",
    "print(nolen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e411aad5-d595-4dd1-8c1d-48bfe80cff47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(bp) for bp in beplist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c3967bf2-4877-4dc7-898f-c275872637da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posadd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02f2ee6b-4245-4823-b665-533e004bbb9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "427"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nset = set()\n",
    "for f in flnodes:\n",
    "    nset.add(str(f.token_idx)+str(f.pos))\n",
    "len(nset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea64acdc-e271-4691-96d0-d5304469260f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(beplist[445])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5f84a9db-3080-4e7f-8e71-24cd261017f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DLReverseNode' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m s \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prepared_pgraphs[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m----> 3\u001b[0m     s\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39m xlm_tok\u001b[38;5;241m.\u001b[39mdecode(\u001b[43mp\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtoken_idx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m) \n\u001b[1;32m      4\u001b[0m s\n",
      "\u001b[0;31mTypeError\u001b[0m: 'DLReverseNode' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "s = \"\"\n",
    "for p in prepared_pgraphs[0]:\n",
    "    s+=\" \"+ xlm_tok.decode(p['token_idx']) \n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a6c8fb-f700-4725-aa73-7782edc763ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae2a037-5780-4a9c-b4b0-da8955c13d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened[34:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3430f1-6dfe-473f-82b0-8548f88b5ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e21c9b-85c6-49a5-b241-49c09f71fa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flnodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6b569-f66d-482a-b21b-a0c1d904cff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity checks - \n",
    "# - are the scores actually storing probabilities? YES\n",
    "# - flnodes has different length than flattened? nevermind that's just because of weirdness from earlier\n",
    "[math.log(fl.prob) for fl in flnodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1ca460-c344-4fef-8727-72456d132c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[32:, 32:][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5de76dc-b32e-4e54-81d3-cb6404501fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_pgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067f9a40-2e09-481a-b447-3cdf844d23fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.sum(mask[32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21411664-7bce-4e18-ba53-ba6a929afcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_context(ind):\n",
    "    row = mask[ind]\n",
    "    cont = \" \" \n",
    "    indtmp = 0\n",
    "    for c in row:\n",
    "        if c>0:\n",
    "            cont = cont + \" \" + xlm_tok.decode(sents[0][indtmp])\n",
    "        indtmp+=1\n",
    "    cont += \" : \" +xlm_tok.decode(sents[0][ind])\n",
    "    return cont[160:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358850b1-479a-4ff8-af70-15a74a149f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask[32:350, 32:350][60]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df49c3-7ba7-42f6-8a36-7b3e371188de",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlen = min(512-(posadd+1), len(flnodes))\n",
    "maxpos = mask_prep_canv(flnodes)\n",
    "back_adjac = adj_mat(flnodes, mlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1902f0e-3a4d-49dd-97cd-79b501713fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "flnodes[5].prevs[0].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "102a579f-7858-4ec3-bbff-9d35da46641f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = back_adjac\n",
    "tmp = back_adjac\n",
    "# keep on going until all nodes hit the back\n",
    "while torch.sum((tot[:, 0]>0))<(mlen-1):\n",
    "    tmp = torch.mm(back_adjac, tmp)\n",
    "    tot += tmp\n",
    "tot = tot+ torch.eye(mlen)\n",
    "return (tot>0).int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125b4b30-68bf-46f9-8415-4688a8ea2c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best , flattened, prepared_pgraphs, mask, sents, posids, pred\n",
    "\n",
    "decs = [xlm_tok.decode(d['token_idx']) for d in flattened]\n",
    "for d in decs:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce678fd-bf61-4ac7-987f-5431977f2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(retvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd478df-c770-45a7-b594-10694934c039",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ppres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ccfec1-1237-4959-9db8-39c9590212b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds = get_all_preds(\"frtest_reversed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1a9268-4d4c-4c76-8848-14d3c1900826",
   "metadata": {},
   "outputs": [],
   "source": [
    "depreds = get_all_preds(\"detest_reversed/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a033cea6-d17a-4d5a-a192-e2f4f3fd0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"frtest_reversed/\"\n",
    "l = len(os.listdir(basedir))\n",
    "res = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5693b273-1868-4eea-b570-4afaac3eacb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(l):\n",
    "    i, r, p = test_graph_ind(i, basedir)\n",
    "    if i==None:\n",
    "        continue\n",
    "    res.append({\n",
    "        'src':i,\n",
    "        'hyp':p,\n",
    "        'ref':r\n",
    "    })\n",
    "    print(i)\n",
    "resdf = pd.DataFrame(res)\n",
    "frpreds = resdf\n",
    "#resdf.to_csv(\"frenchlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0c78d6-9dbb-47be-9c4c-4796f4fc943b",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "model = er.XLMCometEmbeds(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/germanlat0.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd515659-0416-42a2-86da-3895978bba96",
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = \"detest_reversed/\"\n",
    "l = len(os.listdir(basedir))\n",
    "res = []\n",
    "for i in range(l):\n",
    "    i, r, p = test_graph_ind(i, basedir)\n",
    "    res.append({\n",
    "        'src':i,\n",
    "        'hyp':p,\n",
    "        'ref':r\n",
    "    })\n",
    "    print(i)\n",
    "resdf = pd.DataFrame(res)\n",
    "depreds = resdf.to_csv(\"germanlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72698460-e7c3-4a22-8f00-82fbc73e08b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "resdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fbb45d-e007-49d0-a5c5-052e2f4efc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds = pd.read_csv(\"frenchlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8106d2-9ebf-4bb9-8efa-3c1506c45410",
   "metadata": {},
   "outputs": [],
   "source": [
    "depreds.loc[0]['hyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e471f-3c24-4013-b944-0a4629e5baea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_hyps(hyplist, cutoff):\n",
    "    res = []\n",
    "    for h in hyplist:\n",
    "        cind = h[3:].index(cutoff)+len(cutoff)+3\n",
    "        res.append(h[cind:])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2eab03-5dda-47b4-aa6f-34d4dda63220",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds['ahyp'] = get_act_hyps(frpreds['hyp'], \"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39931db3-4144-498d-b86d-5d4ac6b398c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c53317-3d89-4ee7-92f1-c7300d24d77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comet_scores(hyps, srcs, refs):\n",
    "    cometqe_input = [{\"src\": src, \"mt\": mt, \"ref\":ref} for src, mt, ref in zip(srcs, hyps, refs)]\n",
    "    # sentence-level and corpus-level COMET\n",
    "    outputs = comet.predict(\n",
    "        cometqe_input, batch_size=32, progress_bar=True\n",
    "    )\n",
    "    torch.cuda.empty_cache()\n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cd529d-651b-4c35-be71-4a02b2215d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cometqe_dir = \"./cometqemodel\"\n",
    "# can alternatively use wmt21-comet-qe-mqm\n",
    "cometqe_model = \"wmt20-comet-qe-da\"\n",
    "cometmodel = \"wmt20-comet-da\"\n",
    "batch_size = 64\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb818c35-c952-4abe-8f40-36525db80650",
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb564d2a-71a8-45b5-94bd-fa6febff5bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "comet_path = download_model(cometmodel, \"./cometmodel\")\n",
    "comet = load_from_checkpoint(comet_path)\n",
    "comet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95f2c3f-e859-40af-a1c8-46969d4b9d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441afbe0-62a4-4e58-88d8-c1364bbb8108",
   "metadata": {},
   "outputs": [],
   "source": [
    "scos = get_comet_scores(frpreds['ahyp'], frpreds['src'], frpreds['ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cab774-12cf-4eec-b8db-074c56af3046",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds['scos'] = scos[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b473785-da12-4209-a20a-12f9c6a3d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds.to_csv(\"frenchlatpreds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accf2281-f9ee-4281-8bb3-b6f146e38e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "frpreds[frpreds['scos']<0].loc[25]['ref']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33354134-a51e-48f2-9875-2f980a3479a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(depreds['scos'])/1077"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd7acd6-4f7f-41a5-89b8-d3dff858f317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a734ac70-7e88-48c0-8d65-5c3df8e21f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(frpreds['scos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ed32b-55a6-4577-a50b-6907a4059c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = fl.bert_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fd36b-78cb-4c21-9dc4-0d0098ccb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pickle.load(open(base+str(2), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ec2b19-50a8-459a-b14f-d7de1a28554f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['root'].prevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc3dd1b-68ac-437f-864e-0980f0bdf14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debugging stuff out \n",
    "# override this function\n",
    "# TODO will need to update if there are new changes\n",
    "flattened = fl.flatten_lattice(graph)\n",
    "ppinput = prepend_input(flattened, graph['input'])\n",
    "flattened = ppinput[0]\n",
    "covered = fl.get_cover_paths(flattened)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63935f-f6fb-418f-b5a0-01637bf91277",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tind(ftd, val):\n",
    "    finds = []\n",
    "    ind = 0\n",
    "    for t in ftd:\n",
    "        if val in tok.decode(t['token_idx']):\n",
    "            print(tok.decode(t['token_idx']))\n",
    "            print(ind)\n",
    "            finds.append(ind)\n",
    "            \n",
    "        ind+=1\n",
    "    return finds\n",
    "\n",
    "def find_byid(ftd, idval):\n",
    "    i = 0\n",
    "    for t in ftd:\n",
    "        \n",
    "        if t['id']==idval:\n",
    "            print(i)\n",
    "            return t\n",
    "        i+=1\n",
    "    return None\n",
    "\n",
    "def track_to_end(ftd, tstart):\n",
    "    cur = tstart\n",
    "    while len(cur['nexts'])>0:\n",
    "        print(tok.decode(cur['token_idx']))\n",
    "        #print(len(cur['nexts']))\n",
    "        itmp = -1\n",
    "        while find_byid(ftd, cur['nexts'][itmp]) is None:\n",
    "            itmp-=1\n",
    "        cur = find_byid(ftd, cur['nexts'][itmp])\n",
    "find_tind(flattened, \"Another\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec4139-e8b4-452f-9c42-281223c9cbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened[351]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbf462a-fcb7-428e-aaf1-a0bb48511312",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_to_end(flattened, flattened[335])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602bb659-fe20-43aa-8347-0391ace0a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "find_byid(flattened, '3789 40')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a7a5fc-7c8b-4d5e-a3d6-89eebe49ef60",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.decode(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2961f373-1996-4ff1-b027-8cd561640203",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flattened)\n",
    "# We want - Another variable is the degree to which other developed countries‚Äô monetary policies will ease.\n",
    "# We got - The other variable is the extent to which other developed economies‚Äô monetary policies will become more liberal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d899d4-6e03-4f8c-b08d-0186bfdaf61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "posadd = ppinput[1]\n",
    "mask = causal_mask(flattened, posadd)\n",
    "sents, posids = create_inputs([flattened])\n",
    "with torch.no_grad():\n",
    "    pred = model(sents, posids, mask.unsqueeze(0).to(device))\n",
    "fls = [flattened]\n",
    "prepared_pgraphs = prepare_pgraphs(fls, pred[0])\n",
    "bestpath = dp_pgraph(prepared_pgraphs[0])\n",
    "best = xlm_tok.decode(bestpath)\n",
    "print(\"SRC - \"+graph['input'])\n",
    "print(\"PRED - \"+best)\n",
    "print(\"REF - \"+graph['ref'])\n",
    "# return best, covered, flattened, prepared_pgraphs, mask, sents, posids, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17edc620-4d49-4181-8d71-72261679e912",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok.decode([t['token_idx'] for t in prepared_pgraphs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a17fe5c-d42e-4e5e-939d-8da7ade66362",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['root'].nextlist[0].nextlist[1].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1015a08c-4010-419c-9b8a-059eb443b001",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vis_node(node):\n",
    "    for no in node.nextlist:\n",
    "        print(no.token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ab4442-fe8c-4c74-a92c-38af47367b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want - Another variable is the degree to which other developed countries‚Äô monetary policies will ease.\n",
    "vis_node(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ee3b89-f9ca-4ce1-9da0-8c5c6b70f648",
   "metadata": {},
   "outputs": [],
   "source": [
    "n.prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4c4ef-5cc6-4337-8e63-f8c6125ad528",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20813e8-9669-4c00-866f-874b120667b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from new_flatten_lattice import get_dictlist\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978e1f75-b0ea-4aa4-87e3-7b7550087bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatlat = get_dictlist(base+str(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee478cfe-7a73-4b06-b121-acce9211fe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "overcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111ca787-0a71-40ee-95a2-6cab190d2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "overcnt = 0\n",
    "for ind in range(450):\n",
    "    fl = get_dictlist(base+str(ind))\n",
    "\n",
    "    if len(fl)>450:\n",
    "        overcnt+=1\n",
    "overcnt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b24ea03-b25b-486c-991f-774b24627325",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DLReverseNode():\n",
    "    def _get_dictlist_(self, oldnode):\n",
    "        self.uid = oldnode.uid\n",
    "        self.prob = oldnode.prob\n",
    "        self.token_idx = oldnode.token_idx\n",
    "        self.token_str = oldnode.token_str\n",
    "        self.nextlist = oldnode.nextlist\n",
    "        self.next_scores = oldnode.next_scores\n",
    "        self.next_ids = oldnode.next_ids\n",
    "        self.prevs = []\n",
    "        self.detoks = []\n",
    "        self.pos = -1\n",
    "        self.canvpos = 1000\n",
    "        if oldnode.pos>0:\n",
    "            self.prevs = oldnode.prevs\n",
    "            self.pos = oldnode.pos\n",
    "            self.detoks = oldnode.detoks\n",
    "            self.canvpos = oldnode.canvpos\n",
    "        \n",
    "    def __str__(self):\n",
    "        return self.token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e080d3-f4af-497f-92b2-a7db2f66db58",
   "metadata": {},
   "outputs": [],
   "source": [
    "del dblgrph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0780c1-d518-4e3c-9286-9a7c7c275fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\"\n",
    "toker = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "detok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e3d7ca-f897-44d1-a14e-bea8eda63689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO later on just move this to the initial graph reversal\n",
    "def get_dbl_graph(grph):\n",
    "    newgrph = {}\n",
    "    for g in grph.keys():\n",
    "        if g==\"input\" or g== \"ref\" or g== \"rootid\":\n",
    "            continue\n",
    "        tmp = DLReverseNode(grph[g])\n",
    "        newgrph[g] = tmp\n",
    "    for gk in newgrph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        # this should handle everything having a previous list\n",
    "        newgrph[gk].nextlist = None\n",
    "        newgrph[gk].nextlist = [newgrph[idl] for idl in newgrph[gk].next_ids]\n",
    "    for gk in newgrph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        for n in newgrph[gk].nextlist:\n",
    "            n.prevs.append(newgrph[gk])\n",
    "        newgrph[gk].token_idx = [newgrph[gk].token_idx]\n",
    "    # TODO do something to update scores on word graph\n",
    "    return newgrph\n",
    "\n",
    "# greedily traverse graph, run function on each node\n",
    "def greedy_traverse(gr, fun, norev=True):\n",
    "    queue = []\n",
    "    queue.append(gr['root'])\n",
    "    visited = []\n",
    "    while len(queue)>0:\n",
    "        cur = queue.pop()\n",
    "        fun(cur, gr)\n",
    "        order = np.argsort([n.prob for n in cur.nextlist])\n",
    "        # highest prob gets popped off first\n",
    "        for o in order:\n",
    "            if cur.uid not in visited:\n",
    "                queue.append(cur.nextlist[o])\n",
    "        visited.append(cur.uid)\n",
    "                \n",
    "# make so graph has word-only nodes, check tokenization at different node boundaries\n",
    "# update pointers afterwards\n",
    "def combine_nodes(gr):\n",
    "    dblgrph = get_dbl_graph(gr)\n",
    "    #print(\"Doubly Linked - \", len(dblgrph.keys()))\n",
    "    greedy_traverse(dblgrph, consolidate_node)\n",
    "    rmlist = []\n",
    "    for d in dblgrph.keys():\n",
    "        if d==\"input\" or d== \"ref\" or \"root\" in d:\n",
    "            continue\n",
    "        if len(dblgrph[d].prevs)==0:\n",
    "            rmlist.append(d)\n",
    "    for r in rmlist:\n",
    "        del dblgrph[r]\n",
    "    return dblgrph\n",
    "\n",
    "# do this on every node greedily to get flattened lattice canvas\n",
    "def add_to_flat(node, grph):\n",
    "    global flat\n",
    "    if node.canvpos<1000:\n",
    "        return\n",
    "    flat.append(node)\n",
    "    # get detokenization\n",
    "    detok_tmp = detok(node.token_str).input_ids[1:-1]\n",
    "    # update pos on first greedy hit\n",
    "    if len(node.prevs)==0:\n",
    "        node.pos = -1 + len(detok_tmp)\n",
    "    if node.pos==-1:\n",
    "        node.pos = max([n.pos for n in node.prevs])+len(detok_tmp)\n",
    "    node.detoks = detok_tmp\n",
    "    node.canvpos = len(flat)-2+ len(detok_tmp)\n",
    "    \n",
    "flat = []\n",
    "def get_flat_lattice(gr):\n",
    "    global flat\n",
    "    flat = []\n",
    "    wordgraph = combine_nodes(gr)\n",
    "    # print(\"Combined nodes - \", len(wordgraph))\n",
    "    # clear out prevs\n",
    "    for gk in wordgraph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        wordgraph[gk].prevs = []\n",
    "    # reset prevs\n",
    "    for gk in wordgraph.keys():\n",
    "        if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "            continue\n",
    "        for n in wordgraph[gk].nextlist:\n",
    "            n.prevs.append(wordgraph[gk])\n",
    "    greedy_traverse(wordgraph, add_to_flat)\n",
    "    # print(\"Greedy traversal - \", len(flat))\n",
    "    cp = [f for f in flat]\n",
    "    return cp\n",
    "\n",
    "def split_dl_node(node):\n",
    "    if len(node.detoks)==1:\n",
    "        return [node]\n",
    "    res = []\n",
    "    # update previous of nodes\n",
    "    for i in range(len(node.detoks)):\n",
    "        n = node.detoks[i]\n",
    "        # make a copy of our base node\n",
    "        tmp = DLReverseNode(node)\n",
    "        if i>0:\n",
    "            tmp.prevs = [res[-1]]\n",
    "            # only have probability on 1\n",
    "            tmp.prob = 1\n",
    "        tmp.uid = tmp.uid+str(i)\n",
    "        tmp.pos = tmp.pos - (len(node.detoks)-i-1)\n",
    "        tmp.canvpos = tmp.canvpos - (len(node.detoks)-i-1)\n",
    "        tmp.token_idx = n\n",
    "        tmp.token_str = detok.decode(n)\n",
    "        res.append(tmp)\n",
    "    # update next connection of nodes\n",
    "    for i in range(len(res)-1):\n",
    "        if i<(len(node.detoks)-1):\n",
    "            res[i].next_ids = [res[i+1].uid]\n",
    "            res[i].nexts = [res[i+1]]\n",
    "    return res\n",
    "        \n",
    "def tokenize_flat_lattice(gr):\n",
    "    # get rid of first token, usually en_XX for french\n",
    "    print(\"original nodes - \", len(gr.keys()))\n",
    "    tmplist = gr['root'].nextlist[0].nextlist\n",
    "    tmpids = gr['root'].nextlist[0].next_ids\n",
    "    gr['root'].nextlist = tmplist\n",
    "    gr['root'].next_ids = tmpids\n",
    "    flatlat = get_flat_lattice(gr)\n",
    "    res = []\n",
    "    #print(\"flatlat - \", len(flatlat))\n",
    "\n",
    "    for f in flatlat:\n",
    "        res.extend(split_dl_node(f))\n",
    "    print(\"final detokd - \", len(res))\n",
    "    return res\n",
    "    # we need to go through and convert this into lattices compatible \n",
    "    # with the format further into the pipeline, need to tokenize again with BERT\n",
    "    \n",
    "# disconnect / throw away node\n",
    "def throw_garbage(node, grph, lprevs=False):\n",
    "    assert len(node.prevs)==0 or len(node.nextlist)==0\n",
    "    for pre in node.prevs:\n",
    "        if node in pre.nextlist:\n",
    "            pre.nextlist.remove(node)\n",
    "        if node.uid in pre.next_ids:\n",
    "            pre.next_ids.remove(node.uid)\n",
    "\n",
    "    if lprevs:\n",
    "        for n in node.nextlist:\n",
    "            n.prevs.remove(node)\n",
    "    if node.uid not in grph.keys():\n",
    "        #print(\"w\")\n",
    "        \"\"\n",
    "    else:\n",
    "        del grph[node.uid]\n",
    "        \n",
    "# assume that previous nodes are consolidated, \n",
    "def consolidate_node(node, grph):\n",
    "    if node.uid not in grph.keys():\n",
    "        return\n",
    "    goneprevs = []\n",
    "    # check relationship with all previous nodes\n",
    "    for prev in node.prevs:\n",
    "        # it's a word boundary, no changes\n",
    "        comb = toker.decode(prev.token_idx+node.token_idx)\n",
    "        if \" \" in comb or \"</s>\" in comb:\n",
    "            continue\n",
    "        else:\n",
    "            # need to make new node, add necessary stuff\n",
    "            #print(comb)\n",
    "            tmp = DLReverseNode(node)\n",
    "            tmp.token_str = comb\n",
    "            tmp.token_idx = prev.token_idx+node.token_idx\n",
    "            tmp.prob = prev.prob*node.prob\n",
    "            tmp.prevs = []\n",
    "            tmp.prevs.extend(prev.prevs)\n",
    "            tmp.uid = prev.uid+node.uid\n",
    "            \n",
    "            # connect previous nodes\n",
    "            for pre in tmp.prevs:\n",
    "                pre.nextlist.append(tmp)\n",
    "                pre.next_ids.append(tmp.uid)\n",
    "            \n",
    "            grph[tmp.uid] = tmp\n",
    "            # cut off from others where necessary\n",
    "            goneprevs.append(prev)\n",
    "            \n",
    "            if node in prev.nextlist:\n",
    "                prev.nextlist.remove(node)\n",
    "                if node.uid in prev.next_ids:\n",
    "                    prev.next_ids.remove(node.uid)\n",
    "            \n",
    "            for t in tmp.nextlist:\n",
    "                t.prevs.append(tmp)\n",
    "            # prev now garbage, delete it\n",
    "            if len(prev.nextlist)==0:\n",
    "                throw_garbage(prev, grph, True)\n",
    "            \"\"\"\n",
    "            if comb==\"China‚Äô\":\n",
    "                print(\"nexts after\", len(tmp.nextlist))\n",
    "                print(tmp.uid)\n",
    "                print(tmp.nextlist[0].prevs[1].uid)\n",
    "            \"\"\"\n",
    "            \n",
    "    for g in goneprevs:\n",
    "        node.prevs.remove(g)\n",
    "    if len(node.prevs)==0:\n",
    "        throw_garbage(node, grph)\n",
    "        \n",
    "\n",
    "def get_dictlist(grphinp):\n",
    "    fllat = tokenize_flat_lattice(grphinp)\n",
    "    tdicts = []\n",
    "    for f in fllat:\n",
    "        tdicts.append({\n",
    "            'token_idx': f.token_idx,\n",
    "            'pos': f.pos, \n",
    "            'id': f.uid,\n",
    "            'nexts': [fn.uid for fn in f.nextlist], \n",
    "            'score': math.log(f.prob)\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fdfb56-fffc-4a5c-aff1-ad7021f3c962",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3397b1b8-cf09-465f-896a-a6401570cf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pickle.load(open(base+str(0), 'rb'))\n",
    "flatlat = get_dictlist(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dae76c-4ef0-4e8a-a981-9e9f0d2ca8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(75):\n",
    "    graph = pickle.load(open(base+str(i), 'rb'))\n",
    "    flatlat = tokenize_flat_lattice(graph)\n",
    "    print(len(flatlat))\n",
    "    #combnodes = combine_nodes(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47080ef-7cfd-41d3-874e-7ce6c818d421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_duptok(flat, ind):\n",
    "    check = flat[ind]\n",
    "    prestrs = set([fla.uid for fla in check.prevs])\n",
    "    nestrs = set([ns.token_str for ns in check.nextlist])\n",
    "    others = flat[:ind]\n",
    "    if ind<len(flat)-1:\n",
    "        others.extend(flat[ind+1:])\n",
    "    res = []\n",
    "    for f in others:\n",
    "        if check.token_str==f.token_str:\n",
    "            \n",
    "            if prestrs==set([fla.uid for fla in f.prevs]):\n",
    "                res.append(f.token_str)\n",
    "    return res\n",
    "\"\"\"\n",
    "TODO look into issue of duplicates\n",
    "\n",
    "bigre = []\n",
    "for i in range(len(flatlat)-1):\n",
    "    print(check_duptok(flatlat, i))\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "648bf118-f865-48c4-a5e9-e2f305ff999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "combnodes['root'].nextlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005c1deb-474a-4a32-95ac-008cdc12271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "toker.decode([9098, 26, 7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547b479-26a5-4bec-8391-30bce275d0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['root'].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].token_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a8f463-73b1-4ba8-a63c-4fc1144a5a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for gk in combnodes.keys():\n",
    "    if len(combnodes[gk].nextlist)==0:\n",
    "        print(combnodes[gk].token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f47d2a-2da2-48f0-b8e1-7a8d874a1168",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(flatlat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defa2eff-9fba-461b-b084-5e089a27dcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "[f.token_str+\" \"+str(f.pos) for f in flatlat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807fb4e-a17b-479b-96b8-4148fe45d1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gra = combine_nodes(graph)\n",
    "weirds = []\n",
    "print(len(gra.keys()))\n",
    "for gk in gra.keys():\n",
    "    if gk==\"input\" or gk== \"ref\" or gk== \"rootid\":\n",
    "        continue\n",
    "    print(gra[gk])\n",
    "    if len(gra[gk].nextlist)==0:\n",
    "        \n",
    "        weirds.append(gra[gk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f0ecb8-688e-4a3b-9db7-44596967cd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want - Another variable is the degree to which other developed countries‚Äô monetary policies will ease.\n",
    "node = gra['root'].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[0].nextlist[2].nextlist[0].nextlist[0].nextlist[1].nextlist[0].nextlist[1].nextlist[0].nextlist[0].nextlist[0].nextlist[2]\n",
    "for n in node.nextlist:\n",
    "    print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ca898e-7f70-4b45-8f66-a41fb6ad510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "toker = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69abd10-c62a-4dd0-8b2d-25e1a1b0074e",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublegraph = get_dbl_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142d22a-c599-40bf-ab43-25f2f067dac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "doublegraph['root'].nextlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4fb132-0782-4f76-8909-2fc6aa1149c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_nodes(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4400970-2136-44e1-a7b0-a46e07bfb47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO delete if not useful\n",
    "def update_node_prevs(dblgraph, node):\n",
    "    # check if already in existing nodes\n",
    "    if node.uid in dblgraph.keys():\n",
    "        return\n",
    "    # TODO make sure to use the right kind of node\n",
    "    cur = node\n",
    "    while len(cur.nextlist)==1:\n",
    "        if cur.nextlist[0].uid in dblgraph.keys():\n",
    "            tmp = dblgraph[cur.nextlist[0].uid]\n",
    "        else:\n",
    "            tmp = DLReverseNode(cur.nextlist[0])\n",
    "        tmp.prevs.append(cur)\n",
    "        # don't keep going if we've already done this node at some point\n",
    "        if cur.nextlist[0].uid in dblgraph.keys():\n",
    "            return \n",
    "        dblgraph[cur.nextlist[0].uid] = tmp\n",
    "        cur = tmp\n",
    "    # hit the end of segment, multiple choices now\n",
    "    if len(cur.nextlist)>1:\n",
    "        for n in cur.nextlist:\n",
    "            if n.uid in dblgraph.keys():\n",
    "                nnode = dblgraph[n.uid]\n",
    "            else:\n",
    "                nnode = DLReverseNode(n)\n",
    "            nnode.prevs.append(cur)\n",
    "            dblgraph[n.uid] = nnode\n",
    "            update_node_prevs(dblgraph, n)\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "341f4c18-f49b-4ab8-ba04-e465e5a22e93",
   "metadata": {},
   "source": [
    "graph = get_dbl_graph(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8958800f-412b-4354-96a5-0e9bdd409345",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph['root'].nextlist[0].prevs[1].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83eb7663-5c87-43ef-8d6f-7de7f028143e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten out lattice \n",
    "def flatten_lattice(graph):\n",
    "    tokdicts = []\n",
    "    visited = []\n",
    "    prev_contig = []\n",
    "    greedy_flatten(tokdicts, visited, graph['root'], 0, prev_contig, set())\n",
    "    #greedy_flat_old(tokdicts, visited, graph['root'], 0)\n",
    "    return tokdicts\n",
    "\n",
    "max_splits = -1\n",
    "splits_hit = 0\n",
    "# flattens graph by position, ignores </s> and en_XX tokens for greater BERT compatibility\n",
    "# TODO set up to use mbart tokenization\n",
    "def greedy_flatten(tdicts, visited, node, pos, prev_cont, added_ids, branch_start=None):\n",
    "    global splits_hit\n",
    "    if node.uid in visited:\n",
    "        return\n",
    "    if node.token_idx==2 or node.token_idx==250004:\n",
    "        npos = pos\n",
    "    else:\n",
    "        node.pos = pos\n",
    "        \n",
    "        visited.append(node.uid)\n",
    "        npos = pos+1\n",
    "        s = node.token_str\n",
    "        prev_cont.append(node)\n",
    "    \n",
    "    olen = len(tdicts)\n",
    "    # we're hitting a branch or an ending, update to bert tokenization and add to visited\n",
    "    # should be ok to do this since branching / merging only happens at word boundaries (presumably)\n",
    "    branched = (len(node.next_scores)>1)\n",
    "    end = (len(node.next_scores)==0)\n",
    "    merge = end==False and node.nextlist[0].uid in visited\n",
    "    if branched or merge or end:\n",
    "        if len(prev_cont)>0:\n",
    "            errorflag = False\n",
    "            \n",
    "            prev_update = []\n",
    "            for p in prev_cont:\n",
    "                if p.uid in added_ids:\n",
    "                    continue\n",
    "                else:\n",
    "                    prev_update.append(p)\n",
    "                    added_ids.add(p.uid)\n",
    "            \n",
    "            if len(prev_update)>0:\n",
    "                toktmp = get_toklist(prev_update)\n",
    "                for i in range(1, len(prev_update)):\n",
    "                    if prev_update[-(i+1)].pos>=prev_update[-i].pos:\n",
    "                        errorflag = True\n",
    "                        break\n",
    "                decstr = mbart_tok.decode(toktmp)\n",
    "                if errorflag:\n",
    "                    #print(decstr)\n",
    "                    #print([p.pos for p in prev_update])\n",
    "                    \"\"\n",
    "                bert_toks = bert_tok(decstr).input_ids\n",
    "                curpos = prev_update[0].pos\n",
    "                # TODO add logic that tracks scores / next nodes\n",
    "                otdlen = len(tdicts)\n",
    "                for bind in range(0, len(bert_toks)):\n",
    "                    b = bert_toks[bind]\n",
    "                    # change to 101, 102 for bert, change to 0, 2 for xlm\n",
    "                    if b==0 or b==2:\n",
    "                        continue\n",
    "                    nid = str(b)+\" \"+str(curpos)\n",
    "                    # if we're at the start, add this node to next of branch node\n",
    "                    if len(tdicts)==otdlen and branch_start is not None:\n",
    "                        branch_start['nexts'].append(nid)\n",
    "\n",
    "                    if bind<len(bert_toks)-1:\n",
    "                        tdicts.append({\n",
    "                            'token_idx':b,\n",
    "                            'pos':curpos, \n",
    "                            'id': nid,\n",
    "                            'nexts': [str(bert_toks[bind+1])+\" \"+str(curpos+1)], \n",
    "                            'score': 0\n",
    "                        })\n",
    "                    else:\n",
    "                        tdicts.append({\n",
    "                            'token_idx':b,\n",
    "                            'pos':curpos, \n",
    "                            'id': str(b)+\" \"+str(pos),\n",
    "                            'nexts': [], \n",
    "                            'score': 0\n",
    "                        })\n",
    "                    curpos+=1\n",
    "                if merge or end:\n",
    "                    splits_hit+=1\n",
    "            \n",
    "    if len(tdicts)>olen:\n",
    "        del prev_cont\n",
    "        prev_cont = []\n",
    "        \n",
    "    # end things early if we want to limit paths\n",
    "    if max_splits>=0 and splits_hit>=max_splits:\n",
    "        return \n",
    "    \n",
    "    scosort = list(np.argsort(node.next_scores))\n",
    "    if branched and len(tdicts)>0:\n",
    "        branch_start=tdicts[-1]\n",
    "    # TODO check which direction we need to go from argsort\n",
    "    for i in range(0, len(scosort)):\n",
    "        greedy_flatten(tdicts, visited, node.nextlist[scosort[i]], npos, prev_cont, added_ids, branch_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911ff318-1019-447f-aa3d-425712aa1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topological sort the graphs, make sure that nodes that are next always come next in the list\n",
    "def topo_sort_nodes(pgraph):\n",
    "    cp = [p for p in pgraph]\n",
    "    tmpgraph = {}\n",
    "    for c in cp:\n",
    "        tmpgraph[c.uid]=c\n",
    "    res = []\n",
    "    visited = []\n",
    "    # reverse ordering\n",
    "    topo_recurse(cp[0].uid, res, [], tmpgraph)\n",
    "    # don't reverse anymore\n",
    "    # res.reverse()\n",
    "    return res\n",
    "        \n",
    "def topo_recurse(curid, toplist, visited, graph):\n",
    "    if curid in visited:\n",
    "        return \n",
    "    # for stuff in truncated part of graph TODO\n",
    "    if curid not in graph.keys():\n",
    "        return\n",
    "    node = graph[curid]\n",
    "    visited.append(curid)\n",
    "    for nid in [n.uid for n in node.nextlist]:\n",
    "        topo_recurse(nid, toplist, visited, graph)\n",
    "    # once done, add to the beginnings\n",
    "    toplist.insert(0, node)\n",
    "\n",
    "    # take in list of truncnodes, sort for dynamic programming\n",
    "def prepare_nodes(truncnodes, scores, padd):\n",
    "    ind = 0\n",
    "    for p in range(len(truncnodes)):\n",
    "        # get rid of this later if we decide to have multiple canvi\n",
    "        assert len(truncnodes[p])<=512\n",
    "        for i in range(min(len(truncnodes[p]),512)):\n",
    "            # get score after offset (we only get for decoded stuff)\n",
    "            # TODO do some kind of assert\n",
    "            truncnodes[p][i].score = scores[p][i+padd]\n",
    "    \n",
    "    result = []\n",
    "    for trunc in truncnodes:\n",
    "        result.append(topo_sort_nodes(trunc))\n",
    "        \n",
    "    for trunc in result:\n",
    "        dpos = 0\n",
    "        for node in trunc:\n",
    "            node.dppos = dpos\n",
    "            dpos+=1\n",
    "            \n",
    "    return result\n",
    "\n",
    "MINPROP = 0.7\n",
    "def dynamic_path(prepnodes, sco_funct, posapp):\n",
    "    \n",
    "    bplist = [None]*len(prepnodes)\n",
    "    bscolist = [-10000]*len(prepnodes)\n",
    "    endings = []\n",
    "    # go through topologically sorted list of nodes, update best path for each\n",
    "    for prep in prepnodes:\n",
    "        if bplist[prep.dppos]==None:\n",
    "            bplist[prep.dppos] = []\n",
    "        if len(prep.prevs)>0:\n",
    "            mval = -10000\n",
    "            mprev = None\n",
    "            for p in prep.prevs:\n",
    "                if p.dppos>=0 and bscolist[p.dppos]>mval:\n",
    "                    mval = bscolist[p.dppos]\n",
    "                    mprev = p\n",
    "            if mprev is not None:\n",
    "                # use from previous\n",
    "                bplist[prep.dppos].extend(bplist[mprev.dppos])\n",
    "                bscolist[prep.dppos] = bscolist[mprev.dppos] + prep.score\n",
    "                #print(bscolist[prep.dppos])\n",
    "        # TODO look into endings that are happening due to excessive trunction\n",
    "        if len(prep.nextlist)==0:\n",
    "            endings.append(prep.dppos)\n",
    "        if bscolist[prep.dppos]==-10000:\n",
    "            bscolist[prep.dppos]= prep.score\n",
    "        bplist[prep.dppos].append(prep)\n",
    "        #bscolist[prep.dppos] += prep.score\n",
    "    \n",
    "    print(endings)\n",
    "    print([float(bscolist[e]) for e in endings])\n",
    "    bestpath = []\n",
    "    bestsco = -10000\n",
    "    for e in endings:\n",
    "        # make sure we hit minimum length proportional to input\n",
    "        if len(bplist[e])>(MINPROP)*posapp:\n",
    "            if bscolist[e]>bestsco:\n",
    "                bestsco = bscolist[e]\n",
    "                bestpath = bplist[e]\n",
    "    return bestpath, bplist, bscolist\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('latenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
