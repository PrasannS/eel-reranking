{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad833c3b-f011-491e-a028-f79b9f053bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-18 06:03:07.230700: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-18 06:03:07.230722: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from src.recom_search.model.beam_node_reverse import ReverseNode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b444160d-7834-479d-a7c7-3c5f3c9212b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBASE = \"./reverse_graphs/\"\n",
    "endebase = \"mt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9/\"\n",
    "frenbase = \"mtn1_fr-en_bfs_recom_4_-1_False_0.4_True_False_4_5_rcb_0.902_0.0_0.9/\"\n",
    "bert_tok = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "mbart_tok = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")\n",
    "mbart_tok.src_lang = \"en_XX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0eb26b-e45c-4cd2-846f-4d90ec33f1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(fname):\n",
    "    return pickle.load(open(fname,'rb'))\n",
    "\n",
    "def get_toklist(revnodes):\n",
    "    res = []\n",
    "    for r in revnodes:\n",
    "        if type(r) is dict:\n",
    "            res.append(r['token_idx'])\n",
    "        else:\n",
    "            res.append(r.token_idx)\n",
    "    return res\n",
    "\n",
    "def flatten_lattice(graph):\n",
    "    tokdicts = []\n",
    "    visited = []\n",
    "    prev_contig = []\n",
    "    greedy_flatten(tokdicts, visited, graph['root'], 0, prev_contig, set())\n",
    "    #greedy_flat_old(tokdicts, visited, graph['root'], 0)\n",
    "    return tokdicts\n",
    "    \n",
    "# flattens graph by position, ignores </s> and en_XX tokens for greater BERT compatibility\n",
    "# TODO set up to use mbart tokenization\n",
    "def greedy_flatten(tdicts, visited, node, pos, prev_cont, added_ids):\n",
    "    if node.uid in visited:\n",
    "        print(\"cycle here\")\n",
    "        return\n",
    "    if node.token_idx==2 or node.token_idx==250004:\n",
    "        npos = pos\n",
    "    else:\n",
    "        node.pos = pos\n",
    "        # tdicts.append(node)\n",
    "        visited.append(node.uid)\n",
    "        npos = pos+1\n",
    "        s = node.token_str\n",
    "        prev_cont.append(node)\n",
    "    \n",
    "    olen = len(tdicts)\n",
    "    # we're hitting a branch or an ending, update to bert tokenization and add to visited\n",
    "    # should be ok to do this since branching / merging only happens at word boundaries (presumably)\n",
    "    branched = (len(node.next_scores)>1)\n",
    "    end = (len(node.next_scores)==0)\n",
    "    merge = end==False and node.nextlist[0].uid in visited\n",
    "    if branched or merge or end:\n",
    "        #print(branched, \" \", merge, \" \", end)\n",
    "        if len(prev_cont)>0:\n",
    "            errorflag = False\n",
    "            \n",
    "            prev_update = []\n",
    "            for p in prev_cont:\n",
    "                if p.uid in added_ids:\n",
    "                    continue\n",
    "                else:\n",
    "                    prev_update.append(p)\n",
    "                    added_ids.add(p.uid)\n",
    "            \n",
    "            if len(prev_update)>0:\n",
    "                toktmp = get_toklist(prev_update)\n",
    "                for i in range(1, len(prev_update)):\n",
    "                    if prev_update[-(i+1)].pos>=prev_update[-i].pos:\n",
    "                        errorflag = True\n",
    "                        break\n",
    "                decstr = mbart_tok.decode(toktmp)\n",
    "                if errorflag:\n",
    "                    print(decstr)\n",
    "                    print([p.pos for p in prev_update])\n",
    "                bert_toks = bert_tok(decstr).input_ids\n",
    "                curpos = prev_update[0].pos\n",
    "                # TODO add logic that tracks scores\n",
    "                for b in bert_toks:\n",
    "                    if b==101 or b==102:\n",
    "                        continue\n",
    "                    tdicts.append({\n",
    "                        'token_idx':b,\n",
    "                        'pos':curpos\n",
    "                    })\n",
    "                    curpos+=1\n",
    "    if len(tdicts)>olen:\n",
    "        del prev_cont\n",
    "        prev_cont = []\n",
    "        \n",
    "    scosort = list(np.argsort(node.next_scores))\n",
    "    \n",
    "    # TODO check which direction we need to go from argsort\n",
    "    for i in range(0, len(scosort)):\n",
    "        greedy_flatten(tdicts, visited, node.nextlist[scosort[i]], npos, prev_cont, added_ids)\n",
    "        \n",
    "def get_processed_graph_data(lanbase, stop=-1):\n",
    "    base = GBASE+lanbase\n",
    "    paths = os.listdir(base)\n",
    "    print(len(paths))\n",
    "    result = []\n",
    "    if stop==-1:\n",
    "        stop = len(paths)\n",
    "    for i in range(0, stop):\n",
    "        curgraph = load_graph(base+paths[i])\n",
    "        result.append(flatten_lattice(curgraph))\n",
    "    return result\n",
    "\n",
    "def greedy_path(flat):\n",
    "    prev = -1\n",
    "    res = []\n",
    "    for f in flat:\n",
    "        if f.pos>prev:\n",
    "            res.append(f)\n",
    "            prev = f.pos\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecb15518-48b0-4b8e-b79d-f74736842a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_paths(root):\n",
    "    global nodeset\n",
    "    #print(root.token_str)\n",
    "    if len(root.nextlist) == 0:\n",
    "        yield [root]\n",
    "\n",
    "    scosort = list(np.argsort(root.next_scores))\n",
    "    \n",
    "    seen = []\n",
    "    for s in scosort:\n",
    "        child = root.nextlist[s]\n",
    "        if child.uid in seen:\n",
    "            continue\n",
    "        nodeset.add(child.uid)\n",
    "        #if len(seen)>1:\n",
    "            #print(\"maybe not bug\")\n",
    "        seen.append(child.uid)\n",
    "        for path in find_paths(child):\n",
    "            yield [root] + path\n",
    "            \n",
    "def get_plist_sco(plist):\n",
    "    res = []\n",
    "    for p in plist:\n",
    "        res.append(p.prob)\n",
    "    return res\n",
    "\n",
    "def get_plist_str(plist):\n",
    "    res = []\n",
    "    for p in plist:\n",
    "        res.append(p.token_idx)\n",
    "    val =  mbart_tok.decode(res)\n",
    "    #print(val)\n",
    "    return val\n",
    "\n",
    "nodeset = set()\n",
    "STOP = 1000\n",
    "def get_all_possible_candidates(graph):\n",
    "    global nodeset\n",
    "    scores =  []\n",
    "    cands = []\n",
    "    fullplist = []\n",
    "    generated = 0\n",
    "    \n",
    "    for p in find_paths(graph['root']):\n",
    "        if generated == STOP:\n",
    "            break\n",
    "        fullplist.append(p)\n",
    "        generated+=1\n",
    "    print(\"num nodes\")\n",
    "    print(len(nodeset))\n",
    "    nodeset = set()\n",
    "    #fullplist = remove_dups(fullplist)\n",
    "    print(\"candidates\")\n",
    "    print(len(fullplist))\n",
    "    for plist in fullplist:\n",
    "        #scores.append(get_plist_sco(plist))\n",
    "        cands.append(get_plist_str(plist))\n",
    "    \n",
    "    # TODO some kind of filtration that prevents super similar or bad stuff from being used\n",
    "    return cands\n",
    "    \n",
    "def get_allcands(lanbase, stop=-1, res=[]):\n",
    "    base = GBASE+lanbase\n",
    "    paths = os.listdir(base)\n",
    "    print(len(paths))\n",
    "    if stop==-1:\n",
    "        stop = len(paths)\n",
    "    for i in range(0, stop):\n",
    "        try:\n",
    "            curgraph = load_graph(base+paths[i])\n",
    "            res.append(get_all_possible_candidates(curgraph))\n",
    "        except:\n",
    "            print(\"hit recursion limit\")\n",
    "            res.append([])\n",
    "    return res\n",
    "        #result.append(flatten_lattice(curgraph))\n",
    "    #return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c927b0-b0d1-44af-bfbb-6718dd9adb99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1451865b-68f1-4f4c-9d54-1f9eaa6afccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resarrs = []\n",
    "get_allcands(frenbase, -1, resarrs)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18d956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedgraphs = get_processed_graph_data(frenbase, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3b95a3a-60b1-498a-9811-e617b14c275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "61\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(resarrs)):\n\u001b[0;32m----> 2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mresarrs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m         \u001b[38;5;28mprint\u001b[39m(r)\n\u001b[1;32m      4\u001b[0m         \u001b[38;5;28;01mdel\u001b[39;00m resarrs[r]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "for r in range(0, len(resarrs)):\n",
    "    if len(resarrs[r])==0:\n",
    "        print(r)\n",
    "        del resarrs[r]\n",
    "        del processedgraphs[r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43f8942a-464a-4bd9-813b-2c0153075500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(resarrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "711da42e-2886-4bfd-a732-4e138cb8f474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(processedgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807ab356-f2c5-405d-9d34-ae02328c30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455\n",
      "Antibodies trace all nicotine molecules found in the blood system and neutralize them before they reach the brain., making it impossible for smokers to have their nicotine dose. a smoker to get his nicotine have his or her nicotine dose. the smoker to get which prevents smokers from taking their nicotine dose from being reached by the smoker. reaching the smoker. getting their nicotine dose. a smoker from receiving his or her nicotine reaching their nicotine his nicotine or her taking the nicotine their his nicotine or her dose of nicotine. having the right dose of nicotine. their nicotine his nicotine or her dose getting to his nicotine a dose of nicotine. the nicotine their nicotine dosage. his dose of nicotine. or her dose of nicotine. nicotine level. dosage. the smoking person from getting his nicotine smoker from reaching his or nicotine receiving his nicotine taking their his or nicotine having the nicotine their nicotine his nicotine or her thus stopping the smoker keeping the smoker preventing smoking from having its nicotine smokers from receiving their nicotine reaching their nicotine having their taking their nicotine getting the their dose of nicotine. a smoker the nicotine user from getting his nicotine smoking person smo kers from ker thereby blocking the smoker depriving the smoker of his nicotine or her stopping the keeping the smoker preventing smoking smokers a the nicotine user smoking preventing cigarette smokers from smoking smokers a person from getting their nicotine the cigarette smoker from nicotine from reaching the smoker. user smoking individual from getting his or her neutralize them prior to reaching the brain., which thus thereby before reaching the they get to the brain., present in the blood in the blood and neutralize them before they reach the brain., preventing the smoker from getting his detect all nicotine track down all nicotine all the nicotine nicotine\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] The NSA case underlines the complete lack of discussion on intelligence. debate over intelligence. about intelligence. on intelligence. intelligence discussion. debate. total absence of any debate on intelligence. intelligence debate. a debate on an intelligence debate. debate over intelligence. about intelligence. on intelligence discussion. lack of discussion on intelligence. debate over about scores the complete lack absence of any a an debate over about total lack highlights complete lack of debate on a complete lack of total absence of debate on intelligence discussion. lack of debate the complete lack total lack NSA underlines total lack ofscores total lack of highlights the total lack of complete absence of debate total [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = processedgraphs[17]\n",
    "tlist = get_toklist(p)\n",
    "decstr = bert_tok.decode(tlist)\n",
    "print(len(tlist))\n",
    "#for node in p:\n",
    "    #print(node['token_idx'], \" \", node['pos'])\n",
    "print(decstr)\n",
    "\"[CLS] The NSA case underlines the complete lack of discussion on intelligence. debate over intelligence. about intelligence. on intelligence. intelligence discussion. debate. total absence of any debate on intelligence. intelligence debate. a debate on an intelligence debate. debate over intelligence. about intelligence. on intelligence discussion. lack of discussion on intelligence. debate over about scores the complete lack absence of any a an debate over about total lack highlights complete lack of debate on a complete lack of total absence of debate on intelligence discussion. lack of debate the complete lack total lack NSA underlines total lack ofscores total lack of highlights the total lack of complete absence of debate total [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "991b14d0-028c-4150-9b86-8a83dd52d69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_encsame(flat):\n",
    "    tlist = get_toklist(flat)\n",
    "    decstr = mbart_tok.decode(get_toklist(flat))\n",
    "    re_encoded = mbart_tok(decstr).input_ids\n",
    "    print(decstr)\n",
    "    for i in range(0, len(tlist)):\n",
    "        print(mbart_tok.decode(tlist[i]), \" \", mbart_tok.decode(re_encoded[i+1]))\n",
    "        if tlist[i]==re_encoded[i+1]:\n",
    "            continue\n",
    "        #print(tlist[i])\n",
    "        #print(re_encoded[i+1])\n",
    "        #return False\n",
    "    return True\n",
    "\n",
    "def mbart_to_bert (flat):\n",
    "    tlist = get_toklist(flat)\n",
    "    decstr = mbart_tok.decode(get_toklist(flat))\n",
    "\n",
    "def print_proctoks(revnodes):\n",
    "    for rev in revnodes:\n",
    "        print(rev.token_str, \" - \", rev['pos'])\n",
    "\n",
    "#print_proctoks(greedy_path(processedgraphs[2]))\n",
    "#check_encsame(processedgraphs[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea7ef2fb-6adc-4109-89ad-1677afb42794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattice encoding and normal candidate encoding\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "class LinearLatticeBert(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained('bert-base-cased')\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, posids):\n",
    "    \n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            bertout = self.bert(sentences, position_ids=posids, return_dict=True, output_hidden_states=True)\n",
    "        return bertout\n",
    "    \n",
    "class LinearPOSBert(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained('bert-base-cased')\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, pos_ids=None):\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            if pos_ids==None:\n",
    "                word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "            else:\n",
    "                word_rep, sentence_rep = self.bert(sentences, position_ids=pos_ids, return_dict=False)\n",
    "        return self.probe(word_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3d4c7f-91ba-41f3-a18d-e2eb6382189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "posbmodel = LinearPOSBert(52)\n",
    "posbmodel.load_state_dict(torch.load(\"./posbert/posbertmodel/posbert.pth\"))\n",
    "posbmodel.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2e2b4ab9-6551-4f5b-b22a-a51460020ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "878956544"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "94162b0f-e48b-4a5e-b805-5374509c6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 500\n",
    "\n",
    "def find_indices(list_to_check, item_to_find):\n",
    "    indices = locate(list_to_check, lambda x: x == item_to_find)\n",
    "    return list(indices)\n",
    "\n",
    "def clean_expanded(cand):\n",
    "    tmp = cand.replace(\"</s>\", \"\")\n",
    "    tmp = tmp.replace(\"en_XX\", \"\")\n",
    "    tmp = tmp.replace(\"<s>\", \"\")\n",
    "    return tmp.strip()\n",
    "\n",
    "def prepare_dataset(resset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for res in resset:\n",
    "        \n",
    "        curinps = []\n",
    "        for r in res:\n",
    "            try:\n",
    "                toktmp = torch.tensor(bert_tok(clean_expanded(r)).input_ids)\n",
    "                #print(toktmp.shape)\n",
    "                if float(toktmp.shape[0])<MAX_LEN:\n",
    "                    toktmp = torch.cat([toktmp, torch.zeros(MAX_LEN-toktmp.shape[0])])\n",
    "                else:\n",
    "                    toktmp = toktmp[:MAX_LEN]\n",
    "                curinps.append(toktmp)\n",
    "            except:\n",
    "                print(\"weird error happened\")\n",
    "                \n",
    "            \n",
    "        print(len(curinps))\n",
    "        curouts = []\n",
    "        tinp = torch.stack(curinps).long().to(device)\n",
    "        print(tinp.shape)\n",
    "        y.append(posbmodel(tinp))\n",
    "        x.append(tinp)\n",
    "        \n",
    "        print(\"error somewhere\")\n",
    "    return x, y\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0252fa27-de41-4b9e-bc49-5629a7dbe424",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXLEN = 500\n",
    "def create_inputs(pgraphs):\n",
    "    result_tok = []\n",
    "    result_pos = []\n",
    "    for p in pgraphs:\n",
    "        tokstmp = []\n",
    "        postmp = []\n",
    "        for tok in p:\n",
    "            tokstmp.append(tok['token_idx'])\n",
    "            postmp.append(tok['pos']+1)\n",
    "        if len(tokstmp)>=MAX_LEN-2:\n",
    "            tokstmp = tokstmp[:MAXLEN-2]\n",
    "            postmp = postmp[:MAXLEN-2]\n",
    "        tokstmp = [101] + tokstmp + [102]\n",
    "        rem = MAX_LEN - len(tokstmp)\n",
    "        postmp = [0] + postmp + [max(postmp)+1] + [0]*rem\n",
    "        tokstmp = tokstmp + [0]*rem\n",
    "        result_tok.append(tokstmp)\n",
    "        result_pos.append(postmp)\n",
    "        \n",
    "    return torch.tensor(result_tok).to(device), torch.tensor(result_pos).to(device)\n",
    "\n",
    "def dataset_make_tags(inpx, inpy):\n",
    "    tokmap = {}\n",
    "    print(len(inpx))\n",
    "    for i in range(0, len(inpx)):\n",
    "        inpi = inpx[i]\n",
    "        for j in range(0, len(inpi)):\n",
    "            k = str(int(inpi[j]))\n",
    "            if k not in tokmap:\n",
    "                tokmap[k]=[]\n",
    "            tokmap[k].append(inpy[i][j])\n",
    "    for k in tokmap.keys():\n",
    "        \n",
    "        tokmap[k] = torch.stack(tokmap[k]).to(device)\n",
    "        tokmap[k] = torch.mean(tokmap[k], dim=0)\n",
    "        #print(tokmap[k].shape)\n",
    "    return tokmap\n",
    "    \n",
    "def makelattice_pos_data(tokmap, flat):\n",
    "    res = []\n",
    "    for tok in flat:\n",
    "        # this should always work given how the lattice is structured\n",
    "        try:\n",
    "            res.append(tokmap[str(int(tok))])\n",
    "        except:\n",
    "            print(\"missing token\")\n",
    "            res.append(torch.zeros(52).to(device))\n",
    "    return torch.stack(res).float()\n",
    "\n",
    "def lattice_pos_goldlabels(datax, datay, sents):\n",
    "    dataset = []\n",
    "    for i in range(len(datax)):\n",
    "        tmap = dataset_make_tags(datax[i], datay[i])\n",
    "        dataset.append(makelattice_pos_data(tmap, sents[i]))\n",
    "        print(i)\n",
    "    return torch.stack(dataset).float().to(device)\n",
    "\n",
    "soft = torch.nn.Softmax(dim=2)\n",
    "loss = torch.nn.BCEWithLogitsLoss()\n",
    "l1 = torch.nn.L1Loss()\n",
    "mse = torch.nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d5c3cc95-a92d-4a74-a6cf-811dc81851f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0cbd406f-bc0b-4bf6-a730-fd40f7ddcb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "445022720\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(\"cuda:2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "830c77fe-fdda-471b-abb6-73a40565615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del posbmodel\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4242d79e-78c7-4bb6-8a30-895b0aa2acb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labset_partial(explodeds, startind, amt):\n",
    "    print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    dsetx, dsety = prepare_dataset(explodeds[startind:startind+amt])\n",
    "    print(len(dsetx))\n",
    "    print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    assert len(dsetx)==amt\n",
    "    latposylabels = lattice_pos_goldlabels(dsetx, dsety, sents[startind:startind+amt])\n",
    "    print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    del dsetx, dsety\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    return latposylabels\n",
    "\n",
    "def get_biglabset(split):\n",
    "    result = None\n",
    "    for i in range(0, int(len(resarrs)/split)):\n",
    "        print(\"SUBSET - \", i)\n",
    "        try:\n",
    "            if result ==None:\n",
    "                result = get_labset_partial(resarrs, i*split, split)\n",
    "            else:\n",
    "                result = torch.cat((result, get_labset_partial(resarrs, i*split, split)))\n",
    "        except:\n",
    "            print(\"empty list\")\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.save(result, 'latposlabels.pt')\n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942d96be-7d8f-43f2-852f-7650e21e222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "#    latposylabels = get_biglabset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f6c5c4a-47a2-491c-b061-dcfc80f65d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(latposylabels, 'latposlabelsdone.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8caf33ac-26d6-4fb4-9222-23c9a22dd778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445022720"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "38fc1532-0756-4196-8ae2-edc68d9ccb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = posbmodel(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5cfb3c03-d890-4564-9528-b8839124090a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., device='cuda:2', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(soft(latposylabels)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d54f0945-f622-48a2-a2ef-68e08315f17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = torch.rand((6, 500, 52))\n",
    "r2 = torch.rand((6, 500, 52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "23990fa6-3432-4723-b224-22dd173b3423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1668)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7e9330c3-b4c7-4a18-b483-a8db61a73597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7338)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss(r1, r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a91314d1-8216-43fc-8ba4-c60129285dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(35.8972, device='cuda:2', grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse(latposylabels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7b586f3-1873-4370-8c79-e455d1f624c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6352013901818407\n",
      "0.018080638821655393\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "\n",
    "def check_randacc(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(torch.rand(52).to(device))==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "            \n",
    "print(check_accuracy(pred, latposylabels))\n",
    "print(check_randacc(pred, latposylabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f638fbd8-fb3a-43f7-aa87-b6396c9bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from more_itertools import locate\n",
    "\n",
    "def ind_cos_dist (i1, i2, embed):\n",
    "    return 1-cosine(embed[i1].cpu(), embed[i2].cpu())\n",
    "\n",
    "def tok_cos_dist(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in inds1:\n",
    "        for i2 in inds2:\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    #assert l1[ind1]==l2[ind2]\n",
    "    return sims\n",
    "\n",
    "def tok_cos_notbase(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in range(0, len(inps1)):\n",
    "        for i2 in range(0, len(inps2)):\n",
    "            if inps1[i1]==inps2[i2]:\n",
    "                continue\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ae29e763-be20-44fc-91af-8fe08211482a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#latbert = LinearLatticeBert(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d5c1697-a35f-4978-a285-d69e63161cf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#basebert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ac78556-8dbb-4eaf-b982-bb2a390df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean(lis):\n",
    "    try:\n",
    "        return sum(lis)/len(lis)\n",
    "    except:\n",
    "        return 0.8\n",
    "\n",
    "def get_ex_distr(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[example][ex_cand])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    for r in norm_inputs[0]:\n",
    "        res.append(mean(tok_cos_dist(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_ex_notbase(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[ex_cand][0])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    res.append(mean(tok_cos_notbase(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_diff_base(latembed, inp_toks):\n",
    "    diff = []\n",
    "    for i in range(len(inp_toks)):\n",
    "        for j in range(len(inp_toks)):\n",
    "            if inp_toks[i]==inp_toks[j]:\n",
    "                diff.append(ind_cos_dist(i, j, latembed))\n",
    "            \n",
    "    return diff\n",
    "\n",
    "def get_lat_distr(example):\n",
    "    result = []\n",
    "    tot = len(resarrs[example])\n",
    "    if tot>100:\n",
    "        tot = 100\n",
    "    for i in range(tot):\n",
    "        print(i)\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "        result.append(mean(get_ex_distr(example, i, latembed, sents)))\n",
    "    print(len(resarrs[example]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "52423a8e-7096-4e79-b40d-a01b63a5a2e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  8.,  10.,   0.,  30.,  30.,  64.,  92., 110., 254., 518.]),\n",
       " array([0.68519515, 0.71667563, 0.74815612, 0.7796366 , 0.81111709,\n",
       "        0.84259757, 0.87407806, 0.90555854, 0.93703903, 0.96851951,\n",
       "        1.        ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sents, posids = create_inputs(processedgraphs[0:0+1])\n",
    "out = latbert(sents, posids)\n",
    "latembed = out['last_hidden_state'][0]\n",
    "plt.hist(get_diff_base(latembed, sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "df6fc8ef-af43-4a81-8e94-17596d8c40c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4216383578272023]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = []\n",
    "\n",
    "get_ex_notbase(0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35077c7-cc98-4d8f-8c2a-d60fff83ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "809f08ef-4b96-48bd-a491-7d7f33cb0c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.719793975353241,\n",
       " 0.7008659243583679,\n",
       " 0.6701750755310059,\n",
       " 0.6903993487358093,\n",
       " 0.6903993487358093]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7b2623ec-5921-4682-96ce-011304ff2c1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 101,  146, 1341, 1175, 1132, 1160, 3001, 1104, 2593, 1113, 1103, 1226,\n",
      "         1104, 1103, 1497, 2384,  112,  188, 2593,  119,  102]])\n",
      "tensor([[ 101,  146, 1341, 1175, 1132, 1160, 3001, 1104, 2593, 1118, 1103, 1497,\n",
      "         2384,  119,  119, 1113, 1103, 1226, 1104, 1103, 1497, 2384,  119,  112,\n",
      "          188, 2593,  119, 1121, 1103, 1497, 2384, 2059, 1175, 1132, 1160, 1115,\n",
      "         1175, 1132, 1160, 3001, 1104, 2593, 1118, 1103, 1497, 2384,  119,  119,\n",
      "         1113, 1103, 1226, 1104, 1103, 1497, 2384,  119, 1121, 1103, 1497, 2384,\n",
      "         1130, 1139, 2458, 1175, 1132, 1160,  117, 1103, 1497, 2384, 1144, 5133,\n",
      "         1120, 1160, 3001,  119, 1160, 3001,  119, 1104, 2593, 1106, 1142, 1121,\n",
      "         1103, 2827,  119, 1118, 1103, 1497, 2384,  119,  119, 1113, 1103, 1497,\n",
      "         2384,  119,  787,  188, 1226,  119,  112,  188, 1226,  119, 1226, 1104,\n",
      "         1103, 2384,  119, 1104, 1699,  119, 1497, 3912,  119, 2384,  131,  119,\n",
      "         1121, 1103, 2384,  119, 1104, 1699,  119, 1497, 2384,  131, 1175, 1132,\n",
      "         1160, 3001, 1106, 1103, 1497, 2384,  119, 2593, 1104, 1103, 1497, 1121,\n",
      "         1103, 1104, 7163, 1121, 1103, 1497, 1103, 2593, 1121, 1497, 3943, 1113,\n",
      "         1103, 1226, 1121, 1103, 1497, 2590, 1113, 1103, 1226, 1121, 1103, 1497,\n",
      "         4893, 1175, 1132, 1160,  117, 1103, 1497, 1175, 1132,  102]],\n",
      "       device='cuda:2')\n"
     ]
    }
   ],
   "source": [
    "print(norm_inputs)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20c50528-ed67-471f-bd55-357971c75169",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_list = list(set(\" \".join(sentences).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "57887b59-eb3e-477e-abfa-85d47054e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding special tokens\n",
    "word_dict = {'[PAD]': 0, '[CLS]': 1, '[SEP]': 2, '[MASK]': 3}\n",
    "\n",
    "# create vocabulary dictionaries (word->token id mapping)\n",
    "for i, w in enumerate(word_list):\n",
    "    word_dict[w] = i + 4\n",
    "    number_dict = {i: w for i, w in enumerate(word_dict)}\n",
    "    vocab_size = len(word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62557b95-28b4-46bf-afa9-35c43c8a0859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_batch():\n",
    "    batch = []\n",
    "    positive = negative = 0\n",
    "    \n",
    "    # keep things balanced? \n",
    "    while positive != batch_size/2 or negative != batch_size/2:\n",
    "        # get 2 random sentences, we want to check if they're contiguous or not\n",
    "        tokens_a_index, tokens_b_index = randrange(len(sentences)), randrange(len(sentences)) \n",
    "        \n",
    "        # not sure where token_list comes from \n",
    "        tokens_a, tokens_b = token_list[tokens_a_index], token_list[tokens_b_index]\n",
    "\n",
    "        # create a list with all the appropriate token ids for the input formatting\n",
    "        input_ids = [word_dict['[CLS]']] + tokens_a + [word_dict['[SEP]']] + tokens_b + [word_dict['[SEP]']]\n",
    "\n",
    "        # handle segment embedding?\n",
    "        segment_ids = [0] * (1 + len(tokens_a) + 1) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "        # MASK LM\n",
    "        # get num of tokens to mask\n",
    "        n_pred =  min(max_pred, max(1, int(round(len(input_ids) * 0.15)))) # 15 % of tokens in one sentence\n",
    "        cand_maked_pos = [i for i, token in enumerate(input_ids)\n",
    "                         if token != word_dict['[CLS]'] and token != word_dict['[SEP]']]\n",
    "        shuffle(cand_maked_pos)\n",
    "        \n",
    "        # randomly select 15% of tokens to mask\n",
    "        masked_tokens, masked_pos = [], []\n",
    "        for pos in cand_maked_pos[:n_pred]:\n",
    "            \n",
    "            masked_pos.append(pos)\n",
    "            masked_tokens.append(input_ids[pos])\n",
    "            # usually just mask\n",
    "            if random() < 0.8:  # 80%\n",
    "                input_ids[pos] = word_dict['[MASK]'] # make mask\n",
    "            # sometimes just put a random word in\n",
    "            elif random() < 0.5:  # 10%\n",
    "                index = randint(0, vocab_size - 1) # random index in vocabulary\n",
    "                input_ids[pos] = word_dict[number_dict[index]] # replace\n",
    "\n",
    "        # Zero Paddings\n",
    "        n_pad = maxlen - len(input_ids)\n",
    "        input_ids.extend([0] * n_pad)\n",
    "        segment_ids.extend([0] * n_pad)\n",
    "\n",
    "        # Zero Padding (100% - 15%) tokens\n",
    "        if max_pred > n_pred:\n",
    "            n_pad = max_pred - n_pred\n",
    "            masked_tokens.extend([0] * n_pad)\n",
    "            masked_pos.extend([0] * n_pad)\n",
    "\n",
    "        if tokens_a_index + 1 == tokens_b_index and positive < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, True]) # IsNext\n",
    "            positive += 1\n",
    "        elif tokens_a_index + 1 != tokens_b_index and negative < batch_size/2:\n",
    "            batch.append([input_ids, segment_ids, masked_tokens, masked_pos, False]) # NotNext\n",
    "            negative += 1\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0dbbf9aa-bfdd-47a4-ac44-3146389710dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(torch.arange(30, dtype=torch.long).expand_as(input_ids))\n",
    "class Embedding(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Embedding, self).__init__()\n",
    "        self.tok_embed = nn.Embedding(vocab_size, d_model)  # token embedding\n",
    "        self.pos_embed = nn.Embedding(maxlen, d_model)  # position embedding\n",
    "        self.seg_embed = nn.Embedding(n_segments, d_model)  # segment(token type) embedding\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x, seg):\n",
    "        seq_len = x.size(1)\n",
    "        pos = torch.arange(seq_len, dtype=torch.long)\n",
    "        pos = pos.unsqueeze(0).expand_as(x)  # (seq_len,) -> (batch_size, seq_len)\n",
    "        embedding = self.tok_embed(x) + self.pos_embed(pos) + self.seg_embed(seg)\n",
    "        return self.norm(embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fccc8ba-a91d-4cc5-82dd-65f396f26471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attn_pad_mask(seq_q, seq_k):\n",
    "    batch_size, len_q = seq_q.size()\n",
    "    batch_size, len_k = seq_k.size()\n",
    "    # eq(zero) is PAD token\n",
    "    pad_attn_mask = seq_k.data.eq(0).unsqueeze(1)  # batch_size x 1 x len_k(=len_q), one is masking\n",
    "    return pad_attn_mask.expand(batch_size, len_q, len_k)  # batch_size x len_q x len_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0464df-879b-4a06-8297-fd4af74596d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERT, self).__init__()\n",
    "        self.embedding = Embedding()\n",
    "        self.layers = nn.ModuleList([EncoderLayer() for _ in range(n_layers)])\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "        self.activ1 = nn.Tanh()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "        self.activ2 = gelu\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.classifier = nn.Linear(d_model, 2)\n",
    "        # decoder is shared with embedding layer\n",
    "        embed_weight = self.embedding.tok_embed.weight\n",
    "        n_vocab, n_dim = embed_weight.size()\n",
    "        self.decoder = nn.Linear(n_dim, n_vocab, bias=False)\n",
    "        self.decoder.weight = embed_weight\n",
    "        self.decoder_bias = nn.Parameter(torch.zeros(n_vocab))\n",
    "\n",
    "    def forward(self, input_ids, segment_ids, masked_pos):\n",
    "        output = self.embedding(input_ids, segment_ids)\n",
    "        enc_self_attn_mask = get_attn_pad_mask(input_ids, input_ids)\n",
    "        for layer in self.layers:\n",
    "            output, enc_self_attn = layer(output, enc_self_attn_mask)\n",
    "        # output : [batch_size, len, d_model], attn : [batch_size, n_heads, d_mode, d_model]\n",
    "        # it will be decided by first token(CLS)\n",
    "        h_pooled = self.activ1(self.fc(output[:, 0])) # [batch_size, d_model]\n",
    "        logits_clsf = self.classifier(h_pooled) # [batch_size, 2]\n",
    "\n",
    "        masked_pos = masked_pos[:, :, None].expand(-1, -1, output.size(-1)) # [batch_size, max_pred, d_model]\n",
    "\n",
    "        # get masked position from final output of transformer.\n",
    "        h_masked = torch.gather(output, 1, masked_pos) # masking position [batch_size, max_pred, d_model]\n",
    "        h_masked = self.norm(self.activ2(self.linear(h_masked)))\n",
    "        logits_lm = self.decoder(h_masked) + self.decoder_bias # [batch_size, max_pred, n_vocab]\n",
    "\n",
    "        return logits_lm, logits_clsf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "908eb183-766d-4942-993d-bae0cd302ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "examples = [\"Barack Obama receives Iraqs prime minister in the midst of escalating violence.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a39cadb-8ba5-4047-a97e-e0d6d686a937",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-15 07:46:29.695833: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-15 07:46:29.695855: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Importing the relevant modules\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda:2\"\n",
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "           output_hidden_states = True,).to(device)\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "787d823f-f601-4918-a88a-a3baa6714c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f143582a-452b-484e-a39c-54f82d966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in examples:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('Obama')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd15771d-5745-4282-88c4-66e36d66121e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target_word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "fa1457d6-fd88-4834-8fb9-c23619ebc26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "bert_model = LinearLatticeBert(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "06803ea6-c89f-4f0a-a2c1-73abf871030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = torch.tensor(sents).to(device)\n",
    "posids = torch.tensor(posids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "a649ba20-455f-4e41-8e4b-a741ed427306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert_model(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "2a10775b-6e48-4eb4-95ee-c02cdbe051df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lhs = out['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dbd13fb0-e094-4e25-bca7-19398920a763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(119, device='cuda:2')"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(sents[0])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "e97a751a-d65b-4a89-a67d-cadcc18698a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_cos_dist(13, 14, lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "4519fa09-7daf-463e-9564-57496b5cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptest = bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "164ad4dd-b430-49d4-91de-295d6f3915c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "normal_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "1666146d-6818-4633-88d7-e5254550bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalout = normal_bert(torch.tensor([inptest.input_ids]),return_dict=True, output_hidden_states=True)\n",
    "normalhs = normalout['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "d82992cf-1849-428b-82fa-f6ebe5cc10bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 1109, 27020, 1692, 1223, 10443, 1103, 2335, 2960, 1104, 6145, 1113, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "8e39a5e1-b493-4a6f-bf58-aad62b36e8d2",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Boolean value of Tensor with more than one value is ambiguous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [183]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtok_cos_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43mnormalhs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;241;43m1109\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [182]\u001b[0m, in \u001b[0;36mtok_cos_dist\u001b[0;34m(embed1, embed2, tok)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtok_cos_dist\u001b[39m(embed1, embed2, tok):\n\u001b[0;32m----> 5\u001b[0m     ind1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43membed1\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtok\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m     ind2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(embed2)\u001b[38;5;241m.\u001b[39mindex(tok)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mcosine(embed1[ind1]\u001b[38;5;241m.\u001b[39mcpu(), embed2[ind2]\u001b[38;5;241m.\u001b[39mcpu())\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
     ]
    }
   ],
   "source": [
    "tok_cos_dist(lhs,normalhs,  1109)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
