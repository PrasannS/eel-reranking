{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad833c3b-f011-491e-a028-f79b9f053bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-22 04:18:03.689745: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-22 04:18:03.689767: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import flatten_lattice as fl\n",
    "import torch\n",
    "from bert_models import LinearLatticeBert, LinearPOSBert\n",
    "from encoding_utils import *\n",
    "import pickle\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1451865b-68f1-4f4c-9d54-1f9eaa6afccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resarrs = []\n",
    "fl.get_allcands(fl.frenbase, -1, resarrs)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18d956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedgraphs = fl.get_processed_graph_data(fl.frenbase, -1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3b95a3a-60b1-498a-9811-e617b14c275f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "61\n",
      "99\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for r in range(0, len(resarrs)):\n",
    "    try:\n",
    "        if len(resarrs[r])==0:\n",
    "            print(r)\n",
    "            del resarrs[r]\n",
    "            del processedgraphs[r]\n",
    "    except:\n",
    "        break\n",
    "print(len(resarrs))\n",
    "print(len(processedgraphs))\n",
    "bert_tok = fl.bert_tok\n",
    "mbart_tok = fl.mbart_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "807ab356-f2c5-405d-9d34-ae02328c30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "Antibodies trace all nicotine molecules found in the blood system and neutralize them before they reach the brain., detect track\n"
     ]
    }
   ],
   "source": [
    "p = processedgraphs[17]\n",
    "tlist = fl.get_toklist(p)\n",
    "decstr = bert_tok.decode(tlist)\n",
    "print(len(tlist))\n",
    "#for node in p:\n",
    "    #print(node['token_idx'], \" \", node['pos'])\n",
    "print(decstr)\n",
    "#\"[CLS] The NSA case underlines the complete lack of discussion on intelligence. debate over intelligence. about intelligence. on intelligence. intelligence discussion. debate. total absence of any debate on intelligence. intelligence debate. a debate on an intelligence debate. debate over intelligence. about intelligence. on intelligence discussion. lack of discussion on intelligence. debate over about scores the complete lack absence of any a an debate over about total lack highlights complete lack of debate on a complete lack of total absence of debate on intelligence discussion. lack of debate the complete lack total lack NSA underlines total lack ofscores total lack of highlights the total lack of complete absence of debate total [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c3d4c7f-91ba-41f3-a18d-e2eb6382189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433933824\n"
     ]
    }
   ],
   "source": [
    "# credit to tutorial by https://pageperso.lis-lab.fr/benoit.favre/pstaln/09_embedding_evaluation.html for \n",
    "# model \n",
    "posbmodel = LinearPOSBert(52)\n",
    "posbmodel.load_state_dict(torch.load(\"./posbert/posbertmodel/posbert.pth\"))\n",
    "posbmodel.eval()\n",
    "print(torch.cuda.memory_allocated(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94162b0f-e48b-4a5e-b805-5374509c6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(resset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for res in resset:\n",
    "        curinps = []\n",
    "        for r in res:\n",
    "            try:\n",
    "                toktmp = torch.tensor(bert_tok(clean_expanded(r)).input_ids)\n",
    "                #print(toktmp.shape)\n",
    "                if float(toktmp.shape[0])<MAX_LEN:\n",
    "                    toktmp = torch.cat([toktmp, torch.zeros(MAX_LEN-toktmp.shape[0])])\n",
    "                else:\n",
    "                    toktmp = toktmp[:MAX_LEN]\n",
    "                curinps.append(toktmp)\n",
    "            except:\n",
    "                print(\"weird error happened\") \n",
    "        print(len(curinps))\n",
    "        curouts = []\n",
    "        tinp = torch.stack(curinps).long().to(device)\n",
    "        print(tinp.shape)\n",
    "        y.append(posbmodel(tinp))\n",
    "        x.append(tinp)\n",
    "        \n",
    "        #print(\"error somewhere\")\n",
    "    return x, y\n",
    "\n",
    "def get_labset_partial(explodeds, startind, amt):\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    dsetx, dsety = prepare_dataset(explodeds[startind:startind+amt])\n",
    "    print(len(dsetx))\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    assert len(dsetx)==amt\n",
    "    latposylabels, tmaps = lattice_pos_goldlabels(dsetx, dsety, sents[startind:startind+amt])\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    del dsetx, dsety\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    return latposylabels, tmaps\n",
    "\n",
    "def get_biglabset(split):\n",
    "    result = None\n",
    "    tmaps = []\n",
    "    for i in range(0, int(len(resarrs)/split)):\n",
    "        print(\"SUBSET - \", i)\n",
    "        try:\n",
    "            r, tmap = get_labset_partial(resarrs, i*split, split)\n",
    "            tmaps = tmaps + tmap\n",
    "            if result == None:\n",
    "                result = r\n",
    "            else:\n",
    "                result = torch.cat((result, r))\n",
    "        except:\n",
    "            print(\"empty list\")\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.save(result, './plabels/latreposlabels.pt')\n",
    "        file = open('tmaps.pkl', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(tmaps, file)\n",
    "\n",
    "        # close the file\n",
    "        file.close()\n",
    "\n",
    "    return result, tmaps\n",
    "\n",
    "def debug_newinput(linp, explinps, latout, explouts):\n",
    "    i = 0\n",
    "    tot = 0\n",
    "    while linp[i]>0:\n",
    "        print()\n",
    "        print(bert_tok.decode(linp[i]), \" \" ,bert_tok.decode(explinps[0][i]))\n",
    "        print(explinps[0][i])\n",
    "        lv, li = torch.topk(latout[i], 3)\n",
    "        ev, ei = torch.topk(explouts[6][i], 3)\n",
    "        print(li, \" \", ei)\n",
    "        #if l==e:\n",
    "        #    tot+=1\n",
    "        \n",
    "        i+=1\n",
    "    print(tot/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aee42282-14fa-4da1-aad7-cf39501cf5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = prepare_dataset(resarrs[0:1])\n",
    "#bert_tok.decode(x[0][6])\n",
    "#debug_newinput(sents[0], x[0], outtmp[0], y[0])\n",
    "#print(sents[0])\n",
    "#torch.argmax(outtmp[0][0])\n",
    "#torch.argmax(y[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babf0f34-b887-4538-b0a3-ce07a283b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1f1931e-5eb9-40a5-b2a7-518543ab006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "460\n"
     ]
    }
   ],
   "source": [
    "zcnt = 0\n",
    "for p in sents[0]:\n",
    "    if p==0:\n",
    "        zcnt+=1\n",
    "print(zcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bd226e-baa3-4aed-9c5d-8c443934ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06729ff8-d2cf-495c-b259-7fdcd5d67de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tmapsdone.pickle', 'rb') as handle:\n",
    "    tmaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53074c0-ee87-4993-9a52-bf8aace9912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#with torch.no_grad():\n",
    "#    latposylabels, tmaps = get_biglabset(1)\n",
    "latposylabels = tmap_pos_goldlabels(tmaps, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c79fff9-2529-4730-a8d2-7ee0781ecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_id_test(lenvals):\n",
    "    tmp = list(range(0, 500))\n",
    "    res = []\n",
    "    for i in range(0, lenvals):\n",
    "        res.append(torch.tensor(tmp))\n",
    "    return torch.stack(res).to(device)\n",
    "\n",
    "\n",
    "def mod_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            if i>0 and p[i]==0:\n",
    "                p[i] = i\n",
    "    return cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38fc1532-0756-4196-8ae2-edc68d9ccb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = posbmodel(sents)\n",
    "pred3 = posbmodel(sents, posids)\n",
    "pred2 = posbmodel(sents, mod_posids(posids))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d54f0945-f622-48a2-a2ef-68e08315f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1668)\n",
      "tensor(0.7335)\n",
      "tensor(1.7361, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "r1 = torch.rand((6, 500, 52))\n",
    "r2 = torch.rand((6, 500, 52))\n",
    "print(mse(r1, r2))\n",
    "print(loss(r1, r2))\n",
    "print(mse(latposylabels, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a7b586f3-1873-4370-8c79-e455d1f624c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9961571133853808\n",
      "0.019173981635047126\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "\n",
    "def check_randacc(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(torch.rand(52).to(device))==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "            \n",
    "print(check_accuracy(pred2, latposylabels))\n",
    "print(check_randacc(pred2, latposylabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f638fbd8-fb3a-43f7-aa87-b6396c9bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from more_itertools import locate\n",
    "\n",
    "def ind_cos_dist (i1, i2, embed):\n",
    "    return 1-cosine(embed[i1].cpu(), embed[i2].cpu())\n",
    "\n",
    "def tok_cos_dist(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in inds1:\n",
    "        for i2 in inds2:\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    #assert l1[ind1]==l2[ind2]\n",
    "    return sims\n",
    "\n",
    "def tok_cos_notbase(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in range(0, len(inps1)):\n",
    "        for i2 in range(0, len(inps2)):\n",
    "            if inps1[i1]==inps2[i2]:\n",
    "                continue\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae29e763-be20-44fc-91af-8fe08211482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latbert = LinearLatticeBert(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d5c1697-a35f-4978-a285-d69e63161cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basebert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ac78556-8dbb-4eaf-b982-bb2a390df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean(lis):\n",
    "    try:\n",
    "        return sum(lis)/len(lis)\n",
    "    except:\n",
    "        return 0.8\n",
    "\n",
    "def get_ex_distr(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[example][ex_cand])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    for r in norm_inputs[0]:\n",
    "        res.append(mean(tok_cos_dist(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_ex_notbase(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[ex_cand][0])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    res.append(mean(tok_cos_notbase(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_diff_base(latembed, inp_toks):\n",
    "    diff = []\n",
    "    for i in range(len(inp_toks)):\n",
    "        for j in range(len(inp_toks)):\n",
    "            if inp_toks[i]==inp_toks[j]:\n",
    "                diff.append(ind_cos_dist(i, j, latembed))\n",
    "    return diff\n",
    "\n",
    "def get_lat_distr(example):\n",
    "    result = []\n",
    "    tot = len(resarrs[example])\n",
    "    if tot>100:\n",
    "        tot = 100\n",
    "    for i in range(tot):\n",
    "        print(i)\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "        result.append(mean(get_ex_distr(example, i, latembed, sents)))\n",
    "    print(len(resarrs[example]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52423a8e-7096-4e79-b40d-a01b63a5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs[0:0+1])\n",
    "out = latbert(sents, posids)\n",
    "latembed = out['last_hidden_state'][0]\n",
    "plt.hist(get_diff_base(latembed, sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc8ef-af43-4a81-8e94-17596d8c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "get_ex_notbase(0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35077c7-cc98-4d8f-8c2a-d60fff83ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f08ef-4b96-48bd-a491-7d7f33cb0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2623ec-5921-4682-96ce-011304ff2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_inputs)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39cadb-8ba5-4047-a97e-e0d6d686a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "           output_hidden_states = True,).to(device)\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d823f-f601-4918-a88a-a3baa6714c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143582a-452b-484e-a39c-54f82d966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in examples:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('Obama')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15771d-5745-4282-88c4-66e36d66121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1457d6-fd88-4834-8fb9-c23619ebc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = LinearLatticeBert(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803ea6-c89f-4f0a-a2c1-73abf871030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = torch.tensor(sents).to(device)\n",
    "posids = torch.tensor(posids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649ba20-455f-4e41-8e4b-a741ed427306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert_model(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10775b-6e48-4eb4-95ee-c02cdbe051df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lhs = out['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd13fb0-e094-4e25-bca7-19398920a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sents[0])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a751a-d65b-4a89-a67d-cadcc18698a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_cos_dist(13, 14, lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519fa09-7daf-463e-9564-57496b5cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptest = bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ad4dd-b430-49d4-91de-295d6f3915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666146d-6818-4633-88d7-e5254550bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalout = normal_bert(torch.tensor([inptest.input_ids]),return_dict=True, output_hidden_states=True)\n",
    "normalhs = normalout['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82992cf-1849-428b-82fa-f6ebe5cc10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39a5e1-b493-4a6f-bf58-aad62b36e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_cos_dist(lhs,normalhs,  1109)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
