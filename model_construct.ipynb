{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad833c3b-f011-491e-a028-f79b9f053bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-29 07:22:11.128891: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-29 07:22:11.128912: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import flatten_lattice as fl\n",
    "import torch\n",
    "from bert_models import LinearLatticeBert, LinearPOSBert\n",
    "from encoding_utils import *\n",
    "import pickle\n",
    "from mask_utils import *\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1451865b-68f1-4f4c-9d54-1f9eaa6afccf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resarrs = []\n",
    "fl.get_allcands(fl.frenbase, -1, resarrs)\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a18d956d",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedgraphs = fl.get_processed_graph_data(fl.frenbase, -1, 15)\n",
    "greedy = False\n",
    "\n",
    "def filter_greedy(pgraphs):\n",
    "    res = []\n",
    "    for p in pgraphs:\n",
    "        tmp = []\n",
    "        for i in range(1, len(p)):\n",
    "            tmp.append(p[i-1])\n",
    "            if p[i]['pos']<=p[i-1]['pos']:\n",
    "                break\n",
    "            elif i==len(p)-1:\n",
    "                tmp.append(p[i])\n",
    "        res.append(tmp)\n",
    "    return res\n",
    "\n",
    "if greedy:\n",
    "    processedgraphs = filter_greedy(processedgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14b2fef7-6f07-4c91-8eaf-d47c44a8cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO more sanity checking on whether or not we're recording the right number of branches\n",
    "def nexts_sanity(pgraph):\n",
    "    toklist = []\n",
    "    next_tok = pgraph[0]['token_idx']\n",
    "    next_pos = 0\n",
    "    for p in pgraph:\n",
    "        if next_tok == p['token_idx'] and next_pos == p['pos']:\n",
    "            tmp = p['nexts'][0].split()\n",
    "            next_tok = int(tmp[0])\n",
    "            next_pos = int(tmp[1])\n",
    "            print(bert_tok.decode(p['token_idx']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dd09c91-4fdf-417b-93a9-3d2f2767db20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attmasks(pgraphs):\n",
    "    res = []\n",
    "    i = 0\n",
    "    for p in pgraphs:\n",
    "        res.append(connect_mat(p))\n",
    "        print(i)\n",
    "        i+=1\n",
    "    return torch.stack(res).to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "835d3c52-7f1b-46fa-a78a-88d6cd10a4f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "61\n",
      "99\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "for r in range(0, len(resarrs)):\n",
    "    try:\n",
    "        if len(resarrs[r])==0:\n",
    "            print(r)\n",
    "            del resarrs[r]\n",
    "            del processedgraphs[r]\n",
    "    except:\n",
    "        break\n",
    "print(len(resarrs))\n",
    "print(len(processedgraphs))\n",
    "bert_tok = fl.bert_tok\n",
    "mbart_tok = fl.mbart_tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbf3579-f01d-486f-a56c-bb22e508557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "assert len(processedgraphs)==99\n",
    "attmasks = get_attmasks(processedgraphs)\n",
    "torch.save(attmasks, './torchsaved/fiveattmasks.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877cd05a-810f-45fd-83a1-8f4cf05901e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(attmasks, './torchsaved/fixlatattmasks.pt')\n",
    "#attmasks = torch.load('./torchsaved/fixlatattmasks.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64236c95-b4c9-460a-9f5a-5434fd93bf77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:2')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attmasks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8623c30-4e39-4933-8280-0d21892af1ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "807ab356-f2c5-405d-9d34-ae02328c30dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127\n",
      "Antibodies trace all nicotine molecules found in the blood system and neutralize them before they reach the brain., making it impossible for smokers to have their nicotine dose. a smoker to get his nicotine have his or her nicotine dose. the smoker to get which prevents smokers from taking their nicotine dose from being reached by the smoker. reaching the smoker. getting their nicotine dose. a smoker from receiving his or her nicotine reaching their nicotine his nicotine or her taking the nicotine their his having getting the detect track\n"
     ]
    }
   ],
   "source": [
    "p = processedgraphs[17]\n",
    "tlist = fl.get_toklist(p)\n",
    "decstr = bert_tok.decode(tlist)\n",
    "print(len(tlist))\n",
    "#for node in p:\n",
    "    #print(node['token_idx'], \" \", node['pos'])\n",
    "print(decstr)\n",
    "#\"[CLS] The NSA case underlines the complete lack of discussion on intelligence. debate over intelligence. about intelligence. on intelligence. intelligence discussion. debate. total absence of any debate on intelligence. intelligence debate. a debate on an intelligence debate. debate over intelligence. about intelligence. on intelligence discussion. lack of discussion on intelligence. debate over about scores the complete lack absence of any a an debate over about total lack highlights complete lack of debate on a complete lack of total absence of debate on intelligence discussion. lack of debate the complete lack total lack NSA underlines total lack ofscores total lack of highlights the total lack of complete absence of debate total [SEP]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5d8ffc-5c8a-42c9-968a-b2ff3ddd032b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc4db8d1-d388-4a53-a94a-14df1e3bb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from latmask_bert_models import LatticeBertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11e475cd-8a01-4e7d-b4fd-caa862fa2855",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearPOSBertV1(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = LatticeBertModel(AutoConfig.from_pretrained('bert-base-cased'))\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, pos_ids=None, attmasks=None):\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            if pos_ids==None:\n",
    "                word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "            else:\n",
    "                print('YO')\n",
    "                word_rep, sentence_rep = self.bert(sentences, position_ids=pos_ids, encoder_attention_mask=attmasks, attention_mask=attmasks, return_dict=False)\n",
    "        return self.probe(word_rep)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3c3d4c7f-91ba-41f3-a18d-e2eb6382189b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "532475392\n"
     ]
    }
   ],
   "source": [
    "# credit to tutorial by https://pageperso.lis-lab.fr/benoit.favre/pstaln/09_embedding_evaluation.html for \n",
    "# model \n",
    "import json\n",
    "with open('./a3-distrib/lab_vocab.json') as json_file:\n",
    "    labels = json.load(json_file)\n",
    "posbmodel = LinearPOSBertV1(len(list(labels.keys())))\n",
    "posbmodel.load_state_dict(torch.load(\"./a3-distrib/ckpt/posbert.pth\"))\n",
    "posbmodel.eval()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(\"cuda:2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94162b0f-e48b-4a5e-b805-5374509c6aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(resset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for res in resset:\n",
    "        curinps = []\n",
    "        for r in res:\n",
    "            try:\n",
    "                toktmp = torch.tensor(bert_tok(clean_expanded(r)).input_ids)\n",
    "                #print(toktmp.shape)\n",
    "                if float(toktmp.shape[0])<MAX_LEN:\n",
    "                    toktmp = torch.cat([toktmp, torch.zeros(MAX_LEN-toktmp.shape[0])])\n",
    "                else:\n",
    "                    toktmp = toktmp[:MAX_LEN]\n",
    "                curinps.append(toktmp)\n",
    "            except:\n",
    "                print(\"weird error happened\") \n",
    "        print(len(curinps))\n",
    "        curouts = []\n",
    "        tinp = torch.stack(curinps).long().to(device)\n",
    "        print(tinp.shape)\n",
    "        y.append(posbmodel(tinp))\n",
    "        x.append(tinp)\n",
    "        \n",
    "        #print(\"error somewhere\")\n",
    "    return x, y\n",
    "\n",
    "def get_labset_partial(explodeds, startind, amt):\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    dsetx, dsety = prepare_dataset(explodeds[startind:startind+amt])\n",
    "    print(len(dsetx))\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    assert len(dsetx)==amt\n",
    "    latposylabels, tmaps = lattice_pos_goldlabels(dsetx, dsety, sents[startind:startind+amt])\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    del dsetx, dsety\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    return latposylabels, tmaps\n",
    "\n",
    "def get_biglabset(split):\n",
    "    result = None\n",
    "    tmaps = []\n",
    "    for i in range(0, int(len(resarrs)/split)):\n",
    "        print(\"SUBSET - \", i)\n",
    "        \n",
    "        r, tmap = get_labset_partial(resarrs, i*split, split)\n",
    "        tmaps = tmaps + tmap\n",
    "        if result == None:\n",
    "            result = r\n",
    "        else:\n",
    "            result = torch.cat((result, r))\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        torch.save(result, './plabels/latreposlabels.pt')\n",
    "        file = open('tmaps.pkl', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(tmaps, file)\n",
    "\n",
    "        # close the file\n",
    "        file.close()\n",
    "\n",
    "    return result, tmaps\n",
    "\n",
    "def debug_newinput(linp, explinps, latout, explouts):\n",
    "    i = 0\n",
    "    tot = 0\n",
    "    while linp[i]>0:\n",
    "        print()\n",
    "        print(bert_tok.decode(linp[i]), \" \" ,bert_tok.decode(explinps[0][i]))\n",
    "        print(explinps[0][i])\n",
    "        lv, li = torch.topk(latout[i], 3)\n",
    "        ev, ei = torch.topk(explouts[6][i], 3)\n",
    "        print(li, \" \", ei)\n",
    "        #if l==e:\n",
    "        #    tot+=1\n",
    "        \n",
    "        i+=1\n",
    "    print(tot/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aee42282-14fa-4da1-aad7-cf39501cf5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x, y = prepare_dataset(resarrs[0:1])\n",
    "#bert_tok.decode(x[0][6])\n",
    "#debug_newinput(sents[0], x[0], outtmp[0], y[0])\n",
    "#print(sents[0])\n",
    "#torch.argmax(outtmp[0][0])\n",
    "#torch.argmax(y[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "babf0f34-b887-4538-b0a3-ce07a283b626",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1f1931e-5eb9-40a5-b2a7-518543ab006d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359\n"
     ]
    }
   ],
   "source": [
    "zcnt = 0\n",
    "for p in sents[0]:\n",
    "    if p==0:\n",
    "        zcnt+=1\n",
    "print(zcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07bd226e-baa3-4aed-9c5d-8c443934ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06729ff8-d2cf-495c-b259-7fdcd5d67de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./tmaps.pkl', 'rb') as handle:\n",
    "    tmaps = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e53074c0-ee87-4993-9a52-bf8aace9912b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536094720\n",
      "missing token\n",
      "missing token\n",
      "0\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "1\n",
      "2\n",
      "3\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "4\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "5\n",
      "6\n",
      "7\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "8\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "9\n",
      "missing token\n",
      "10\n",
      "missing token\n",
      "missing token\n",
      "11\n",
      "12\n",
      "13\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "14\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "15\n",
      "missing token\n",
      "16\n",
      "missing token\n",
      "missing token\n",
      "17\n",
      "missing token\n",
      "18\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "19\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "20\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "21\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "22\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "23\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "24\n",
      "missing token\n",
      "missing token\n",
      "25\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "26\n",
      "27\n",
      "28\n",
      "missing token\n",
      "29\n",
      "30\n",
      "31\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "32\n",
      "33\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "34\n",
      "35\n",
      "36\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "37\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "43\n",
      "44\n",
      "missing token\n",
      "missing token\n",
      "45\n",
      "missing token\n",
      "46\n",
      "47\n",
      "missing token\n",
      "48\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "49\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "50\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "51\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "56\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "57\n",
      "58\n",
      "59\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "60\n",
      "missing token\n",
      "missing token\n",
      "61\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "62\n",
      "missing token\n",
      "missing token\n",
      "63\n",
      "64\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "65\n",
      "missing token\n",
      "missing token\n",
      "66\n",
      "missing token\n",
      "67\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "68\n",
      "missing token\n",
      "69\n",
      "70\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "71\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "72\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "73\n",
      "missing token\n",
      "missing token\n",
      "74\n",
      "75\n",
      "missing token\n",
      "76\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "77\n",
      "78\n",
      "missing token\n",
      "79\n",
      "missing token\n",
      "missing token\n",
      "80\n",
      "missing token\n",
      "missing token\n",
      "81\n",
      "missing token\n",
      "82\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "83\n",
      "84\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "85\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "86\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "87\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "88\n",
      "missing token\n",
      "missing token\n",
      "89\n",
      "90\n",
      "missing token\n",
      "missing token\n",
      "91\n",
      "92\n",
      "missing token\n",
      "missing token\n",
      "93\n",
      "94\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "95\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "96\n",
      "97\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "missing token\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #latposylabels, tmaps = get_biglabset(1)\n",
    "latposylabels = tmap_pos_goldlabels(tmaps, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f69dbee4-e32b-4cf6-b825-2c0db493ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(tmaps, \"./torchsaved/tmapsnewdone.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04959e22-d3b8-4d60-a4f7-119ea5121506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 500, 44])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latposylabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0c2213a9-0cd2-489c-a17f-5402ec0d78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(latposylabels, \"./torchsaved/latposylabels.pt\")\n",
    "#torch.save(sents, \"./torchsaved/sents.pt\")\n",
    "#torch.save(posids, \"./torchsaved/posids.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/betterposlatposylabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c79fff9-2529-4730-a8d2-7ee0781ecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_id_test(lenvals):\n",
    "    tmp = list(range(0, 500))\n",
    "    res = []\n",
    "    for i in range(0, lenvals):\n",
    "        res.append(torch.tensor(tmp))\n",
    "    return torch.stack(res).to(device)\n",
    "\n",
    "\n",
    "def mod_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            if i>0 and p[i]==0:\n",
    "                p[i] = i\n",
    "    return cop\n",
    "\n",
    "def fix_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            p[i] = i\n",
    "    return cop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fc1532-0756-4196-8ae2-edc68d9ccb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = posbmodel(sents)\n",
    "#pred3 = posbmodel(sents, posids)\n",
    "#pred2 = posbmodel(sents, mod_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred1 = posbmodel(sents, mod_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred2 = posbmodel(sents, fix_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred3 = posbmodel(sents, mod_posids(posids), None)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred4 = posbmodel(sents, fix_posids(posids), None)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d54f0945-f622-48a2-a2ef-68e08315f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1672)\n",
      "tensor(0.7344)\n",
      "tensor(28.2398, device='cuda:2', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "r1 = torch.rand((6, 500, 52))\n",
    "r2 = torch.rand((6, 500, 52))\n",
    "print(mse(r1, r2))\n",
    "print(loss(r1, r2))\n",
    "print(mse(latposylabels, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7b586f3-1873-4370-8c79-e455d1f624c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9092716006079739\n",
      "0.9076176957653181\n",
      "0.9172932330827067\n",
      "0.9235266046289669\n"
     ]
    }
   ],
   "source": [
    "def check_accuracy(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(ex[j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "\n",
    "def check_randacc(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(torch.rand(52).to(device))==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "            \n",
    "print(check_accuracy(pred1, latposylabels))\n",
    "print(check_accuracy(pred2, latposylabels))\n",
    "print(check_accuracy(pred3, latposylabels))\n",
    "print(check_accuracy(pred4, latposylabels))\n",
    "\n",
    "#print(check_randacc(pred2, latposylabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f638fbd8-fb3a-43f7-aa87-b6396c9bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "from more_itertools import locate\n",
    "\n",
    "def ind_cos_dist (i1, i2, embed):\n",
    "    return 1-cosine(embed[i1].cpu(), embed[i2].cpu())\n",
    "\n",
    "def tok_cos_dist(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in inds1:\n",
    "        for i2 in inds2:\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    #assert l1[ind1]==l2[ind2]\n",
    "    return sims\n",
    "\n",
    "def tok_cos_notbase(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in range(0, len(inps1)):\n",
    "        for i2 in range(0, len(inps2)):\n",
    "            if inps1[i1]==inps2[i2]:\n",
    "                continue\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ae29e763-be20-44fc-91af-8fe08211482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latbert = LinearLatticeBert(52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c1697-a35f-4978-a285-d69e63161cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basebert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac78556-8dbb-4eaf-b982-bb2a390df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean(lis):\n",
    "    try:\n",
    "        return sum(lis)/len(lis)\n",
    "    except:\n",
    "        return 0.8\n",
    "\n",
    "def get_ex_distr(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[example][ex_cand])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    for r in norm_inputs[0]:\n",
    "        res.append(mean(tok_cos_dist(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_ex_notbase(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[ex_cand][0])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    res.append(mean(tok_cos_notbase(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_diff_base(latembed, inp_toks):\n",
    "    diff = []\n",
    "    for i in range(len(inp_toks)):\n",
    "        for j in range(len(inp_toks)):\n",
    "            if inp_toks[i]==inp_toks[j]:\n",
    "                diff.append(ind_cos_dist(i, j, latembed))\n",
    "    return diff\n",
    "\n",
    "def get_lat_distr(example):\n",
    "    result = []\n",
    "    tot = len(resarrs[example])\n",
    "    if tot>100:\n",
    "        tot = 100\n",
    "    for i in range(tot):\n",
    "        print(i)\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "        result.append(mean(get_ex_distr(example, i, latembed, sents)))\n",
    "    print(len(resarrs[example]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52423a8e-7096-4e79-b40d-a01b63a5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs[0:0+1])\n",
    "out = latbert(sents, posids)\n",
    "latembed = out['last_hidden_state'][0]\n",
    "plt.hist(get_diff_base(latembed, sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc8ef-af43-4a81-8e94-17596d8c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "get_ex_notbase(0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35077c7-cc98-4d8f-8c2a-d60fff83ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f08ef-4b96-48bd-a491-7d7f33cb0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2623ec-5921-4682-96ce-011304ff2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_inputs)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39cadb-8ba5-4047-a97e-e0d6d686a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda:2\"\n",
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "           output_hidden_states = True,).to(device)\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d823f-f601-4918-a88a-a3baa6714c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143582a-452b-484e-a39c-54f82d966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in examples:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('Obama')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15771d-5745-4282-88c4-66e36d66121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1457d6-fd88-4834-8fb9-c23619ebc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = LinearLatticeBert(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803ea6-c89f-4f0a-a2c1-73abf871030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = torch.tensor(sents).to(device)\n",
    "posids = torch.tensor(posids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649ba20-455f-4e41-8e4b-a741ed427306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert_model(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10775b-6e48-4eb4-95ee-c02cdbe051df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lhs = out['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd13fb0-e094-4e25-bca7-19398920a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sents[0])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a751a-d65b-4a89-a67d-cadcc18698a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_cos_dist(13, 14, lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519fa09-7daf-463e-9564-57496b5cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptest = bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ad4dd-b430-49d4-91de-295d6f3915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666146d-6818-4633-88d7-e5254550bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalout = normal_bert(torch.tensor([inptest.input_ids]),return_dict=True, output_hidden_states=True)\n",
    "normalhs = normalout['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82992cf-1849-428b-82fa-f6ebe5cc10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39a5e1-b493-4a6f-bf58-aad62b36e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_cos_dist(lhs,normalhs,  1109)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
