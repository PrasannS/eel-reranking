{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad833c3b-f011-491e-a028-f79b9f053bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-31 06:00:32.622561: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-31 06:00:32.622581: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import flatten_lattice as fl\n",
    "import torch\n",
    "from bert_models import LinearLatticeBert, LinearPOSBert\n",
    "from encoding_utils import *\n",
    "import pickle\n",
    "from mask_utils import *\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from latmask_bert_models import LatticeBertModel\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18d956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "61\n",
      "99\n",
      "99\n",
      "127\n",
      "Antibodies trace all nicotine molecules found in the blood system and neutralize them before they reach the brain., making it impossible for smokers to have their nicotine dose. a smoker to get his nicotine have his or her nicotine dose. the smoker to get which prevents smokers from taking their nicotine dose from being reached by the smoker. reaching the smoker. getting their nicotine dose. a smoker from receiving his or her nicotine reaching their nicotine his nicotine or her taking the nicotine their his having getting the detect track\n"
     ]
    }
   ],
   "source": [
    "STOPS = 15\n",
    "\n",
    "# get exploded candidates in case needed\n",
    "resarrs = []\n",
    "fl.get_allcands(fl.frenbase, -1, resarrs)\n",
    "\"\"\n",
    "\n",
    "# get flattened graphs \n",
    "processedgraphs = fl.get_processed_graph_data(fl.frenbase, -1, STOPS)\n",
    "greedy = False\n",
    "\n",
    "def filter_greedy(pgraphs):\n",
    "    res = []\n",
    "    for p in pgraphs:\n",
    "        tmp = []\n",
    "        for i in range(1, len(p)):\n",
    "            tmp.append(p[i-1])\n",
    "            if p[i]['pos']<=p[i-1]['pos']:\n",
    "                break\n",
    "            elif i==len(p)-1:\n",
    "                tmp.append(p[i])\n",
    "        res.append(tmp)\n",
    "    return res\n",
    "\n",
    "if STOPS==1:\n",
    "    processedgraphs = filter_greedy(processedgraphs)\n",
    "    \n",
    "# clean up empty examples\n",
    "for r in range(0, len(resarrs)):\n",
    "    try:\n",
    "        if len(resarrs[r])==0:\n",
    "            print(r)\n",
    "            del resarrs[r]\n",
    "            del processedgraphs[r]\n",
    "    except:\n",
    "        break\n",
    "print(len(resarrs))\n",
    "print(len(processedgraphs))\n",
    "bert_tok = fl.bert_tok\n",
    "mbart_tok = fl.mbart_tok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b87a334e-c4ad-49c0-86f3-28ee73b1899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n",
      "Two days before the trial of President Mohamed Morsi was to begin, they went down to the street. s. the street. s., who has been deposed, they went ousted President Mohamed Morsi began, the two men went down to the street. s. they were out on the street. s. went to the street. s. on the street. s. into the street., the\n"
     ]
    }
   ],
   "source": [
    "# sanity check to make sure things look ok\n",
    "p = processedgraphs[87]\n",
    "tlist = fl.get_toklist(p)\n",
    "decstr = bert_tok.decode(tlist)\n",
    "print(len(tlist))\n",
    "#for node in p:\n",
    "    #print(node['token_idx'], \" \", node['pos'])\n",
    "print(decstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14b2fef7-6f07-4c91-8eaf-d47c44a8cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO more sanity checking on whether or not we're recording the right number of branches\n",
    "def nexts_sanity(pgraph):\n",
    "    toklist = []\n",
    "    next_tok = pgraph[0]['token_idx']\n",
    "    next_pos = 0\n",
    "    for p in pgraph:\n",
    "        if next_tok == p['token_idx'] and next_pos == p['pos']:\n",
    "            tmp = p['nexts'][0].split()\n",
    "            next_tok = int(tmp[0])\n",
    "            next_pos = int(tmp[1])\n",
    "            print(bert_tok.decode(p['token_idx']))\n",
    "\n",
    "def get_attmasks(pgraphs):\n",
    "    res = []\n",
    "    i = 0\n",
    "    for p in pgraphs:\n",
    "        res.append(connect_mat(p))\n",
    "        print(i)\n",
    "        i+=1\n",
    "    return torch.stack(res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ecbf3579-f01d-486f-a56c-bb22e508557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n"
     ]
    }
   ],
   "source": [
    "assert len(processedgraphs)==99\n",
    "attmasks = get_attmasks(processedgraphs)\n",
    "torch.save(attmasks, './torchsaved/attmasks15.pt')\n",
    "#torch.save(attmasks, './torchsaved/fixlatattmasks.pt')\n",
    "# Change this when you run stuff\n",
    "# TODO make a dictionary mapping from this to STOPS variable\n",
    "#attmasks = torch.load('./torchsaved/attmasksall.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b19b3045-dec4-48df-8d3a-31c5135a345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attmasks[attmasks==0] = -float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5bf2894a-43cf-472a-9a75-8eaa81fffa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 500, 500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attmasks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a08eacc7-89ac-4d44-ac86-cd6fc80cf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "class LinearPOSBertV1(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = LatticeBertModel(AutoConfig.from_pretrained('bert-base-cased'))\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, pos_ids=None, attmasks=None):\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            if pos_ids==None:\n",
    "                word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "            else:\n",
    "                \n",
    "                word_rep, sentence_rep = self.bert(sentences, position_ids=pos_ids, encoder_attention_mask=attmasks, attention_mask=attmasks, return_dict=False)\n",
    "        return self.probe(word_rep)\n",
    "    \n",
    "# credit to tutorial by https://pageperso.lis-lab.fr/benoit.favre/pstaln/09_embedding_evaluation.html for \n",
    "# input / pre-processing setup\n",
    "with open('./a3-distrib/lab_vocab.json') as json_file:\n",
    "    labels = json.load(json_file)\n",
    "posbmodel = LinearPOSBertV1(len(list(labels.keys())))\n",
    "t = torch.load(\"./a3-distrib/ckpt/posbert.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b31b5622-1e04-4dd5-a148-372f72b9f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966380544\n"
     ]
    }
   ],
   "source": [
    "posbmodel.load_state_dict(t)\n",
    "posbmodel.eval()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(\"cuda:2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "babf0f34-b887-4538-b0a3-ce07a283b626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141\n"
     ]
    }
   ],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n",
    "# sanity check roughly how many nodes current input params are producing\n",
    "zcnt = 0\n",
    "for p in sents[0]:\n",
    "    if p==0:\n",
    "        zcnt+=1\n",
    "print(500-zcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53074c0-ee87-4993-9a52-bf8aace9912b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get maps from token -> labels\n",
    "with open('./tmaps.pkl', 'rb') as handle:\n",
    "    tmaps = pickle.load(handle)\n",
    "    \n",
    "print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #latposylabels, tmaps = get_biglabset(1)\n",
    "latposylabels = tmap_pos_goldlabels(tmaps, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69dbee4-e32b-4cf6-b825-2c0db493ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(tmaps, \"./torchsaved/tmapsnewdone.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/latposylabels.pt\")\n",
    "#torch.save(sents, \"./torchsaved/sents.pt\")\n",
    "#torch.save(posids, \"./torchsaved/posids.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/betterposlatposylabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "04959e22-d3b8-4d60-a4f7-119ea5121506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 500, 44])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latposylabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c79fff9-2529-4730-a8d2-7ee0781ecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_id_test(lenvals):\n",
    "    tmp = list(range(0, 500))\n",
    "    res = []\n",
    "    for i in range(0, lenvals):\n",
    "        res.append(torch.tensor(tmp))\n",
    "    return torch.stack(res).to(device)\n",
    "\n",
    "\n",
    "def mod_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            if i>0 and p[i]==0:\n",
    "                p[i] = i\n",
    "    return cop\n",
    "\n",
    "def fix_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            p[i] = i\n",
    "    return cop\n",
    "\n",
    "def check_accuracy(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(ex[j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "\n",
    "def identify_errors(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    res = []\n",
    "    for i in range(0, len(setpred)):\n",
    "        errtmp = []\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "            else:\n",
    "                tmp = {}\n",
    "                tmp['index'] = j\n",
    "                tmp['predvec'] = ex[j]\n",
    "                tmp['goldvec'] = setlabels[i][j]\n",
    "                tmp['predlabel'] = torch.argmax(ex[j])\n",
    "                tmp['godlabel'] = torch.argmax(setlabels[i][j])\n",
    "                errtmp.append(tmp)\n",
    "        res.append(errtmp)\n",
    "                \n",
    "    return res\n",
    "\n",
    "def check_randacc(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(torch.rand(52).to(device))==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93a46a36-28cf-4af4-9612-2ede5c50a173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14.2446,  -0.8201,  -5.6803,  ..., -23.3130, -22.5731, -48.2292],\n",
       "        [  9.8024,   5.8023,   8.4158,  ..., -12.1282, -16.7127, -28.2145],\n",
       "        [  8.9438,  -1.3982,  -2.0562,  ..., -22.1643, -24.6604, -18.4705],\n",
       "        ...,\n",
       "        [ 26.1403,  -9.1826, -20.0536,  ..., -42.7384, -18.8766, -44.2679],\n",
       "        [ 26.1403,  -9.1826, -20.0536,  ..., -42.7384, -18.8766, -44.2679],\n",
       "        [ 26.1403,  -9.1826, -20.0536,  ..., -42.7384, -18.8766, -44.2679]],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latposylabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38fc1532-0756-4196-8ae2-edc68d9ccb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9418715683934114\n",
      "0.9315561959654178\n",
      "0.9172932330827067\n",
      "0.9235266046289669\n"
     ]
    }
   ],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred1 = posbmodel(sents, mod_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred2 = posbmodel(sents, fix_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred3 = posbmodel(sents, mod_posids(posids), None)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred4 = posbmodel(sents, fix_posids(posids), None)\n",
    "\n",
    "            \n",
    "print(check_accuracy(pred1, latposylabels))\n",
    "print(check_accuracy(pred2, latposylabels))\n",
    "print(check_accuracy(pred3, latposylabels))\n",
    "print(check_accuracy(pred4, latposylabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8a1bad11-dad2-4acb-9cea-e41acbff9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_errs  = identify_errors(pred1, latposylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdaf2dd6-62bd-43a0-94dc-cade995c110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lblist = [l for l in labels.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c86b263b-05b6-4d6a-a753-fb85c4ac24a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   [('JJ', 'NNP'), ('<pad>', 'NN')]\n",
      "1   [('<pad>', 'NN'), ('VBN', 'JJ')]\n",
      "2   [('<pad>', 'NN'), ('JJ', 'NN'), ('JJ', 'VBN'), ('NN', 'VB')]\n",
      "3   [('IN', 'RB'), ('DT', 'IN')]\n",
      "4   [('IN', 'EX'), ('<pad>', 'NN'), ('<pad>', '.'), ('VBD', 'VBN')]\n",
      "5   [('<pad>', 'IN'), ('<pad>', '.'), ('JJ', 'RB'), ('IN', 'RB'), ('VBP', 'VB'), ('VB', 'VBP'), ('UH', 'VB')]\n",
      "6   []\n",
      "7   [('IN', 'RB'), ('<pad>', 'JJ'), ('<pad>', 'JJ'), ('IN', 'RB'), ('<pad>', 'JJ'), ('IN', 'RB'), ('<pad>', 'JJ'), ('IN', 'RB'), ('<pad>', 'JJ'), ('IN', 'RB'), ('<pad>', 'JJ'), ('IN', 'RB'), ('<pad>', 'JJ'), ('JJ', 'DT'), ('JJ', 'DT')]\n",
      "8   [('VB', 'VBP')]\n",
      "9   []\n",
      "10   [('NNP', 'JJ'), ('<pad>', 'NN'), ('NNP', 'JJ'), ('<pad>', 'NNP'), ('NNP', 'JJ'), ('NNP', 'JJ'), ('VBG', 'NN'), ('PRP$', 'JJ'), ('<pad>', 'JJ'), ('<pad>', 'VBP'), ('JJ', 'NNP')]\n",
      "11   [('<pad>', 'IN'), ('IN', 'WDT')]\n",
      "12   [('NN', 'NNP'), ('JJ', 'NN'), ('IN', 'WP'), ('NNPS', 'NNP')]\n",
      "13   [('NN', 'NNP'), ('JJ', 'NNP'), ('JJ', 'NNP')]\n",
      "14   [('<pad>', 'NN'), ('NN', 'VB'), ('<pad>', 'CD'), ('<pad>', 'IN'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "15   [('VBN', 'JJ'), ('VBN', 'JJ'), ('<pad>', 'NN'), ('<pad>', '.'), ('NNP', 'JJ'), ('VBN', 'JJ'), ('JJ', 'NN'), ('<pad>', '.'), ('VBN', 'JJ'), ('JJ', 'NN'), ('VBN', 'VBD'), ('<pad>', '.')]\n",
      "16   [('IN', 'RB'), ('JJ', 'NN'), ('VBZ', 'RB')]\n",
      "17   [('VB', 'VBP'), ('VB', 'VBP')]\n",
      "18   [('<pad>', ','), ('VB', 'NN'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('VB', 'NN'), ('JJ', 'IN')]\n",
      "19   [('IN', 'CC'), ('RB', 'VBN'), ('<pad>', '.'), ('IN', 'WDT'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', '.'), ('VBG', 'VBN'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.')]\n",
      "20   [('NNPS', 'NNP'), ('JJ', 'RB'), ('<pad>', '.'), ('<pad>', '.'), ('NN', 'CD'), ('JJ', 'RB'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "21   [('VB', 'NN'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', '.'), ('VB', 'NN'), ('<pad>', 'NN'), ('<pad>', '.')]\n",
      "22   [('NN', 'JJ')]\n",
      "23   [('<pad>', 'RB'), ('<pad>', 'DT'), ('<pad>', 'DT'), ('<pad>', 'DT'), ('<pad>', 'DT'), ('<pad>', 'DT'), ('VBG', 'NN'), ('<pad>', 'DT'), ('NN', 'VBG')]\n",
      "24   [('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', 'NNPS'), ('<pad>', 'VBZ')]\n",
      "25   [('NNPS', 'NNS'), ('VBD', 'VBN'), ('DT', 'PDT'), ('VB', 'VBP'), ('<pad>', 'NNP'), ('<pad>', 'NNP')]\n",
      "26   [('DT', 'IN'), ('WDT', 'IN'), ('WDT', 'IN'), ('WDT', 'IN'), ('<pad>', 'VBP')]\n",
      "27   [('IN', 'WRB'), ('NNP', 'NNPS'), ('VB', 'VBP'), ('WRB', 'IN'), ('NNP', 'NNPS'), ('<pad>', 'IN'), ('VB', 'VBP'), ('VB', 'VBP'), ('<pad>', 'IN'), ('VB', 'VBP'), ('RB', 'NN'), ('VB', 'VBP'), ('NN', 'NNS'), ('NN', 'NNS'), ('VB', 'VBP'), ('WRB', 'IN'), ('<pad>', 'IN')]\n",
      "28   []\n",
      "29   [('IN', 'WRB'), ('NNP', 'NNPS'), ('<pad>', 'NN'), ('WDT', 'DT'), ('IN', 'DT'), ('<pad>', 'JJ')]\n",
      "30   [('<pad>', 'VBZ'), ('<pad>', 'IN')]\n",
      "31   [('<pad>', ','), ('<pad>', ','), ('<pad>', ','), ('<pad>', ',')]\n",
      "32   [('<pad>', '.'), ('NN', 'JJ'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "33   [('VBP', '``'), ('<pad>', '``'), ('RB', 'JJ'), ('JJ', 'NN'), ('JJ', 'NN')]\n",
      "34   [('<pad>', 'NN'), ('<pad>', 'NNP')]\n",
      "35   [('VB', 'NN'), (',', 'NNP')]\n",
      "36   [('<pad>', 'DT'), ('RBR', 'JJR'), ('NNS', 'NN'), ('NNPS', 'JJ'), ('FW', 'JJ'), ('<pad>', 'NNP'), ('<pad>', 'NNP'), ('<pad>', 'NNP'), ('<pad>', 'JJ')]\n",
      "37   [('VBZ', 'NNS'), ('<pad>', 'VBZ'), ('VBZ', 'NNS')]\n",
      "38   [('VBP', 'VB'), ('<pad>', 'NN'), ('<pad>', 'CC'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', 'NN'), ('VBN', 'VB'), ('NNP', 'NNPS'), ('VBP', 'VB'), ('RP', 'IN'), ('RB', 'JJ'), ('<pad>', 'NNP'), ('RP', 'IN')]\n",
      "39   [('DT', ':'), ('<pad>', 'NNP'), ('<pad>', \"''\"), ('JJ', ':'), ('JJ', ':'), ('DT', ':'), ('<pad>', '``'), ('<pad>', '``'), ('<pad>', ':')]\n",
      "40   [('VBD', 'VBN'), ('VBD', 'VBN'), ('JJ', 'JJR'), ('RBR', 'JJR'), ('VBN', 'JJ')]\n",
      "41   [('NNPS', 'JJ'), ('VBG', 'JJ'), ('VBG', 'JJ'), ('VBG', 'JJ'), ('NN', 'VBP')]\n",
      "42   [('NNS', 'NN'), ('VBD', 'VBN'), ('VBP', 'VB'), ('VBD', 'VBN'), ('VBD', 'VBN'), ('VBN', 'VBD'), ('VBP', 'VB'), ('WDT', 'IN'), ('VBP', 'VB'), ('VBP', 'VB')]\n",
      "43   [('VBD', 'VBN'), ('VBD', 'VBN')]\n",
      "44   [('JJ', 'NNP'), ('JJ', 'NN'), ('<pad>', '.'), ('IN', 'NNP'), ('<pad>', '.'), ('VBZ', 'NNS'), ('VBP', 'NN'), (':', '.'), ('<pad>', 'NN')]\n",
      "45   [('NNPS', 'NNS'), ('NN', 'NNP'), ('NNPS', 'NNS'), ('NNPS', 'NNS'), ('NNPS', 'NNS'), ('NNPS', 'NNS'), ('NNPS', 'NNS'), ('NNPS', 'NNS'), ('<pad>', 'IN')]\n",
      "46   []\n",
      "47   [('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('IN', 'MD'), ('JJ', 'RB'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "48   [('IN', 'RB'), ('CD', 'JJ'), ('NNP', 'JJ'), ('NNP', 'RB'), ('<pad>', 'VBD')]\n",
      "49   [('<pad>', 'NNP'), ('VBN', 'NNP'), ('RB', 'RP'), ('RB', 'RP'), ('RB', 'RP'), ('<pad>', 'POS'), ('VB', 'NN'), ('RB', 'JJ'), ('RB', 'NN'), ('NN', 'RP'), ('RB', 'RP')]\n",
      "50   [('IN', 'DT')]\n",
      "51   [('NNPS', 'NNP'), ('NNPS', 'NNP'), ('<pad>', '.'), ('NNPS', 'NNP'), ('NNP', 'NN'), ('NN', 'NNP'), ('NNPS', 'NNP')]\n",
      "52   []\n",
      "53   [('<pad>', 'DT'), ('<pad>', 'DT'), ('<pad>', 'DT'), ('<pad>', 'DT'), ('<pad>', 'DT')]\n",
      "54   [('NNS', 'NN'), ('<pad>', ','), ('<pad>', 'NN'), ('NNS', 'NN')]\n",
      "55   [('IN', 'WRB'), ('VBN', 'VBG'), ('<pad>', 'NNP'), ('JJ', 'IN'), ('VBN', 'JJ')]\n",
      "56   [('NNP', 'NNPS'), ('NNP', 'NNPS'), ('NNP', 'NNPS'), ('NNP', 'NNPS'), ('VBZ', 'NNS'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('JJ', 'NN'), ('NNP', 'NNPS'), ('NNP', 'NNPS'), ('NNP', 'NNPS')]\n",
      "57   [('IN', 'RB'), ('.', 'RB'), ('NN', 'NNP'), ('NN', 'JJ'), ('<pad>', '.'), ('NN', 'JJ'), ('NN', 'JJ'), ('<pad>', '.'), ('<pad>', '.'), ('NN', 'JJ')]\n",
      "58   [('NNP', 'NNPS'), ('JJ', 'NNP'), ('JJ', 'NNP'), ('JJ', 'NNP'), ('<pad>', '.'), ('JJ', 'NNP'), ('JJ', 'NNP'), ('NNPS', 'NNP'), ('NNP', 'NNPS'), ('NNP', 'NN')]\n",
      "59   [('NNP', 'NNPS'), ('<pad>', ','), ('NNP', ','), ('NN', 'NNP'), ('<pad>', 'POS'), ('NN', 'VBG')]\n",
      "60   [('<pad>', 'JJ'), ('<pad>', 'FW'), ('NN', 'VBN'), ('NN', 'NNS'), ('<pad>', 'NNP'), ('NN', 'NNS'), ('NN', 'NNS'), ('<pad>', 'NNP'), ('NN', 'NNS'), ('NN', 'NNS'), ('NN', 'NNS'), ('<pad>', 'NNP')]\n",
      "61   [('IN', 'DT'), ('<pad>', ','), ('<pad>', ','), ('NN', 'JJ')]\n",
      "62   [('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('JJ', 'PRP'), ('<pad>', '.'), ('IN', 'MD'), ('NNP', 'JJ')]\n",
      "63   [('VBG', 'JJ'), ('<pad>', 'NN'), ('<pad>', 'NN'), ('<pad>', 'POS'), ('<pad>', 'NN'), ('<pad>', 'POS'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', 'POS'), ('<pad>', 'POS'), ('<pad>', 'POS'), ('<pad>', 'NN'), ('<pad>', 'POS'), ('NN', 'VBP'), ('NNS', 'VBP')]\n",
      "64   [('NNP', 'NNPS'), ('IN', 'JJ'), ('IN', 'JJ'), ('IN', 'JJ'), ('RB', 'JJ'), ('IN', 'JJ'), ('<pad>', 'JJ'), ('NNP', 'NNPS'), ('<pad>', 'NNP'), ('<pad>', 'NNP'), ('NNP', 'NNPS'), ('IN', 'JJ'), ('RB', 'JJ'), ('<pad>', 'IN')]\n",
      "65   [('<pad>', '.'), ('VBP', 'VB'), ('<pad>', 'RB')]\n",
      "66   [('IN', 'DT'), ('VBN', 'JJ'), ('<pad>', 'VBN')]\n",
      "67   [('JJ', 'VBG'), ('JJ', 'VBG'), ('JJ', 'VBG'), ('JJ', 'VBG'), ('VBN', 'VBD'), ('JJ', 'VBG'), ('JJ', 'VBG')]\n",
      "68   [('JJ', 'VBN'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "69   [('TO', 'DT'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', 'NN'), ('<pad>', 'NN')]\n",
      "70   [('NNP', 'JJ'), ('NNP', 'JJ'), ('NNP', 'JJ'), ('NNP', 'JJ'), ('NNP', 'JJ'), ('NNP', 'JJ')]\n",
      "71   []\n",
      "72   [('<pad>', 'NNP'), ('JJ', 'JJR'), ('<pad>', 'JJ'), ('<pad>', 'NN')]\n",
      "73   [('<pad>', 'NN'), ('<pad>', '``')]\n",
      "74   [('IN', 'RB'), ('RB', 'NN'), ('JJ', 'NN'), ('<pad>', 'NNS'), ('NNS', 'VBN')]\n",
      "75   [('VBD', 'VBN'), ('VBD', 'VBN'), ('``', 'NNS'), ('<pad>', 'NNS')]\n",
      "76   [('<pad>', 'CD')]\n",
      "77   [('JJS', 'JJ'), ('JJ', 'NN'), ('VBN', 'JJ'), ('NNPS', 'NNS'), ('NNP', 'NN'), ('JJ', 'NN'), ('JJ', 'NN'), ('<pad>', 'VBZ'), ('VBD', 'VBN'), ('JJ', 'NN'), ('<pad>', 'NNP'), ('NNP', 'NN'), ('JJ', 'NN'), ('<pad>', 'NNP')]\n",
      "78   [('VBN', 'VBD'), ('NNP', 'NNPS'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "79   [('JJ', 'NN'), ('VBP', 'NN'), ('VBP', 'NN'), ('VBP', 'NN'), ('JJ', 'NN'), ('VBP', 'NN'), ('JJ', 'NN')]\n",
      "80   [('IN', 'WDT'), ('VBN', 'VBD'), ('VBD', 'VBN'), ('VBN', 'VBD')]\n",
      "81   [('JJ', 'NNPS'), ('NN', 'NNS'), ('NNPS', 'NNP'), ('<pad>', 'NN'), ('<pad>', 'POS'), ('<pad>', 'NNS'), ('JJ', 'NNPS'), ('IN', 'VBG')]\n",
      "82   [('<pad>', 'VBD')]\n",
      "83   [('NN', 'JJ'), ('<pad>', 'NN'), ('<pad>', 'VB')]\n",
      "84   [('NNPS', 'NNP'), ('NNS', 'NN'), ('<pad>', 'NN'), ('NNPS', 'NNP'), ('JJ', 'NNP'), ('NNS', 'NN'), ('RB', 'NNP')]\n",
      "85   [('VBZ', 'NNS'), ('VBP', 'NN'), ('NN', 'NNS'), ('NN', 'NNS'), ('<pad>', 'NNP'), ('VB', 'NNP'), ('VBZ', 'NNS'), ('NNP', 'NN'), ('NN', 'NNP'), ('<pad>', '.'), ('<pad>', 'JJ'), ('NN', 'NNP'), ('<pad>', '.')]\n",
      "86   [('<pad>', 'NNS'), ('VBP', 'VBD'), ('NNS', 'RB')]\n",
      "87   [('<pad>', 'CD'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('RB', 'IN'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.'), ('<pad>', '.')]\n",
      "88   [('IN', 'WDT')]\n",
      "89   [('<pad>', 'NNP'), ('<pad>', 'NNP'), ('<pad>', 'NNP')]\n",
      "90   [('VB', 'NN'), ('<pad>', 'VBP'), ('<pad>', 'NN'), ('<pad>', '.'), ('VBZ', 'POS'), ('VB', 'IN'), ('VB', 'NN'), ('<pad>', 'VBP'), ('<pad>', '.')]\n",
      "91   [('JJ', 'NNP'), ('VBN', 'JJ'), ('JJ', 'NNP'), ('JJ', 'NNP'), ('JJ', 'NNP'), ('JJR', 'VBN')]\n",
      "92   [('<pad>', ':'), ('<pad>', ':'), ('<pad>', 'NNP'), ('JJ', ':'), ('<pad>', ':')]\n",
      "93   [('JJ', 'CD'), ('<pad>', 'NN'), ('JJ', 'NN'), ('<pad>', 'NN')]\n",
      "94   []\n",
      "95   [('<pad>', 'NNS'), ('<pad>', 'NN'), ('<pad>', '.'), ('<pad>', 'NN'), ('VB', 'VBP'), ('<pad>', 'NN'), ('NN', 'VBG'), ('<pad>', 'NN')]\n",
      "96   [('RB', 'VBN'), ('IN', 'PRP$')]\n",
      "97   [('NN', 'JJ'), ('NNP', 'JJ'), ('NNP', 'JJ'), ('NN', 'CD'), ('DT', 'JJ')]\n",
      "98   [('<pad>', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "# number of errors per lattice \n",
    "e_len_distr = [len(e) for e in pred_errs]\n",
    "def get_tag_pred_distr(p_errs):\n",
    "    tpdistr = []\n",
    "    tgdistr = []\n",
    "    for perr in p_errs:\n",
    "        for e in perr:\n",
    "            tpdistr.append(float(e['predlabel']))\n",
    "            tgdistr.append(float(e['godlabel']))\n",
    "    return tpdistr, tgdistr\n",
    "# error tag\n",
    "\n",
    "def granular_pred_distr(p_errs):\n",
    "    gpdistr = []\n",
    "    for perr in p_errs:\n",
    "        tmppred = []\n",
    "        tmpgold = []\n",
    "        for e in perr:\n",
    "            tmppred.append(lblist[int(e['predlabel'])])\n",
    "            tmpgold.append(lblist[int(e['godlabel'])])\n",
    "        gpdistr.append(list(zip(tmppred, tmpgold)))\n",
    "    return gpdistr\n",
    "\n",
    "def understand_errpairs (epairdistr):\n",
    "    frequency = collections.Counter(epairdistr)\n",
    "    fdict = dict(frequency)\n",
    "\n",
    "    d = dict(sorted(fdict.items(), key=lambda item: item[1]))\n",
    "    #print(fdict)\n",
    "    for k in d.keys():\n",
    "        print(lblist[int(k[0])], \" \", lblist[int(k[1])], \": \", d[k])\n",
    "        \n",
    "#ep_distr, eg_distr = get_tag_pred_distr(pred_errs)\n",
    "#understand_errpairs(zip(ep_distr, eg_distr))\n",
    "granpd = granular_pred_distr(pred_errs)\n",
    "for i in range(0, len(granpd)):\n",
    "    print(i, \" \", granpd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52233476-682b-4dfd-b515-730f3c7d171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epairs = zip(ep_distr, eg_distr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678e8a6d-c0f7-485b-ba58-5cd7f772f4e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(dict(frequency))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d54f0945-f622-48a2-a2ef-68e08315f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1672)\n",
      "tensor(0.7344)\n",
      "tensor(28.2398, device='cuda:2', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "r1 = torch.rand((6, 500, 52))\n",
    "r2 = torch.rand((6, 500, 52))\n",
    "print(mse(r1, r2))\n",
    "print(loss(r1, r2))\n",
    "print(mse(latposylabels, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3601c-19d2-4b6e-8af8-8fdeeb0c18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code needed when changing set of gold labels\n",
    "def prepare_dataset(resset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for res in resset:\n",
    "        curinps = []\n",
    "        for r in res:\n",
    "            try:\n",
    "                toktmp = torch.tensor(bert_tok(clean_expanded(r)).input_ids)\n",
    "                #print(toktmp.shape)\n",
    "                if float(toktmp.shape[0])<MAX_LEN:\n",
    "                    toktmp = torch.cat([toktmp, torch.zeros(MAX_LEN-toktmp.shape[0])])\n",
    "                else:\n",
    "                    toktmp = toktmp[:MAX_LEN]\n",
    "                curinps.append(toktmp)\n",
    "            except:\n",
    "                print(\"weird error happened\") \n",
    "        print(len(curinps))\n",
    "        curouts = []\n",
    "        tinp = torch.stack(curinps).long().to(device)\n",
    "        print(tinp.shape)\n",
    "        y.append(posbmodel(tinp))\n",
    "        x.append(tinp)\n",
    "        \n",
    "        #print(\"error somewhere\")\n",
    "    return x, y\n",
    "\n",
    "def get_labset_partial(explodeds, startind, amt):\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    dsetx, dsety = prepare_dataset(explodeds[startind:startind+amt])\n",
    "    print(len(dsetx))\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    assert len(dsetx)==amt\n",
    "    latposylabels, tmaps = lattice_pos_goldlabels(dsetx, dsety, sents[startind:startind+amt])\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    del dsetx, dsety\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    return latposylabels, tmaps\n",
    "\n",
    "def get_biglabset(split):\n",
    "    result = None\n",
    "    tmaps = []\n",
    "    for i in range(0, int(len(resarrs)/split)):\n",
    "        print(\"SUBSET - \", i)\n",
    "        \n",
    "        r, tmap = get_labset_partial(resarrs, i*split, split)\n",
    "        tmaps = tmaps + tmap\n",
    "        if result == None:\n",
    "            result = r\n",
    "        else:\n",
    "            result = torch.cat((result, r))\n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        torch.save(result, './plabels/latreposlabels.pt')\n",
    "        file = open('tmaps.pkl', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(tmaps, file)\n",
    "\n",
    "        # close the file\n",
    "        file.close()\n",
    "\n",
    "    return result, tmaps\n",
    "\n",
    "def debug_newinput(linp, explinps, latout, explouts):\n",
    "    i = 0\n",
    "    tot = 0\n",
    "    while linp[i]>0:\n",
    "        print()\n",
    "        print(bert_tok.decode(linp[i]), \" \" ,bert_tok.decode(explinps[0][i]))\n",
    "        print(explinps[0][i])\n",
    "        lv, li = torch.topk(latout[i], 3)\n",
    "        ev, ei = torch.topk(explouts[6][i], 3)\n",
    "        print(li, \" \", ei)\n",
    "        #if l==e:\n",
    "        #    tot+=1\n",
    "        i+=1\n",
    "    print(tot/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f638fbd8-fb3a-43f7-aa87-b6396c9bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START embedding distance stuff\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from more_itertools import locate\n",
    "\n",
    "def ind_cos_dist (i1, i2, embed):\n",
    "    return 1-cosine(embed[i1].cpu(), embed[i2].cpu())\n",
    "\n",
    "def tok_cos_dist(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in inds1:\n",
    "        for i2 in inds2:\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    #assert l1[ind1]==l2[ind2]\n",
    "    return sims\n",
    "\n",
    "def tok_cos_notbase(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in range(0, len(inps1)):\n",
    "        for i2 in range(0, len(inps2)):\n",
    "            if inps1[i1]==inps2[i2]:\n",
    "                continue\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac78556-8dbb-4eaf-b982-bb2a390df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean(lis):\n",
    "    try:\n",
    "        return sum(lis)/len(lis)\n",
    "    except:\n",
    "        return 0.8\n",
    "\n",
    "def get_ex_distr(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[example][ex_cand])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    for r in norm_inputs[0]:\n",
    "        res.append(mean(tok_cos_dist(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_ex_notbase(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[ex_cand][0])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    res.append(mean(tok_cos_notbase(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_diff_base(latembed, inp_toks):\n",
    "    diff = []\n",
    "    for i in range(len(inp_toks)):\n",
    "        for j in range(len(inp_toks)):\n",
    "            if inp_toks[i]==inp_toks[j]:\n",
    "                diff.append(ind_cos_dist(i, j, latembed))\n",
    "    return diff\n",
    "\n",
    "def get_lat_distr(example):\n",
    "    result = []\n",
    "    tot = len(resarrs[example])\n",
    "    if tot>100:\n",
    "        tot = 100\n",
    "    for i in range(tot):\n",
    "        print(i)\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "        result.append(mean(get_ex_distr(example, i, latembed, sents)))\n",
    "    print(len(resarrs[example]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52423a8e-7096-4e79-b40d-a01b63a5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs[0:0+1])\n",
    "out = latbert(sents, posids)\n",
    "latembed = out['last_hidden_state'][0]\n",
    "plt.hist(get_diff_base(latembed, sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc8ef-af43-4a81-8e94-17596d8c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "get_ex_notbase(0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35077c7-cc98-4d8f-8c2a-d60fff83ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f08ef-4b96-48bd-a491-7d7f33cb0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2623ec-5921-4682-96ce-011304ff2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_inputs)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39cadb-8ba5-4047-a97e-e0d6d686a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda:2\"\n",
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "           output_hidden_states = True,).to(device)\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d823f-f601-4918-a88a-a3baa6714c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143582a-452b-484e-a39c-54f82d966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in examples:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('Obama')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15771d-5745-4282-88c4-66e36d66121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1457d6-fd88-4834-8fb9-c23619ebc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = LinearLatticeBert(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803ea6-c89f-4f0a-a2c1-73abf871030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = torch.tensor(sents).to(device)\n",
    "posids = torch.tensor(posids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649ba20-455f-4e41-8e4b-a741ed427306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert_model(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10775b-6e48-4eb4-95ee-c02cdbe051df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lhs = out['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd13fb0-e094-4e25-bca7-19398920a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sents[0])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a751a-d65b-4a89-a67d-cadcc18698a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_cos_dist(13, 14, lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519fa09-7daf-463e-9564-57496b5cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptest = bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ad4dd-b430-49d4-91de-295d6f3915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666146d-6818-4633-88d7-e5254550bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalout = normal_bert(torch.tensor([inptest.input_ids]),return_dict=True, output_hidden_states=True)\n",
    "normalhs = normalout['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82992cf-1849-428b-82fa-f6ebe5cc10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39a5e1-b493-4a6f-bf58-aad62b36e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_cos_dist(lhs,normalhs,  1109)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
