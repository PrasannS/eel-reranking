{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad833c3b-f011-491e-a028-f79b9f053bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flatten_lattice as fl\n",
    "import torch\n",
    "from bert_models import LinearLatticeBert, LinearPOSBert\n",
    "from encoding_utils import *\n",
    "import pickle\n",
    "from mask_utils import *\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from latmask_bert_models import LatticeBertModel\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a18d956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "STOPS = -1\n",
    "\n",
    "# get flattened graphs \n",
    "processedgraphs = fl.get_processed_graph_data(fl.frenbase, -1, STOPS)\n",
    "\n",
    "\n",
    "# get exploded candidates in case needed\n",
    "resarrs = [fl.get_cover_paths(p)[0] for p in processedgraphs]\n",
    "#resarrs = []\n",
    "#fl.get_allcands(fl.frenbase, -1, resarrs)\n",
    "\n",
    "\n",
    "\n",
    "def filter_greedy(pgraphs):\n",
    "    res = []\n",
    "    for p in pgraphs:\n",
    "        tmp = []\n",
    "        for i in range(1, len(p)):\n",
    "            tmp.append(p[i-1])\n",
    "            if p[i]['pos']<=p[i-1]['pos']:\n",
    "                break\n",
    "            elif i==len(p)-1:\n",
    "                tmp.append(p[i])\n",
    "        res.append(tmp)\n",
    "    return res\n",
    "\n",
    "if STOPS==1:\n",
    "    processedgraphs = filter_greedy(processedgraphs)\n",
    "    \n",
    "def clean_empty(rarrs, pgraphs):\n",
    "    # clean up empty examples\n",
    "    for r in range(0, len(resarrs)):\n",
    "        try:\n",
    "            if len(rarrs[r])==0:\n",
    "                print(r)\n",
    "                del rarrs[r]\n",
    "                del pgraphs[r]\n",
    "        except:\n",
    "            break\n",
    "    assert len(rarrs)==len(pgraphs)\n",
    "print(len(resarrs))\n",
    "print(len(processedgraphs))\n",
    "bert_tok = fl.bert_tok\n",
    "mbart_tok = fl.mbart_tok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d75bda89-610f-4b46-bdef-b7b517c51f0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nimport pickle\\n\\nwith open('./torchsaved/pgraphsall.pkl', 'wb') as file:\\n    pickle.dump(processedgraphs, file)\\nwith open('./torchsaved/resarrsall.pkl', 'wb') as file:\\n    pickle.dump(resarrs, file)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "with open('./torchsaved/pgraphsall.pkl', 'wb') as file:\n",
    "    pickle.dump(processedgraphs, file)\n",
    "with open('./torchsaved/resarrsall.pkl', 'wb') as file:\n",
    "    pickle.dump(resarrs, file)\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87a334e-c4ad-49c0-86f3-28ee73b1899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "167\n",
      "Two days before the trial of President Mohamed Morsi was to begin, they went down to the street. s. the street. s, who has been deposed, they went ousted President Mohamed Morsi began, the two men went down to the street. s. they were out on went to on into the took, the two men went down to they were out took to the street. s went into the the outgoingi began, the, the two they were took went into out down to the deposedi opens, the two they have taken took went out was due to start, they took went open begin, the two they were went out to open, they took went begin, the two opened were went to on out into the street s began down, the outgoing deposed Mohamed Morsi, they went down President\n"
     ]
    }
   ],
   "source": [
    "# sanity check to make sure things look ok\n",
    "p = processedgraphs[89]\n",
    "tlist = fl.get_toklist(p)\n",
    "decstr = bert_tok.decode(tlist)\n",
    "print(len(tlist))\n",
    "#for node in p:\n",
    "    #print(node['token_idx'], \" \", node['pos'])\n",
    "print(decstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14b2fef7-6f07-4c91-8eaf-d47c44a8cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO more sanity checking on whether or not we're recording the right number of branches\n",
    "def nexts_sanity(pgraph):\n",
    "    toklist = []\n",
    "    next_tok = pgraph[0]['token_idx']\n",
    "    next_pos = 0\n",
    "    for p in pgraph:\n",
    "        if next_tok == p['token_idx'] and next_pos == p['pos']:\n",
    "            tmp = p['nexts'][0].split()\n",
    "            next_tok = int(tmp[0])\n",
    "            next_pos = int(tmp[1])\n",
    "            print(bert_tok.decode(p['token_idx']))\n",
    "\n",
    "def get_attmasks(pgraphs):\n",
    "    res = []\n",
    "    i = 0\n",
    "    for p in pgraphs:\n",
    "        res.append(connect_mat(p))\n",
    "        print(i)\n",
    "        i+=1\n",
    "    return torch.stack(res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79519fd-470f-4ee0-b962-2dbfc7c337f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 500])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attmasks(processedgraphs[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbf3579-f01d-486f-a56c-bb22e508557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(processedgraphs)==101\n",
    "attmasks = get_attmasks(processedgraphs)\n",
    "# without lower triangular\n",
    "torch.save(attmasks, './torchsaved/attmasksallv3.pt')\n",
    "\n",
    "#torch.save(attmasks, './torchsaved/fixlatattmasks.pt')\n",
    "# Change this when you run stuff\n",
    "# TODO make a dictionary mapping from this to STOPS variable\n",
    "#attmasks = torch.load('./torchsaved/attmasksall.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "067a2950-f86c-4faa-a2eb-3628ec3fdb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "attmasks = torch.tril(attmasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5bf2894a-43cf-472a-9a75-8eaa81fffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#attmasks = torch.load('./torchsaved/fixlatattmasks.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a08eacc7-89ac-4d44-ac86-cd6fc80cf8e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Model setup\n",
    "class LinearPOSBertV1(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        #self.bert = LatticeBertModel(AutoConfig.from_pretrained('bert-base-cased'))\n",
    "        self.bert = AutoModel.from_pretrained('bert-base-cased')\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, pos_ids=None, attmasks=None):\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            if pos_ids==None:\n",
    "                word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "            else:\n",
    "                \n",
    "                word_rep, sentence_rep = self.bert(sentences, position_ids=pos_ids, encoder_attention_mask=attmasks, attention_mask=attmasks, return_dict=False)\n",
    "        return self.probe(word_rep)\n",
    "    \n",
    "# credit to tutorial by https://pageperso.lis-lab.fr/benoit.favre/pstaln/09_embedding_evaluation.html for \n",
    "# input / pre-processing setup\n",
    "with open('./a3distrib/lab_vocab.json') as json_file:\n",
    "    labels = json.load(json_file)\n",
    "posbmodel = LinearPOSBertV1(len(list(labels.keys())))\n",
    "t = torch.load(\"./a3distrib/ckpt/bertonewayv1.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9715f05-06af-46db-a052-679f7a6c5f6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b31b5622-1e04-4dd5-a148-372f72b9f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1069140992\n"
     ]
    }
   ],
   "source": [
    "posbmodel.load_state_dict(t)\n",
    "posbmodel.eval()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ffe1023a-e250-46ec-8eb8-ec114f06ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "635572736\n"
     ]
    }
   ],
   "source": [
    "del t\n",
    "print(torch.cuda.memory_allocated(\"cuda:0\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e8199e70-6d4b-41a2-98de-13ffb101549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n",
    "# sanity check roughly how many nodes current input params are producing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3d3f6f21-568d-46ad-891e-46259beb2199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(226.24752475247524, 462)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def avg_nodes(sentences):\n",
    "    zcnts = [500-list(sent).count(0) for sent in sentences]\n",
    "    return sum(zcnts)/len(zcnts), max(zcnts)\n",
    "\n",
    "\n",
    "avg_nodes(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6df3153c-429a-4129-a3c6-3a1cc7d26c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# get maps from token -> labels\n",
    "with open('./tmaps.pkl', 'rb') as handle:\n",
    "    tmaps = pickle.load(handle)\n",
    "    \n",
    "tmaps = []\n",
    "for i in range(0, 99):\n",
    "    with open('./torchsaved/tmapssplit/tmaps0_'+str(i)+'.pkl', 'rb') as file:\n",
    "        tmaps.append(pickle.load(file)[0])\n",
    "\"\"\"\n",
    "\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f70be238-2e99-4226-8d4b-f1a161043cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EX = 101\n",
    "tmaps = []\n",
    "for i in range(0, N_EX):\n",
    "    with open('./torchsaved/tmapsmasked/tmaps_'+str(i)+'.pkl', 'rb') as file:\n",
    "        tmaps.append(pickle.load(file)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748456bb-cd2a-49a3-bc1c-3dd14fdcaec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "#with torch.no_grad():\n",
    "    #latposylabels, tmaps = get_biglabset(1)\n",
    "latposylabels = tmap_pos_goldlabels(tmaps, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2e12aba4-08d1-4c40-9b8a-423cd40dbf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmaps[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69dbee4-e32b-4cf6-b825-2c0db493ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(tmaps, \"./torchsaved/tmapsnewdone.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/latposylabels.pt\")\n",
    "#torch.save(sents, \"./torchsaved/sents.pt\")\n",
    "#torch.save(posids, \"./torchsaved/posids.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/betterposlatposylabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "04959e22-d3b8-4d60-a4f7-119ea5121506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 500, 44])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latposylabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c79fff9-2529-4730-a8d2-7ee0781ecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_id_test(lenvals):\n",
    "    tmp = list(range(0, 500))\n",
    "    res = []\n",
    "    for i in range(0, lenvals):\n",
    "        res.append(torch.tensor(tmp))\n",
    "    return torch.stack(res).to(device)\n",
    "\n",
    "\n",
    "def mod_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            if i>0 and p[i]==0:\n",
    "                p[i] = i\n",
    "    return cop\n",
    "\n",
    "def fix_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            p[i] = i\n",
    "    return cop\n",
    "\n",
    "def check_accuracy(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "\n",
    "def identify_errors(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    res = []\n",
    "    for i in range(0, len(setpred)):\n",
    "        errtmp = []\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "            else:\n",
    "                tmp = {}\n",
    "                tmp['index'] = j\n",
    "                tmp['predvec'] = ex[j]\n",
    "                tmp['goldvec'] = setlabels[i][j]\n",
    "                tmp['predlabel'] = torch.argmax(ex[j])\n",
    "                tmp['godlabel'] = torch.argmax(setlabels[i][j])\n",
    "                errtmp.append(tmp)\n",
    "        res.append(errtmp)\n",
    "                \n",
    "    return res\n",
    "\n",
    "def check_randacc(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(torch.rand(52).to(device))==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "93a46a36-28cf-4af4-9612-2ede5c50a173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  2,  3,  3, 14, 16, 22, 23,  3,  3,  2,  3,  3,  3,  3,  3, 12,  4,\n",
       "         4, 12,  4,  1,  2,  5, 16, 22,  3,  5,  1, 25,  2, 34,  5,  1,  5,  1,\n",
       "         4, 10,  3,  4, 12,  1,  5,  1,  3,  5, 16, 22,  2, 34,  5,  1,  5,  1,\n",
       "         4, 10,  3,  1,  3,  4,  4,  4,  1,  5,  1,  2,  4, 12, 25,  3,  5,  1,\n",
       "         1,  2,  5, 16, 22,  2,  3, 19, 34,  2,  5, 16, 22,  5,  1,  5, 12,  4,\n",
       "         4,  4, 12, 25,  4,  4,  8, 15,  4, 12,  1,  5, 12,  1,  2,  5,  4,  1,\n",
       "         2,  5, 16, 22,  3,  5,  1, 25,  2, 34,  5,  1,  5,  1,  4, 10,  3,  5,\n",
       "        16, 22,  3,  5, 16, 22,  2, 22,  2,  3, 19, 22,  5,  2, 34,  1, 34, 34,\n",
       "        22,  4, 12, 25,  3,  5, 16, 22,  2,  5,  1, 25, 22,  5, 16,  1, 22, 25,\n",
       "         5,  2, 34,  5,  1,  2,  5,  5,  1,  5,  1, 19, 16, 22,  2, 34,  5, 22,\n",
       "         2,  1, 22, 25,  2, 34,  5, 25, 19,  5, 16, 22,  5, 22,  2,  3, 19,  1,\n",
       "         2, 34, 34,  5,  1,  2, 34,  3,  3,  3,  5,  1, 16, 22, 16, 22,  2,  5,\n",
       "        16, 22,  5,  1, 22, 25,  5, 12, 25,  3,  5,  1,  2,  5, 16, 22,  2,  3,\n",
       "        19, 34,  5,  1,  2,  4, 16, 22,  1, 20, 14, 18,  1,  2, 18,  1, 25,  3,\n",
       "         5,  2,  5,  1, 16, 22, 22,  2,  5,  3,  1,  3,  3, 12, 20, 18, 14, 25,\n",
       "         5,  1,  2,  3,  1, 25,  2, 22,  2,  3,  3,  3, 19,  5, 25,  3,  3,  1,\n",
       "        21,  5,  5, 18,  5,  1,  2,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "         6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(latposylabels[0], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b52998d8-dc30-4ef8-8af0-d8369c385271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  101,  1109,  1646,  1697,  1108,  1106,  3531,  8612,  3460,  2110,\n",
       "         1302,  8212,  2586, 15147,  1182,  5286,   117,  1379,   122,   117,\n",
       "         1381,  1107,  1126,  3098,  1106,  5622,  1646,  5052,  1107,  2935,\n",
       "         1103,  4997,  4003,  1104,  4289,  1107,  1421,  1201,   119,  1381,\n",
       "          117,  1107,  3403,  1104,  1646,  5052,  1106,  2147,  1103,  4997,\n",
       "         4003,  1104,  4289,  1107,  1421,  1201,   119,  1113,  5286,   122,\n",
       "         1379,  1381,  1107,  3403,  1104,  1126,  1381,   117,  5788,  1646,\n",
       "         5052,  1107,  1107,   170,  6875,  1106,  1494,  1103,  1244,  1311,\n",
       "         4997,  1126,  3098,  1106,  5622,  5052,  1107,  3403,   117,   122,\n",
       "         1379,  1381,   117,  5788,  1379,   122,   188,  1204,  1381,   117,\n",
       "         1107,  3403,   117,  1107,  1126,  3098,  1381,  1107,  1126,  2661,\n",
       "         1106,  5622,  1646,  5052,  1107,  2935,  1103,  4997,  4003,  1104,\n",
       "         4289,  1107,  1421,  1201,   119,  3098,  1106,  1525,  1646,  1619,\n",
       "         1106,  2147,  1103,  1494,  1103,  1244,  1311,  4127,  4003,  1103,\n",
       "         4583,  1104, 11112,  4997,  5622,  1381,   117,  5788,  1646,  4256,\n",
       "         1106,  2147,  1103,  1619,  1107,  2935,  1494,  5052,  1106,  1107,\n",
       "         4127,  1158,  4003,  1103,  4997,  4003,  1107,  1126,  3098,  3403,\n",
       "         1104,  5052,  1121,  1311,  1106,  4127,  1103,  4997,  4003,  2147,\n",
       "         1103,  1107,  4127,  1158,  1103,  4997,  4003,  2935,  1311,  4256,\n",
       "         1106,  2147,  5052,  1494,  1103,  1646,  1311,  1107,  1103,  4997,\n",
       "        11112,  4003,  1104,  1103, 11112,   158,   119,  1646,  1619,  1107,\n",
       "         1106,  1494,  1106,  2147,  1103,  4256,  1106,  4127,  5052,  1107,\n",
       "         4127,  1158,  4003,   117,  5788,  1646,  5052,  1107,   170,  6875,\n",
       "         1106,  1494,  1103,  1244,  1311,  4997,  3403,  1104,  1126,  1381,\n",
       "         1106,  5622,  1112,  1119,  4110, 11053,  1107,  1103,  7816,  1104,\n",
       "         5788,  1646,  5052,   170,  6875,  1111,  1106,  5622,  1494,  1103,\n",
       "         1583,  1646,  1104,   158,   119,   117,  1119, 11053,  4110,  5788,\n",
       "         5052,  1121,  1103,  1646,  1107,  2935,  1103,  1494,  1103,  1646,\n",
       "         1244,  1244,  1311,  5052,  2935,   158,   119,  1107,  1117, 12485,\n",
       "         5052,  7816,  6875,  1111,  1126,  2661,   102,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "38fc1532-0756-4196-8ae2-edc68d9ccb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.8202827946768061\n",
      "0.7848344423320659\n"
     ]
    }
   ],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred1 = posbmodel(sents, mod_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred2 = posbmodel(sents, fix_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred3 = posbmodel(sents, mod_posids(posids), None)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred4 = posbmodel(sents, fix_posids(posids), None)\n",
    "\n",
    "            \n",
    "print(check_accuracy(pred1, latposylabels))\n",
    "print(check_accuracy(pred2, latposylabels))\n",
    "print(check_accuracy(pred3, latposylabels))\n",
    "print(check_accuracy(pred4, latposylabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e8b3f457-a426-41ea-9f52-abfb85481287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]],\n",
       "\n",
       "        [[nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         ...,\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan],\n",
       "         [nan, nan, nan,  ..., nan, nan, nan]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bcf4685a-357e-4030-af5e-25ead77fcedf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 500, 44])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ad0ff9ad-55f2-43f8-8818-aad5f67b9a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./torchsaved/sentsdecent.pkl', 'wb') as file:\n",
    "    pickle.dump(sents, file)\n",
    "    \n",
    "with open('./torchsaved/posidsdecent.pkl', 'wb') as file:\n",
    "    pickle.dump(posids, file)\n",
    "    \n",
    "with open('./torchsaved/attmasksdecent.pkl', 'wb') as file:\n",
    "    pickle.dump(attmasks, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2a0ba3b1-c306-4fca-888b-fbea0ab22f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./torchsaved/predsdecent.pkl', 'wb') as file:\n",
    "    pickle.dump(pred1, file)\n",
    "    \n",
    "with open('./torchsaved/labelsdecent.pkl', 'wb') as file:\n",
    "    pickle.dump(latposylabels, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a1bad11-dad2-4acb-9cea-e41acbff9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_errs  = identify_errors(pred1, latposylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdaf2dd6-62bd-43a0-94dc-cade995c110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lblist = [l for l in labels.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "684a4e9a-02a7-423f-9dd6-256d2f23566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4926\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for e in errpairs.keys():\n",
    "    tot+=errpairs[e]\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b263b-05b6-4d6a-a753-fb85c4ac24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# number of errors per lattice \n",
    "e_len_distr = [len(e) for e in pred_errs]\n",
    "def get_tag_pred_distr(p_errs):\n",
    "    tpdistr = []\n",
    "    tgdistr = []\n",
    "    for perr in p_errs:\n",
    "        for e in perr:\n",
    "            tpdistr.append(float(e['predlabel']))\n",
    "            tgdistr.append(float(e['godlabel']))\n",
    "    return tpdistr, tgdistr\n",
    "# error tag\n",
    "\n",
    "def granular_pred_distr(p_errs):\n",
    "    gpdistr = []\n",
    "    for perr in p_errs:\n",
    "        tmppred = []\n",
    "        tmpgold = []\n",
    "        for e in perr:\n",
    "            tmppred.append(lblist[int(e['predlabel'])])\n",
    "            tmpgold.append(lblist[int(e['godlabel'])])\n",
    "        gpdistr.append(list(zip(tmppred, tmpgold)))\n",
    "    return gpdistr\n",
    "\n",
    "def understand_errpairs (epairdistr):\n",
    "    frequency = collections.Counter(epairdistr)\n",
    "    fdict = dict(frequency)\n",
    "\n",
    "    d = dict(sorted(fdict.items(), key=lambda item: item[1]))\n",
    "    #print(fdict)\n",
    "    for k in d.keys():\n",
    "        print(lblist[int(k[0])], \" \", lblist[int(k[1])], \": \", d[k])\n",
    "    return d\n",
    "        \n",
    "ep_distr, eg_distr = get_tag_pred_distr(pred_errs)\n",
    "errpairs = understand_errpairs(zip(ep_distr, eg_distr))\n",
    "granpd = granular_pred_distr(pred_errs)\n",
    "for i in range(0, len(granpd)):\n",
    "    print(i, \" \", granpd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52233476-682b-4dfd-b515-730f3c7d171e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "678e8a6d-c0f7-485b-ba58-5cd7f772f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.2313,  -3.2251,  -6.9445,  ..., -31.4852, -19.2721, -20.7780],\n",
       "        [ -3.4530,   3.3715,   9.0444,  ...,  -8.5703, -12.5707, -13.5763],\n",
       "        [ -5.2397,   0.5385,   2.7538,  ..., -14.1365, -36.7951, -15.4723],\n",
       "        ...,\n",
       "        [ 14.5528,  -4.9714, -18.5249,  ..., -51.4184, -28.4842, -25.7899],\n",
       "        [ 14.5528,  -4.9714, -18.5249,  ..., -51.4184, -28.4842, -25.7899],\n",
       "        [ 14.5528,  -4.9714, -18.5249,  ..., -51.4184, -28.4842, -25.7899]],\n",
       "       device='cuda:0', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "latposylabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d54f0945-f622-48a2-a2ef-68e08315f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1663)\n",
      "tensor(0.7329)\n",
      "tensor(45.7936, device='cuda:0', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "r1 = torch.rand((6, 500, 52))\n",
    "r2 = torch.rand((6, 500, 52))\n",
    "print(mse(r1, r2))\n",
    "print(loss(r1, r2))\n",
    "print(mse(latposylabels, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43d3601c-19d2-4b6e-8af8-8fdeeb0c18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code needed when changing set of gold labels\n",
    "def prepare_dataset(resset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for res in resset:\n",
    "        curinps = []\n",
    "        for r in res:\n",
    "            try:\n",
    "                toktmp = torch.tensor(bert_tok(clean_expanded(r)).input_ids)\n",
    "                #print(toktmp.shape)\n",
    "                if float(toktmp.shape[0])<MAX_LEN:\n",
    "                    toktmp = torch.cat([toktmp, torch.zeros(MAX_LEN-toktmp.shape[0])])\n",
    "                else:\n",
    "                    toktmp = toktmp[:MAX_LEN]\n",
    "                curinps.append(toktmp)\n",
    "            except:\n",
    "                print(\"weird error happened\") \n",
    "        print(len(curinps))\n",
    "        curouts = []\n",
    "        tinp = torch.stack(curinps).long().to(device)\n",
    "        print(tinp.shape)\n",
    "        y.append(posbmodel(tinp))\n",
    "        x.append(tinp)\n",
    "        del tinp\n",
    "        \n",
    "        #print(\"error somewhere\")\n",
    "    return x, y\n",
    "\n",
    "def get_labset_partial(explodeds, startind, amt):\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    dsetx, dsety = prepare_dataset(explodeds[startind:startind+amt])\n",
    "    print(len(dsetx))\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    assert len(dsetx)==amt\n",
    "    latposylabels, tmaps = lattice_pos_goldlabels(dsetx, dsety, sents[startind:startind+amt])\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    del dsetx, dsety\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "    return latposylabels, tmaps\n",
    "\n",
    "def get_biglabset(split):\n",
    "    #result = None\n",
    "    #tmaps = []\n",
    "    for i in range(0, int(len(resarrs)/split)):\n",
    "        print(\"SUBSET - \", i)\n",
    "        r, tmap = get_labset_partial(resarrs, i*split, split)\n",
    "        #tmaps = tmaps + tmap\n",
    "        \"\"\"\n",
    "        if result == None:\n",
    "            result = r\n",
    "        else:\n",
    "            result = torch.cat((result, r))\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        #torch.save(result, './plabels/latreposlabels0.pt')\n",
    "        file = open('./torchsaved/tmapsmasked/tmaps_'+str(i*split)+'.pkl', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(tmap, file)\n",
    "\n",
    "        # close the file\n",
    "        file.close()\n",
    "        del r\n",
    "        del tmap\n",
    "        torch.cuda.empty_cache()\n",
    "        print(torch.cuda.memory_allocated(\"cuda:0\"))\n",
    "\n",
    "def debug_newinput(linp, explinps, latout, explouts):\n",
    "    i = 0\n",
    "    tot = 0\n",
    "    while linp[i]>0:\n",
    "        print()\n",
    "        print(bert_tok.decode(linp[i]), \" \" ,bert_tok.decode(explinps[0][i]))\n",
    "        print(explinps[0][i])\n",
    "        lv, li = torch.topk(latout[i], 3)\n",
    "        ev, ei = torch.topk(explouts[6][i], 3)\n",
    "        print(li, \" \", ei)\n",
    "        #if l==e:\n",
    "        #    tot+=1\n",
    "        i+=1\n",
    "    print(tot/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c1a3a-7dd1-46b9-82a4-c20a28e04f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to generate stuff for gold\n",
    "get_biglabset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0690f609-5f8d-4405-bf85-87aa35ae539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f638fbd8-fb3a-43f7-aa87-b6396c9bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START embedding distance stuff\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from more_itertools import locate\n",
    "\n",
    "def ind_cos_dist (i1, i2, embed):\n",
    "    return 1-cosine(embed[i1].cpu(), embed[i2].cpu())\n",
    "\n",
    "def tok_cos_dist(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in inds1:\n",
    "        for i2 in inds2:\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    #assert l1[ind1]==l2[ind2]\n",
    "    return sims\n",
    "\n",
    "def tok_cos_notbase(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in range(0, len(inps1)):\n",
    "        for i2 in range(0, len(inps2)):\n",
    "            if inps1[i1]==inps2[i2]:\n",
    "                continue\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac78556-8dbb-4eaf-b982-bb2a390df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean(lis):\n",
    "    try:\n",
    "        return sum(lis)/len(lis)\n",
    "    except:\n",
    "        return 0.8\n",
    "\n",
    "def get_ex_distr(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[example][ex_cand])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    for r in norm_inputs[0]:\n",
    "        res.append(mean(tok_cos_dist(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_ex_notbase(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[ex_cand][0])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    res.append(mean(tok_cos_notbase(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_diff_base(latembed, inp_toks):\n",
    "    diff = []\n",
    "    for i in range(len(inp_toks)):\n",
    "        for j in range(len(inp_toks)):\n",
    "            if inp_toks[i]==inp_toks[j]:\n",
    "                diff.append(ind_cos_dist(i, j, latembed))\n",
    "    return diff\n",
    "\n",
    "def get_lat_distr(example):\n",
    "    result = []\n",
    "    tot = len(resarrs[example])\n",
    "    if tot>100:\n",
    "        tot = 100\n",
    "    for i in range(tot):\n",
    "        print(i)\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "        result.append(mean(get_ex_distr(example, i, latembed, sents)))\n",
    "    print(len(resarrs[example]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52423a8e-7096-4e79-b40d-a01b63a5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs[0:0+1])\n",
    "out = latbert(sents, posids)\n",
    "latembed = out['last_hidden_state'][0]\n",
    "plt.hist(get_diff_base(latembed, sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc8ef-af43-4a81-8e94-17596d8c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "get_ex_notbase(0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35077c7-cc98-4d8f-8c2a-d60fff83ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f08ef-4b96-48bd-a491-7d7f33cb0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2623ec-5921-4682-96ce-011304ff2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_inputs)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39cadb-8ba5-4047-a97e-e0d6d686a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda:0\"\n",
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "           output_hidden_states = True,).to(device)\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d823f-f601-4918-a88a-a3baa6714c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143582a-452b-484e-a39c-54f82d966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in examples:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('Obama')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15771d-5745-4282-88c4-66e36d66121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1457d6-fd88-4834-8fb9-c23619ebc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = LinearLatticeBert(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803ea6-c89f-4f0a-a2c1-73abf871030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = torch.tensor(sents).to(device)\n",
    "posids = torch.tensor(posids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649ba20-455f-4e41-8e4b-a741ed427306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert_model(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10775b-6e48-4eb4-95ee-c02cdbe051df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lhs = out['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd13fb0-e094-4e25-bca7-19398920a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sents[0])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a751a-d65b-4a89-a67d-cadcc18698a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_cos_dist(13, 14, lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519fa09-7daf-463e-9564-57496b5cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptest = bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ad4dd-b430-49d4-91de-295d6f3915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666146d-6818-4633-88d7-e5254550bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalout = normal_bert(torch.tensor([inptest.input_ids]),return_dict=True, output_hidden_states=True)\n",
    "normalhs = normalout['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82992cf-1849-428b-82fa-f6ebe5cc10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39a5e1-b493-4a6f-bf58-aad62b36e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_cos_dist(lhs,normalhs,  1109)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
