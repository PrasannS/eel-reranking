{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad833c3b-f011-491e-a028-f79b9f053bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 04:22:46.058093: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-05 04:22:46.058113: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import flatten_lattice as fl\n",
    "import torch\n",
    "from bert_models import LinearLatticeBert, LinearPOSBert\n",
    "from encoding_utils import *\n",
    "import pickle\n",
    "from mask_utils import *\n",
    "import torch.nn as nn\n",
    "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
    "from latmask_bert_models import LatticeBertModel\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a18d956d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "61\n",
      "99\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "STOPS = -1\n",
    "\n",
    "# get exploded candidates in case needed\n",
    "resarrs = []\n",
    "fl.get_allcands(fl.frenbase, -1, resarrs)\n",
    "\"\"\n",
    "\n",
    "# get flattened graphs \n",
    "processedgraphs = fl.get_processed_graph_data(fl.frenbase, -1, STOPS)\n",
    "greedy = False\n",
    "\n",
    "def filter_greedy(pgraphs):\n",
    "    res = []\n",
    "    for p in pgraphs:\n",
    "        tmp = []\n",
    "        for i in range(1, len(p)):\n",
    "            tmp.append(p[i-1])\n",
    "            if p[i]['pos']<=p[i-1]['pos']:\n",
    "                break\n",
    "            elif i==len(p)-1:\n",
    "                tmp.append(p[i])\n",
    "        res.append(tmp)\n",
    "    return res\n",
    "\n",
    "if STOPS==1:\n",
    "    processedgraphs = filter_greedy(processedgraphs)\n",
    "    \n",
    "# clean up empty examples\n",
    "for r in range(0, len(resarrs)):\n",
    "    try:\n",
    "        if len(resarrs[r])==0:\n",
    "            print(r)\n",
    "            del resarrs[r]\n",
    "            del processedgraphs[r]\n",
    "    except:\n",
    "        break\n",
    "print(len(resarrs))\n",
    "print(len(processedgraphs))\n",
    "bert_tok = fl.bert_tok\n",
    "mbart_tok = fl.mbart_tok\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d75bda89-610f-4b46-bdef-b7b517c51f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./torchsaved/resarrsall.pkl', 'wb') as file:\n",
    "    pickle.dump(resarrs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45348667-f877-47f6-8963-81d3255225c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./torchsaved/pgraphsall.pkl', 'wb') as file:\n",
    "    pickle.dump(processedgraphs, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b87a334e-c4ad-49c0-86f3-28ee73b1899c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377\n",
      "The US President was to receive Iraqi Prime Minister Nouri Al Maliki Friday, November 1, 2013 in an effort to seek US assistance in fighting the worst wave of violence in five years. 2013, in search of US assistance to fight the worst wave of violence in five years. on Friday 1 November 2013 in search of an 2013, seeking US assistance in in a bid to help the United States fight the worst an effort to seek US assistance in search, 1 November 2013 2013, seeking November 1 st 2013, in search, in an effort 2013 in an attempt to seek US assistance in fighting the worst wave of violence in five years. effort to find US support to fight the help the United States combat the worst wave fight the biggest wave of strongest wave of worst seek 2013, seeking US aid to fight the support to fight the in fighting the help in fighting the assistance to in combating the worst wave fighting the worst wave in an effort search of assistance from the United States to combat the worst wave fight the in combating the worst wave fighting the United States aid to fight assistance to fight help from the US to fight the United States in fighting the to combat the worst strongest wave of fight the strongest U. US support in to help to fight the in fighting the aid in fighting the to combat the fight the assistance in combating to combat the fight the worst wave, seeking US assistance in a bid to help the United States fight the worst search of an 2013 to seek as he sought US assistance in seeks US assistance in in the hopes of seeking US assistance a bid for US assistance in to seek help the country fight the worst US fight the worst search of U. 2013, to seek as he seeks sought seeking assistance from the US in fighting the help from the US to fight the United United States assistance in fighting U. in his quest for US assistance the hopes a bid for an attempt\n"
     ]
    }
   ],
   "source": [
    "# sanity check to make sure things look ok\n",
    "p = processedgraphs[0]\n",
    "tlist = fl.get_toklist(p)\n",
    "decstr = bert_tok.decode(tlist)\n",
    "print(len(tlist))\n",
    "#for node in p:\n",
    "    #print(node['token_idx'], \" \", node['pos'])\n",
    "print(decstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14b2fef7-6f07-4c91-8eaf-d47c44a8cf12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO more sanity checking on whether or not we're recording the right number of branches\n",
    "def nexts_sanity(pgraph):\n",
    "    toklist = []\n",
    "    next_tok = pgraph[0]['token_idx']\n",
    "    next_pos = 0\n",
    "    for p in pgraph:\n",
    "        if next_tok == p['token_idx'] and next_pos == p['pos']:\n",
    "            tmp = p['nexts'][0].split()\n",
    "            next_tok = int(tmp[0])\n",
    "            next_pos = int(tmp[1])\n",
    "            print(bert_tok.decode(p['token_idx']))\n",
    "\n",
    "def get_attmasks(pgraphs):\n",
    "    res = []\n",
    "    i = 0\n",
    "    for p in pgraphs:\n",
    "        res.append(connect_mat(p))\n",
    "        print(i)\n",
    "        i+=1\n",
    "    return torch.stack(res).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8f05ac73-69b0-4a24-9e54-601dd40f8fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = connect_mat(processedgraphs[0])\n",
    "c[400]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b79519fd-470f-4ee0-b962-2dbfc7c337f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([      0,       1,       1,       1,       1,       1,       1,       1,\n",
      "              1,       1,       1,       1,       1,       1,       1,       1,\n",
      "              1,       2,       2,       4,       8,      16,      16,      24,\n",
      "             24,    1120,    4480,   17058,   51174,  375154, 1875770, 3751540,\n",
      "        3751540, 3751540, 3751540, 3751540, 3751540, 3751540,       4,      10,\n",
      "             38,      76,     152,     314,    1480,    2600,    6024,   23720,\n",
      "          71160,  142320,  142320,  142320,  142320,  142320,  142320,  142320,\n",
      "              1,       1,       1,       2,       2,       6,      12,      12,\n",
      "             12,       2,       4,       4,       4,       4,      36,       6,\n",
      "              6,       6,      18,      18,      94,     412,     824,    6024,\n",
      "          23720,   71160,      12,      12,      18,      18,     314,    1480,\n",
      "           5560,      12,       1,       2,       2,       4,       4,      10,\n",
      "             14,       2,       2,       2,       2,       6,      12,      36,\n",
      "             72,      10,      38,      76,      76,      10,      36,      72,\n",
      "             72,     258,     516,    1150,    1150,    1150,    1150,  309526,\n",
      "         928578, 2476208, 7428624, 7428624, 7428624, 7428624, 7428624, 6474048,\n",
      "            144,     258,     258,    1150,    1150,    8328,   81258,  309526,\n",
      "           1378,    7178,   21534,   64602,   64602,  309526,  928578, 2476208,\n",
      "          81258,  309526,  309526, 2476208, 7428624,  309526, 2476208, 7428624,\n",
      "         928578,     516,      10,      10,      10,      10,      10,     258,\n",
      "            516,    7178,      10,     258,     516,    7178,      88,     352,\n",
      "           7178,      34,      88,     352,    7178,      22,     258,      88,\n",
      "             88,      88,   23720,   71160,  142320,     352,    7178,    7178,\n",
      "           7178,      36,      72,     144,      72,     224,    1480,    1856,\n",
      "           7178,   21534,   64602,  129204,  387612, 1808856, 3617712, 7235424,\n",
      "         258408, 1808856,  129204,  387612,  387612,  387612,  387612,  387612,\n",
      "         258408, 1808856,     412,     824,     824,    1872,    3744,    1048,\n",
      "           1872,    3744,     376,    1856,    7178,    7178,    8328,   81258,\n",
      "         309526,   21534,   64602,  129204,  258408, 1808856,  129204,  387612,\n",
      "        1808856, 3617712, 3617712, 7235424, 7235424,  258408, 1808856, 3617712,\n",
      "            224,     224,    1120,    1120,   17058,    8098,    1378,    8098,\n",
      "          25854,  375154,   17058,   51174,  375154,    1120,   17058,   51174,\n",
      "         375154,    8098,   33254,  375154,   25854,  375154,    4480,   17058,\n",
      "          33254,   33254,    8098,   33254,  375154,   25854,  375154, 1875770,\n",
      "        3751540,       4,      14,      14,      26,       8,       8,       8,\n",
      "             24,      34,      34,      34,      34,   25854,  375154, 1875770,\n",
      "              8,       8,      16,       6,      18,      36,      18,      36,\n",
      "             72,     314,    1480,    5560,      72,     314,    1480,    5560,\n",
      "             38,      76,     152,     224,     224,     224,    1048,      76,\n",
      "            152,     342,    1120,    4480,   17058,     152,     152,     376,\n",
      "            376,     376,   25854,  375154, 1875770,    1150,   25854,  375154,\n",
      "        1875770,      76,     152,     152,     152,       6,      12,      18,\n",
      "             36,      18,      36,      72,      72,      12,      26,      38,\n",
      "             94,    1120,    5560,    5560,   23720,      12,      38,      94,\n",
      "           1120,    2600,    6024,   23720,     412,      12,      12,      22,\n",
      "             88,     352,      12,      12,      38,      38,      38,     342,\n",
      "           1120,    4480,      76,     152,      76,     152,     342,      76,\n",
      "             76])\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 500, 500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_attmasks(processedgraphs[:1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecbf3579-f01d-486f-a56c-bb22e508557c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(processedgraphs)==99\n",
    "#attmasks = get_attmasks(processedgraphs)\n",
    "#torch.save(attmasks, './torchsaved/attmasksall.pt')\n",
    "#torch.save(attmasks, './torchsaved/fixlatattmasks.pt')\n",
    "# Change this when you run stuff\n",
    "# TODO make a dictionary mapping from this to STOPS variable\n",
    "attmasks = torch.load('./torchsaved/attmasksall.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b19b3045-dec4-48df-8d3a-31c5135a345b",
   "metadata": {},
   "outputs": [],
   "source": [
    "attmasks[attmasks<0] = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bf2894a-43cf-472a-9a75-8eaa81fffa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "attmasks = torch.load('./torchsaved/fixlatattmasks.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a08eacc7-89ac-4d44-ac86-cd6fc80cf8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model setup\n",
    "class LinearPOSBertV1(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = LatticeBertModel(AutoConfig.from_pretrained('bert-base-cased'))\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, pos_ids=None, attmasks=None):\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            if pos_ids==None:\n",
    "                word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "            else:\n",
    "                \n",
    "                word_rep, sentence_rep = self.bert(sentences, position_ids=pos_ids, encoder_attention_mask=attmasks, attention_mask=attmasks, return_dict=False)\n",
    "        return self.probe(word_rep)\n",
    "    \n",
    "# credit to tutorial by https://pageperso.lis-lab.fr/benoit.favre/pstaln/09_embedding_evaluation.html for \n",
    "# input / pre-processing setup\n",
    "with open('./a3distrib/lab_vocab.json') as json_file:\n",
    "    labels = json.load(json_file)\n",
    "posbmodel = LinearPOSBertV1(len(list(labels.keys())))\n",
    "t = torch.load(\"./a3distrib/ckpt/posbertfixedv0.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b31b5622-1e04-4dd5-a148-372f72b9f345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "966856704\n"
     ]
    }
   ],
   "source": [
    "posbmodel.load_state_dict(t)\n",
    "posbmodel.eval()\n",
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_allocated(\"cuda:2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ffe1023a-e250-46ec-8eb8-ec114f06ef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "533475840\n"
     ]
    }
   ],
   "source": [
    "del t\n",
    "print(torch.cuda.memory_allocated(\"cuda:2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "babf0f34-b887-4538-b0a3-ce07a283b626",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n",
    "# sanity check roughly how many nodes current input params are producing\n",
    "zcnt = 0\n",
    "for p in sents[0]:\n",
    "    if p==0:\n",
    "        zcnt+=1\n",
    "print(500-zcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ca35e10e-1e5e-4d20-b798-8acadc5859de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "545807360\n"
     ]
    }
   ],
   "source": [
    "# get maps from token -> labels\n",
    "#with open('./tmaps.pkl', 'rb') as handle:\n",
    "#    tmaps = pickle.load(handle)\n",
    "    \n",
    "tmaps = []\n",
    "for i in range(0, 99):\n",
    "    with open('./torchsaved/tmapssplit/tmaps0_'+str(i)+'.pkl', 'rb') as file:\n",
    "        tmaps.append(pickle.load(file)[0])\n",
    "    \n",
    "print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664fd00-9d2d-4ecf-a8ab-d5d05133b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#with torch.no_grad():\n",
    "    #latposylabels, tmaps = get_biglabset(1)\n",
    "latposylabels = tmap_pos_goldlabels(tmaps, sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e12aba4-08d1-4c40-9b8a-423cd40dbf7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tmaps[0][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f69dbee4-e32b-4cf6-b825-2c0db493ab71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(tmaps, \"./torchsaved/tmapsnewdone.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/latposylabels.pt\")\n",
    "#torch.save(sents, \"./torchsaved/sents.pt\")\n",
    "#torch.save(posids, \"./torchsaved/posids.pt\")\n",
    "#torch.save(latposylabels, \"./torchsaved/betterposlatposylabels.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "04959e22-d3b8-4d60-a4f7-119ea5121506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([99, 500, 44])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latposylabels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c79fff9-2529-4730-a8d2-7ee0781ecc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inp_id_test(lenvals):\n",
    "    tmp = list(range(0, 500))\n",
    "    res = []\n",
    "    for i in range(0, lenvals):\n",
    "        res.append(torch.tensor(tmp))\n",
    "    return torch.stack(res).to(device)\n",
    "\n",
    "\n",
    "def mod_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            if i>0 and p[i]==0:\n",
    "                p[i] = i\n",
    "    return cop\n",
    "\n",
    "def fix_posids(pids):\n",
    "    cop = pids\n",
    "    for p in cop:\n",
    "        for i in range(0, len(p)):\n",
    "            p[i] = i\n",
    "    return cop\n",
    "\n",
    "def check_accuracy(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot\n",
    "\n",
    "def identify_errors(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    res = []\n",
    "    for i in range(0, len(setpred)):\n",
    "        errtmp = []\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            elif torch.argmax(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(ex[j])==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "            else:\n",
    "                tmp = {}\n",
    "                tmp['index'] = j\n",
    "                tmp['predvec'] = ex[j]\n",
    "                tmp['goldvec'] = setlabels[i][j]\n",
    "                tmp['predlabel'] = torch.argmax(ex[j])\n",
    "                tmp['godlabel'] = torch.argmax(setlabels[i][j])\n",
    "                errtmp.append(tmp)\n",
    "        res.append(errtmp)\n",
    "                \n",
    "    return res\n",
    "\n",
    "def check_randacc(setpred, setlabels):\n",
    "    cor = 0\n",
    "    tot = 0\n",
    "    for i in range(0, len(setpred)):\n",
    "        ex = setpred[i]\n",
    "        for j in range(0, len(ex)):\n",
    "            if sum(setlabels[i][j])==0:\n",
    "                continue\n",
    "            tot+=1\n",
    "            if torch.argmax(torch.rand(52).to(device))==torch.argmax(setlabels[i][j]):\n",
    "                cor+=1\n",
    "    return cor/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "93a46a36-28cf-4af4-9612-2ede5c50a173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 14.9318,  -2.7634,  -7.6049,  ..., -33.5248, -21.4982, -21.1939],\n",
       "        [ -4.9516,   7.1504,   3.0023,  ...,  -0.9376, -16.3110, -13.4094],\n",
       "        [  2.4785,  -3.4839,  -4.8681,  ..., -30.1726, -25.3926, -34.3325],\n",
       "        ...,\n",
       "        [ 14.4614,  -4.5659, -18.8923,  ..., -48.2720, -30.0582, -25.5089],\n",
       "        [ 14.4614,  -4.5659, -18.8923,  ..., -48.2720, -30.0582, -25.5089],\n",
       "        [ 14.4614,  -4.5659, -18.8923,  ..., -48.2720, -30.0582, -25.5089]],\n",
       "       device='cuda:2', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latposylabels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "38fc1532-0756-4196-8ae2-edc68d9ccb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8341246590564704\n",
      "0.8334511903559282\n",
      "0.8326767013503047\n",
      "0.8526787217564064\n"
     ]
    }
   ],
   "source": [
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred1 = posbmodel(sents, mod_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred2 = posbmodel(sents, fix_posids(posids), attmasks)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred3 = posbmodel(sents, mod_posids(posids), None)\n",
    "sents, posids = create_inputs(processedgraphs)\n",
    "pred4 = posbmodel(sents, fix_posids(posids), None)\n",
    "\n",
    "            \n",
    "print(check_accuracy(pred1, latposylabels))\n",
    "print(check_accuracy(pred2, latposylabels))\n",
    "print(check_accuracy(pred3, latposylabels))\n",
    "print(check_accuracy(pred4, latposylabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a1bad11-dad2-4acb-9cea-e41acbff9239",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_errs  = identify_errors(pred1, latposylabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fdaf2dd6-62bd-43a0-94dc-cade995c110e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lblist = [l for l in labels.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "684a4e9a-02a7-423f-9dd6-256d2f23566f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4926\n"
     ]
    }
   ],
   "source": [
    "tot = 0\n",
    "for e in errpairs.keys():\n",
    "    tot+=errpairs[e]\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86b263b-05b6-4d6a-a753-fb85c4ac24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "# number of errors per lattice \n",
    "e_len_distr = [len(e) for e in pred_errs]\n",
    "def get_tag_pred_distr(p_errs):\n",
    "    tpdistr = []\n",
    "    tgdistr = []\n",
    "    for perr in p_errs:\n",
    "        for e in perr:\n",
    "            tpdistr.append(float(e['predlabel']))\n",
    "            tgdistr.append(float(e['godlabel']))\n",
    "    return tpdistr, tgdistr\n",
    "# error tag\n",
    "\n",
    "def granular_pred_distr(p_errs):\n",
    "    gpdistr = []\n",
    "    for perr in p_errs:\n",
    "        tmppred = []\n",
    "        tmpgold = []\n",
    "        for e in perr:\n",
    "            tmppred.append(lblist[int(e['predlabel'])])\n",
    "            tmpgold.append(lblist[int(e['godlabel'])])\n",
    "        gpdistr.append(list(zip(tmppred, tmpgold)))\n",
    "    return gpdistr\n",
    "\n",
    "def understand_errpairs (epairdistr):\n",
    "    frequency = collections.Counter(epairdistr)\n",
    "    fdict = dict(frequency)\n",
    "\n",
    "    d = dict(sorted(fdict.items(), key=lambda item: item[1]))\n",
    "    #print(fdict)\n",
    "    for k in d.keys():\n",
    "        print(lblist[int(k[0])], \" \", lblist[int(k[1])], \": \", d[k])\n",
    "    return d\n",
    "        \n",
    "ep_distr, eg_distr = get_tag_pred_distr(pred_errs)\n",
    "errpairs = understand_errpairs(zip(ep_distr, eg_distr))\n",
    "granpd = granular_pred_distr(pred_errs)\n",
    "for i in range(0, len(granpd)):\n",
    "    print(i, \" \", granpd[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52233476-682b-4dfd-b515-730f3c7d171e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "678e8a6d-c0f7-485b-ba58-5cd7f772f4e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 15.2313,  -3.2251,  -6.9445,  ..., -31.4852, -19.2721, -20.7780],\n",
       "        [ -3.4530,   3.3715,   9.0444,  ...,  -8.5703, -12.5707, -13.5763],\n",
       "        [ -5.2397,   0.5385,   2.7538,  ..., -14.1365, -36.7951, -15.4723],\n",
       "        ...,\n",
       "        [ 14.5528,  -4.9714, -18.5249,  ..., -51.4184, -28.4842, -25.7899],\n",
       "        [ 14.5528,  -4.9714, -18.5249,  ..., -51.4184, -28.4842, -25.7899],\n",
       "        [ 14.5528,  -4.9714, -18.5249,  ..., -51.4184, -28.4842, -25.7899]],\n",
       "       device='cuda:2', grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "latposylabels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d54f0945-f622-48a2-a2ef-68e08315f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.1663)\n",
      "tensor(0.7329)\n",
      "tensor(45.7936, device='cuda:2', grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "r1 = torch.rand((6, 500, 52))\n",
    "r2 = torch.rand((6, 500, 52))\n",
    "print(mse(r1, r2))\n",
    "print(loss(r1, r2))\n",
    "print(mse(latposylabels, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "43d3601c-19d2-4b6e-8af8-8fdeeb0c18ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code needed when changing set of gold labels\n",
    "def prepare_dataset(resset):\n",
    "    x = []\n",
    "    y = []\n",
    "    for res in resset:\n",
    "        curinps = []\n",
    "        for r in res:\n",
    "            try:\n",
    "                toktmp = torch.tensor(bert_tok(clean_expanded(r)).input_ids)\n",
    "                #print(toktmp.shape)\n",
    "                if float(toktmp.shape[0])<MAX_LEN:\n",
    "                    toktmp = torch.cat([toktmp, torch.zeros(MAX_LEN-toktmp.shape[0])])\n",
    "                else:\n",
    "                    toktmp = toktmp[:MAX_LEN]\n",
    "                curinps.append(toktmp)\n",
    "            except:\n",
    "                print(\"weird error happened\") \n",
    "        print(len(curinps))\n",
    "        curouts = []\n",
    "        tinp = torch.stack(curinps).long().to(device)\n",
    "        print(tinp.shape)\n",
    "        y.append(posbmodel(tinp))\n",
    "        x.append(tinp)\n",
    "        del tinp\n",
    "        \n",
    "        #print(\"error somewhere\")\n",
    "    return x, y\n",
    "\n",
    "def get_labset_partial(explodeds, startind, amt):\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    dsetx, dsety = prepare_dataset(explodeds[startind:startind+amt])\n",
    "    print(len(dsetx))\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    assert len(dsetx)==amt\n",
    "    latposylabels, tmaps = lattice_pos_goldlabels(dsetx, dsety, sents[startind:startind+amt])\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    del dsetx, dsety\n",
    "    \n",
    "    torch.cuda.empty_cache()\n",
    "    #print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "    return latposylabels, tmaps\n",
    "\n",
    "def get_biglabset(split):\n",
    "    #result = None\n",
    "    #tmaps = []\n",
    "    for i in range(0, int(len(resarrs)/split)):\n",
    "        print(\"SUBSET - \", i)\n",
    "        r, tmap = get_labset_partial(resarrs, i*split, split)\n",
    "        #tmaps = tmaps + tmap\n",
    "        \"\"\"\n",
    "        if result == None:\n",
    "            result = r\n",
    "        else:\n",
    "            result = torch.cat((result, r))\n",
    "        \"\"\"\n",
    "        torch.cuda.empty_cache()\n",
    "        #torch.save(result, './plabels/latreposlabels0.pt')\n",
    "        file = open('./torchsaved/tmapssplit0/tmaps0_'+str(i*split)+'.pkl', 'wb')\n",
    "        # dump information to that file\n",
    "        pickle.dump(tmap, file)\n",
    "\n",
    "        # close the file\n",
    "        file.close()\n",
    "        del r\n",
    "        del tmap\n",
    "        torch.cuda.empty_cache()\n",
    "        print(torch.cuda.memory_allocated(\"cuda:2\"))\n",
    "\n",
    "def debug_newinput(linp, explinps, latout, explouts):\n",
    "    i = 0\n",
    "    tot = 0\n",
    "    while linp[i]>0:\n",
    "        print()\n",
    "        print(bert_tok.decode(linp[i]), \" \" ,bert_tok.decode(explinps[0][i]))\n",
    "        print(explinps[0][i])\n",
    "        lv, li = torch.topk(latout[i], 3)\n",
    "        ev, ei = torch.topk(explouts[6][i], 3)\n",
    "        print(li, \" \", ei)\n",
    "        #if l==e:\n",
    "        #    tot+=1\n",
    "        i+=1\n",
    "    print(tot/i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c1a3a-7dd1-46b9-82a4-c20a28e04f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "result, tmaps = get_biglabset(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0690f609-5f8d-4405-bf85-87aa35ae539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f638fbd8-fb3a-43f7-aa87-b6396c9bde50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# START embedding distance stuff\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from more_itertools import locate\n",
    "\n",
    "def ind_cos_dist (i1, i2, embed):\n",
    "    return 1-cosine(embed[i1].cpu(), embed[i2].cpu())\n",
    "\n",
    "def tok_cos_dist(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in inds1:\n",
    "        for i2 in inds2:\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    #assert l1[ind1]==l2[ind2]\n",
    "    return sims\n",
    "\n",
    "def tok_cos_notbase(embed1, embed2, inps1, inps2, tok):\n",
    "    l1 = list(inps1)\n",
    "    l2 = list(inps2)\n",
    "    \n",
    "    inds1 = find_indices(l1, tok)\n",
    "    inds2 = find_indices(l2, tok)\n",
    "    sims = []\n",
    "    e1 = embed1.cpu()\n",
    "    e2 = embed2.cpu()\n",
    "    for i1 in range(0, len(inps1)):\n",
    "        for i2 in range(0, len(inps2)):\n",
    "            if inps1[i1]==inps2[i2]:\n",
    "                continue\n",
    "            sims.append(1-cosine(e1[i1], e2[i2]))\n",
    "    return sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac78556-8dbb-4eaf-b982-bb2a390df8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def mean(lis):\n",
    "    try:\n",
    "        return sum(lis)/len(lis)\n",
    "    except:\n",
    "        return 0.8\n",
    "\n",
    "def get_ex_distr(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[example][ex_cand])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    for r in norm_inputs[0]:\n",
    "        res.append(mean(tok_cos_dist(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_ex_notbase(example, ex_cand, latembed=None, sents=None):\n",
    "    if latembed == None:\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "    norm_inputs = torch.tensor([bert_tok(clean_expanded(resarrs[ex_cand][0])).input_ids])\n",
    "    #norm_inputs\n",
    "    with torch.no_grad():\n",
    "        norm_out = basebert(input_ids=norm_inputs, return_dict=True, output_hidden_states=True)\n",
    "    normembed = norm_out['last_hidden_state'][0]\n",
    "    res = []\n",
    "    res.append(mean(tok_cos_notbase(latembed, normembed, sents[0], norm_inputs[0], r)))\n",
    "    \n",
    "    return res\n",
    "\n",
    "def get_diff_base(latembed, inp_toks):\n",
    "    diff = []\n",
    "    for i in range(len(inp_toks)):\n",
    "        for j in range(len(inp_toks)):\n",
    "            if inp_toks[i]==inp_toks[j]:\n",
    "                diff.append(ind_cos_dist(i, j, latembed))\n",
    "    return diff\n",
    "\n",
    "def get_lat_distr(example):\n",
    "    result = []\n",
    "    tot = len(resarrs[example])\n",
    "    if tot>100:\n",
    "        tot = 100\n",
    "    for i in range(tot):\n",
    "        print(i)\n",
    "        sents, posids = create_inputs(processedgraphs[example:example+1])\n",
    "        out = latbert(sents, posids)\n",
    "        latembed = out['last_hidden_state'][0]\n",
    "        result.append(mean(get_ex_distr(example, i, latembed, sents)))\n",
    "    print(len(resarrs[example]))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52423a8e-7096-4e79-b40d-a01b63a5a2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents, posids = create_inputs(processedgraphs[0:0+1])\n",
    "out = latbert(sents, posids)\n",
    "latembed = out['last_hidden_state'][0]\n",
    "plt.hist(get_diff_base(latembed, sents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6fc8ef-af43-4a81-8e94-17596d8c40c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "\n",
    "get_ex_notbase(0, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35077c7-cc98-4d8f-8c2a-d60fff83ff72",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(res, bins = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809f08ef-4b96-48bd-a491-7d7f33cb0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2623ec-5921-4682-96ce-011304ff2c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(norm_inputs)\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a39cadb-8ba5-4047-a97e-e0d6d686a937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the relevant modules\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "device = \"cuda:2\"\n",
    "# Loading the pre-trained BERT model\n",
    "###################################\n",
    "# Embeddings will be derived from\n",
    "# the outputs of this model\n",
    "model = BertModel.from_pretrained('bert-base-cased',\n",
    "           output_hidden_states = True,).to(device)\n",
    "# Setting up the tokenizer\n",
    "###################################\n",
    "# This is the same tokenizer that\n",
    "# was used in the model to generate\n",
    "# embeddings to ensure consistency\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787d823f-f601-4918-a88a-a3baa6714c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bert_text_preparation(text, tokenizer):\n",
    "    \"\"\"Preparing the input for BERT\n",
    "    \n",
    "    Takes a string argument and performs\n",
    "    pre-processing like adding special tokens,\n",
    "    tokenization, tokens to ids, and tokens to\n",
    "    segment ids. All tokens are mapped to seg-\n",
    "    ment id = 1.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted\n",
    "        tokenizer (obj): Tokenizer object\n",
    "            to convert text into BERT-re-\n",
    "            adable tokens and ids\n",
    "        \n",
    "    Returns:\n",
    "        list: List of BERT-readable tokens\n",
    "        obj: Torch tensor with token ids\n",
    "        obj: Torch tensor segment ids\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    marked_text = \"[CLS] \" + text + \" [SEP]\"\n",
    "    tokenized_text = tokenizer.tokenize(marked_text)\n",
    "    indexed_tokens = tokenizer.convert_tokens_to_ids(tokenized_text)\n",
    "    segments_ids = [1]*len(indexed_tokens)\n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor = torch.tensor([indexed_tokens]).to(device)\n",
    "    segments_tensors = torch.tensor([segments_ids]).to(device)\n",
    "\n",
    "    return tokenized_text, tokens_tensor, segments_tensors\n",
    "\n",
    "def get_bert_embeddings(tokens_tensor, segments_tensors, model):\n",
    "    \"\"\"Get embeddings from an embedding model\n",
    "    \n",
    "    Args:\n",
    "        tokens_tensor (obj): Torch tensor size [n_tokens]\n",
    "            with token ids for each token in text\n",
    "        segments_tensors (obj): Torch tensor size [n_tokens]\n",
    "            with segment ids for each token in text\n",
    "        model (obj): Embedding model to generate embeddings\n",
    "            from token and segment ids\n",
    "    \n",
    "    Returns:\n",
    "        list: List of list of floats of size\n",
    "            [n_tokens, n_embedding_dimensions]\n",
    "            containing embeddings for each token\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # Gradient calculation id disabled\n",
    "    # Model is in inference mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(tokens_tensor, segments_tensors)\n",
    "        # Removing the first hidden state\n",
    "        # The first state is the input state\n",
    "        hidden_states = outputs[2][1:]\n",
    "\n",
    "    # Getting embeddings from the final BERT layer\n",
    "    token_embeddings = hidden_states[-1]\n",
    "    # Collapsing the tensor into 1-dimension\n",
    "    token_embeddings = torch.squeeze(token_embeddings, dim=0)\n",
    "    # Converting torchtensors to lists\n",
    "    list_token_embeddings = [token_embed.tolist() for token_embed in token_embeddings]\n",
    "\n",
    "    return list_token_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f143582a-452b-484e-a39c-54f82d966a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_word_embeddings = []\n",
    "\n",
    "for text in examples:\n",
    "    tokenized_text, tokens_tensor, segments_tensors = bert_text_preparation(text, tokenizer)\n",
    "    list_token_embeddings = get_bert_embeddings(tokens_tensor, segments_tensors, model)\n",
    "    \n",
    "    # Find the position 'bank' in list of tokens\n",
    "    word_index = tokenized_text.index('Obama')\n",
    "    # Get the embedding for bank\n",
    "    word_embedding = list_token_embeddings[word_index]\n",
    "\n",
    "    target_word_embeddings.append(word_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15771d-5745-4282-88c4-66e36d66121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(target_word_embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1457d6-fd88-4834-8fb9-c23619ebc26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model = LinearLatticeBert(52)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06803ea6-c89f-4f0a-a2c1-73abf871030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = torch.tensor(sents).to(device)\n",
    "posids = torch.tensor(posids).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649ba20-455f-4e41-8e4b-a741ed427306",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bert_model(sents, posids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a10775b-6e48-4eb4-95ee-c02cdbe051df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lhs = out['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd13fb0-e094-4e25-bca7-19398920a763",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(sents[0])[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97a751a-d65b-4a89-a67d-cadcc18698a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_cos_dist(13, 14, lhs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4519fa09-7daf-463e-9564-57496b5cd4a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "inptest = bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164ad4dd-b430-49d4-91de-295d6f3915c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_bert = AutoModel.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1666146d-6818-4633-88d7-e5254550bafa",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalout = normal_bert(torch.tensor([inptest.input_ids]),return_dict=True, output_hidden_states=True)\n",
    "normalhs = normalout['last_hidden_state'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82992cf-1849-428b-82fa-f6ebe5cc10bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tok(clean_expanded(resarrs[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e39a5e1-b493-4a6f-bf58-aad62b36e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_cos_dist(lhs,normalhs,  1109)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
