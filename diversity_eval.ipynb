{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52988157-efd6-4541-b558-f5cb0e89aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-31 12:10:53.872873: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-31 12:10:53.872897: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# notebook to get numbers for, and plot for diversity trade-off\n",
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from encode_utils.new_mask_utils import randomsingle, useall\n",
    "from encode_utils.eval_utils import all_lattice_multi, mean, all_unnoun_multi, get_hyp_sco\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e6533f47-3337-48ec-bae2-bc8887cdbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up information for set\n",
    "col = {\n",
    "    \"noun_xsum\": [\"nounsum_reversed/\", \"nounxsumlargeexplodev2.csv\"],\n",
    "    \"noun_fren\": [\"frtest_reversed/\", \"nounlargeexplodev1.csv\"],\n",
    "    \"mt_fren\": [\"frtest_reversed/\", \"frenchlargeexplodev1.csv\"],\n",
    "    \"mt_ende\": [\"detest_reversed/\", \"germanlargeexplodev1.csv\"],\n",
    "    \"mt_enru\": [\"rutest_reversed/\", \"russianlargeexplodev1.csv\"],\n",
    "    \"mt_fren_b12\": ['reversed_mtfren_beam12/', 'mtfrenbeam12v2.csv'],\n",
    "    \"mt_fren_b50\": ['reversed_mtfren_beam50/', 'mtfrenbeam50v2.csv'],\n",
    "    \"noun_xsum_b12\": ['reversed_xsum_beam12/', 'nounxsumbeam12v2.csv'],\n",
    "    \"noun_xsum_b50\": ['reversed_xsum_beam50/', 'nounxsumbeam50v2.csv'],\n",
    "}\n",
    "curcol = \"noun_xsum_b12\"\n",
    "gsuffix = col[curcol][0]\n",
    "expl_fname = col[curcol][1]\n",
    "base = \"outputs/graph_pickles/\"+gsuffix\n",
    "goldmetric = \"utnoun\"\n",
    "explode_df = pd.read_csv(\"outputs/score_csvs/\"+expl_fname)\n",
    "#TODO switch back for french-english\n",
    "if \"fren\" in curcol:\n",
    "    SETLEN = len(os.listdir(base))\n",
    "else:\n",
    "    SETLEN = int(len(os.listdir(base))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8ba53b-fba8-4fae-ae6b-c1633032f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETLEN = len(os.listdir(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8a9d10-f81a-41fd-9b46-18c364a476cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# use noun model\n",
    "if \"noun\" in expl_fname:\n",
    "    encodemod = get_effrerank_model(\"noun\")\n",
    "# use mt model (causal)\n",
    "else:\n",
    "    encodemod = get_effrerank_model(\"comstyle\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aaba354-6aaa-441f-a45d-a383158f9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'setlen':int(SETLEN),\n",
    "    'tok':xlm_tok, \n",
    "    'dev':device,\n",
    "    'model':encodemod,\n",
    "    'explode_df':explode_df,\n",
    "    'base':base,\n",
    "    'goldmetric':goldmetric,\n",
    "    'device':device, \n",
    "    'efficient':False,\n",
    "    'noregen':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c9f17f-63ec-4dcb-92e5-14746ada89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "#DIVWEIGHT = 1\n",
    "#doadd = True\n",
    "DIVWEIGHT = 1\n",
    "doadd = True\n",
    "    \n",
    "def tokenprobdiverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def tokendiverse (node, used, norm):\n",
    "    if hasattr(node, \"score\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def nodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            if doadd:\n",
    "                return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def extranodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*used.count(node)\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "94f670d3-31b2-4a72-8e7b-47830d4add9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrefs = list(explode_df['ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38691c25-3cf8-4c34-9caf-0393b1ea5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRUNS = 10\n",
    "\n",
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct, metric):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    if g['ref'] not in lrefs:\n",
    "        return None, None, None\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_comstyle(g, encodemod, scofunct, metric, {'afunc':randomsingle}, False, NRUNS)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f61c2350-3fd9-4ec7-968a-b9d106d92de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques\n",
    "\n",
    "def count_unique_ngrams(sentences, n):\n",
    "    return len(cand_unique_ngrams(sentences, xlm_tok, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "92d1a73c-5579-43eb-a774-2683abfe063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_unique_ngrams(edf, n):\n",
    "    uns = edf['ref'].unique()\n",
    "    ndist = []\n",
    "    for u in uns:\n",
    "        segment = edf[edf['ref']==u]\n",
    "        \n",
    "        if len(segment)>0:\n",
    "            ndist.append(count_unique_ngrams(list(segment['hyp']), n))\n",
    "    return ndist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36411396-acd6-4b54-b2cc-cc42244310d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66.35666666666667\n"
     ]
    }
   ],
   "source": [
    "ndist = base_unique_ngrams(explode_df, 4)\n",
    "print(sum(ndist)/len(ndist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "660b6809-4c3d-46f5-8725-67a4b2a22b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show -> \n",
    "\n",
    "# Plot 1\n",
    "# - include random baseline for selecting in terms of quality\n",
    "# - go from left to right (number of candidates generated, and show score of each)\n",
    "\n",
    "# Plot 2 \n",
    "# - show beam search 50 baseline\n",
    "# - go from left to right, show n-gram diversity metric for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a89921c6-e753-4ba2-9b91-ce2301763555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind_diverse(ind, metric):\n",
    "    result = test_graph_ind(ind, base, tokendiverse, metric)\n",
    "    if result[0] is None:\n",
    "        return None, None, None\n",
    "    # get number of unique n-grams added with more generation\n",
    "    cgrams = []\n",
    "    for i in range(1, len(result[2])+1):\n",
    "        cgrams.append(count_unique_ngrams(result[2][:i], 4))\n",
    "\n",
    "    if \"noun\" in metric:\n",
    "        source = \"noun\"\n",
    "    else:\n",
    "        source = result[0]\n",
    "    # get hypothesis scores\n",
    "    cscos = []\n",
    "    # TODO set this up with batching\n",
    "    for c in result[2]:\n",
    "        cscos.append(float(torch.sum(get_hyp_sco(c[4:], source, args))))\n",
    "    return cscos, cgrams, result\n",
    "\n",
    "def get_diverse_distr(metric, total):\n",
    "    allcs, allcg = [0]*NRUNS, [0]*NRUNS\n",
    "    tvals = 0\n",
    "    for i in range(total):\n",
    "        cstmp, cgtmp, r = get_ind_diverse(i, metric)\n",
    "        if cstmp is None:\n",
    "            #print(\"skip\")\n",
    "            continue\n",
    "        for j in range(NRUNS):\n",
    "            allcs[j] += cstmp[j]\n",
    "            allcg[j] += cgtmp[j]\n",
    "        tvals+=1\n",
    "        print(tvals, \" \", i)\n",
    "    return [c/tvals for c in allcs], [g/tvals for g in allcg]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e622787c-94dd-4e1c-affe-ff929d9756a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448   870\n",
      "449   872\n",
      "450   873\n",
      "451   878\n",
      "452   883\n",
      "453   884\n",
      "454   886\n",
      "455   887\n",
      "456   893\n",
      "457   896\n",
      "458   899\n",
      "459   900\n",
      "460   902\n",
      "461   903\n",
      "462   906\n",
      "463   907\n",
      "464   909\n",
      "465   910\n",
      "466   911\n",
      "467   912\n",
      "468   913\n",
      "469   915\n",
      "470   917\n",
      "471   919\n",
      "472   920\n",
      "473   921\n",
      "474   924\n",
      "475   926\n",
      "476   927\n",
      "477   929\n",
      "478   930\n",
      "479   932\n",
      "480   933\n",
      "481   936\n",
      "482   938\n",
      "483   939\n",
      "484   941\n",
      "485   942\n",
      "486   943\n",
      "487   944\n",
      "488   946\n",
      "489   948\n",
      "490   950\n",
      "491   952\n",
      "492   953\n",
      "493   954\n",
      "494   956\n",
      "495   958\n",
      "496   959\n",
      "497   962\n",
      "498   963\n",
      "499   964\n",
      "500   967\n",
      "501   968\n",
      "502   970\n",
      "503   972\n",
      "504   976\n",
      "505   977\n",
      "506   978\n",
      "507   980\n",
      "508   982\n",
      "509   983\n",
      "510   985\n",
      "511   993\n",
      "512   997\n",
      "513   1000\n",
      "514   1001\n",
      "515   1002\n",
      "516   1004\n",
      "517   1005\n",
      "518   1006\n",
      "519   1007\n",
      "520   1008\n",
      "521   1009\n",
      "522   1011\n",
      "523   1015\n",
      "524   1016\n",
      "525   1018\n",
      "526   1019\n",
      "527   1020\n",
      "528   1022\n",
      "529   1023\n",
      "530   1024\n",
      "531   1025\n",
      "532   1026\n",
      "533   1027\n",
      "534   1028\n",
      "535   1030\n",
      "536   1031\n",
      "537   1032\n",
      "538   1034\n",
      "539   1035\n",
      "540   1037\n",
      "541   1041\n",
      "542   1043\n",
      "543   1044\n",
      "544   1046\n",
      "545   1047\n",
      "546   1049\n",
      "547   1050\n",
      "548   1055\n",
      "549   1058\n",
      "550   1059\n",
      "551   1064\n",
      "552   1065\n",
      "553   1066\n",
      "554   1076\n",
      "555   1079\n",
      "556   1080\n",
      "557   1087\n",
      "558   1091\n",
      "559   1092\n",
      "560   1097\n",
      "561   1098\n",
      "562   1099\n",
      "563   1100\n",
      "564   1102\n",
      "565   1103\n",
      "566   1105\n",
      "567   1108\n",
      "568   1109\n",
      "569   1110\n",
      "570   1112\n",
      "571   1114\n",
      "572   1119\n",
      "573   1120\n",
      "574   1122\n",
      "575   1123\n",
      "576   1124\n",
      "577   1126\n",
      "578   1127\n",
      "579   1130\n",
      "580   1131\n",
      "581   1132\n",
      "582   1135\n",
      "583   1136\n",
      "584   1140\n",
      "585   1143\n",
      "586   1144\n",
      "587   1145\n",
      "588   1146\n",
      "589   1147\n",
      "590   1148\n",
      "591   1150\n",
      "592   1155\n",
      "593   1156\n",
      "594   1157\n",
      "595   1158\n",
      "596   1161\n",
      "597   1162\n",
      "598   1163\n",
      "599   1166\n",
      "600   1167\n"
     ]
    }
   ],
   "source": [
    "overall = get_diverse_distr(\"utnoun\", SETLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "957e1d41-5fe9-4aeb-9c71-896bdb3c0973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.0463203240931034,\n",
       "  0.9083600198229154,\n",
       "  0.8470527469366789,\n",
       "  0.8217564211289088,\n",
       "  0.8079156806816657,\n",
       "  0.7796099009364843,\n",
       "  0.7803336255252361,\n",
       "  0.7687843435506025,\n",
       "  0.7727742357303699,\n",
       "  0.7488706836601099],\n",
       " [34.235,\n",
       "  53.776666666666664,\n",
       "  68.89333333333333,\n",
       "  80.34,\n",
       "  89.13166666666666,\n",
       "  95.64,\n",
       "  101.235,\n",
       "  105.74,\n",
       "  109.55333333333333,\n",
       "  112.61])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a5f5026d-7d35-4b38-8701-a0157cbca290",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = ([1.0463203240931034,\n",
    "  0.9083600198229154,\n",
    "  0.8470527469366789,\n",
    "  0.8217564211289088,\n",
    "  0.8079156806816657,\n",
    "  0.7796099009364843,\n",
    "  0.7803336255252361,\n",
    "  0.7687843435506025,\n",
    "  0.7727742357303699,\n",
    "  0.7488706836601099],\n",
    " [34.235,\n",
    "  53.776666666666664,\n",
    "  68.89333333333333,\n",
    "  80.34,\n",
    "  89.13166666666666,\n",
    "  95.64,\n",
    "  101.235,\n",
    "  105.74,\n",
    "  109.55333333333333,\n",
    "  112.61])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c23511fa-c431-4d8d-8b0d-588ca85c44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f7591144400>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(NRUNS)), y=overall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ff7bf4f-0e5b-490b-ac7c-712f91e74bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f757c378190>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(NRUNS)), y=overall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2faab66-1eb9-44f5-83c6-e9fa7b0034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc3eb7-b182-409f-9d04-08ce951b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741494c2-e102-4b90-9b52-faa5bf044d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_graph_ind(0, base, tokendiverse, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0215fb4-bae7-4346-a9be-23998cfbfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgrams = []\n",
    "for i in range(1, len(result[2])+1):\n",
    "    cgrams.append(count_unique_ngrams(result[2][:i], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1073ff6-a924-4941-a1a0-f749d2106aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 68, 89, 106, 106, 125, 132, 137, 137, 137]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c5443d-87b3-4cc3-88f6-46725577d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> A senior army officer in the Democratic Republic of Congo has been accused by at least five women of ordering a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Day.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Eve.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of more than 50 women and girls in a single day.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been arrested on suspicion of raping dozens of women and girls in a single attack.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been accused of carrying out a mass rape in the north-eastern province of Kasai.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been accused of being behind a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Eve.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27f9f3-d775-497e-9272-120aeedc75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 100 examples, generate diverse options (up to 20), score each of them\n",
    "SET = 100\n",
    "i = 0\n",
    "while SET>0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8109df-b81f-4717-a3b2-8a29de29523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8467394-8aa5-408f-ac52-ee60b5611b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/graph_pickles/exploded_mtfren_beam12/0\", \"rb\") as file:\n",
    "    res = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2675fcd5-d945-409d-b93c-654351f05ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A slow new year for the world economy',\n",
       " 'A new slow year for the world economy',\n",
       " 'A slow new year for the global economy',\n",
       " 'A new slow year for the global economy',\n",
       " 'A Slow New Year for the World Economy',\n",
       " 'A New Slow Year for the World Economy',\n",
       " 'A Slow New Year for the Global Economy',\n",
       " 'A New Slow Year for the Global Economy',\n",
       " 'A slow new year for the world economy.',\n",
       " 'A slow new year for the global economy.',\n",
       " 'A new slow year for the world economy.',\n",
       " 'A new slow year for the global economy.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a133b4-2d37-4e3c-9efe-71660394af92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_graph_ind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_ind_diverse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutnoun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_ind_diverse\u001b[0;34m(ind, metric)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ind_diverse\u001b[39m(ind, metric):\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_graph_ind\u001b[49m(\u001b[38;5;241m0\u001b[39m, base, tokendiverse, metric)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# get number of unique n-grams added with more generation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     cgrams \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_graph_ind' is not defined"
     ]
    }
   ],
   "source": [
    "res = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550ab83f-7047-4b5f-8ce9-7f300c8c8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = [r[4:] for r in res[2][2]]\n",
    "scos = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2228117-b955-4e9b-ba8c-cec715e44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45810b0a-ffc3-4c32-906c-a02eec7fd0e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[1, 2, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[1, 2, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (3)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abdab085-3e02-4414-9ec5-e75b0a4e39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put elsewhere - make batched version of get_hyp_sco (TODO also do dataloader setup or smth)\n",
    "def causalmask (a, dev):\n",
    "    masksdef = torch.zeros((a.shape[0], a.shape[1],a.shape[1]), device=dev)\n",
    "    for i in range(len(a)):\n",
    "        lim = int(torch.sum(a[i]))\n",
    "        masksdef[i, :lim, :lim] = torch.tril(torch.ones((lim, lim)))\n",
    "    return masksdef\n",
    "\n",
    "def batch_hyp_sco(srcs, hyps, metric):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "    \n",
    "    out_toks = tok(hyps, return_tensors='pt', padding=True, truncation=True).to(dev)\n",
    "    out_tokens = out_toks.input_ids\n",
    "    hypmask = causalmask(out_toks.attention_mask, device)\n",
    "    \n",
    "    positionids = None\n",
    "    toked_inp = tok(srcs, padding=True, truncation=True, return_tensors=\"pt\").to(dev)\n",
    "    \n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, out_tokens, positionids, \\\n",
    "        hypmask)\n",
    "    \n",
    "    return torch.sum(predout['score'], 1)#, toked_inp, out_tokens, positionids, hypmask\n",
    "    \n",
    "# get token level scores from model, given hypothesis and input source\n",
    "def get_hyp_sco(inphyp, inpsrc, args):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "\n",
    "    # calculate inputs\n",
    "    tokens = tok(inphyp, return_tensors='pt', truncation=True).to(dev)\n",
    "    tokens = tokens.input_ids\n",
    "    positionids = None\n",
    "    toked_inp = tok([inpsrc], return_tensors=\"pt\").to(dev)\n",
    "    # get causal mask\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(dev)\n",
    "    # run through model\n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    return torch.sum(predout['score'])#, toked_inp, tokens, positionids, tmpmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4348518d-e7c5-4e4f-8775-96ee787f9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2, 3, 1)\n",
    "b = torch.ones(2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f34c1eb-2f3c-46e3-84ca-deee68e33d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0af82a9-0d33-4fab-9fb8-789ab0f0034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btest = batch_hyp_sco([\"noun\"]*10, cands, args)\n",
    "htest = get_hyp_sco(cands[3], \"noun\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2bcd0b-1425-4de7-9a52-3f29d5e97c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22332ce9-9a1d-4aad-b192-68640e8971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = explode_df.loc[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "558da394-3b6f-4432-9731-2dd96084d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05416083335876465\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "batch_hyp_sco([\"noun\"]*len(tmp), list(tmp['hyp']), args)\n",
    "tot = time.time()-s\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227a5c27-6d97-411b-bdd6-27c56494bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                     0\n",
       "src            Comme pour tout compromis, les parties prenant...\n",
       "ref            As with any compromise, the contending parties...\n",
       "hyp            As with any compromise, stakeholders would hav...\n",
       "dcqeold                                                  0.67299\n",
       "comet                                                   0.776076\n",
       "cqe                                                     0.526303\n",
       "posthoc                                                  0.39046\n",
       "dupcqeprev1                                              0.64051\n",
       "dupcqe                                                  0.640568\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tind = tmp.loc[0]\n",
    "tind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d616cce8-fa84-468a-86cd-e403063e9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comme pour tout compromis, les parties prenantes auraient à la fois à perdre et à gagner dans cet arrangement. '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tind['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61b7887-395a-48c9-bfff-8f1e10bb99c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6200, device='cuda:2', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hyp_sco(tind['hyp'], tind['src'], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d24fed-27f7-477d-9a4c-6e24c2c14f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6200],\n",
       "        [0.6123],\n",
       "        [0.5721],\n",
       "        [0.6260],\n",
       "        [0.6966],\n",
       "        [0.6428],\n",
       "        [0.5876],\n",
       "        [0.7055],\n",
       "        [0.6402],\n",
       "        [0.6341],\n",
       "        [0.5645],\n",
       "        [0.7112],\n",
       "        [0.6950],\n",
       "        [0.6687],\n",
       "        [0.6928],\n",
       "        [0.6689],\n",
       "        [0.6937],\n",
       "        [0.6920],\n",
       "        [0.6818],\n",
       "        [0.6978],\n",
       "        [0.6919],\n",
       "        [0.6104],\n",
       "        [0.6473],\n",
       "        [0.6588],\n",
       "        [0.8014],\n",
       "        [0.7982],\n",
       "        [0.7970],\n",
       "        [0.7946],\n",
       "        [0.7982],\n",
       "        [0.7975],\n",
       "        [0.7970],\n",
       "        [0.8056],\n",
       "        [0.8075]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_hyp_sco(list(tmp['src']), list(tmp['hyp']), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb50fac-0eba-4535-b7de-9603cdb66b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3034],\n",
       "        [1.1236],\n",
       "        [1.2539],\n",
       "        [1.3034],\n",
       "        [0.9848],\n",
       "        [0.9704],\n",
       "        [0.8752],\n",
       "        [1.2966],\n",
       "        [0.8793],\n",
       "        [1.3001]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa212be-14d8-4c84-b861-934f78322265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3034, device='cuda:2', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7f1ff06-a3ef-4189-ac24-b89bfd2d6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpstmp = btest[1].input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d8c1962-2723-409e-8e39-3b4e12e0ee97",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minpstmp\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpstmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "inpstmp/(torch.max(inpstmp, 1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6011385-1b23-4a7c-a871-00c6cadf2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2]], device='cuda:2')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpstmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34932db-97e9-4b02-b7c1-5b057fe225e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2586, 1.3145, 1.6432, 1.7925, 1.4084, 1.3145, 1.8486, 1.6901, 1.3145,\n",
       "         1.8486],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.7550, 0.7885, 0.9856, 1.0752, 0.8448, 0.7885, 1.1088, 1.0138, 0.7885,\n",
       "         1.1088],\n",
       "        [0.6813, 0.7116, 0.8895, 0.9704, 0.7624, 0.7116, 1.0007, 0.9149, 0.7116,\n",
       "         1.0007],\n",
       "        [1.1618, 1.2134, 1.5167, 1.6546, 1.3001, 1.2134, 1.7063, 1.5601, 1.2134,\n",
       "         1.7063],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.5986, 0.6253, 0.7816, 0.8526, 0.6699, 0.6253, 0.8793, 0.8039, 0.6253,\n",
       "         0.8793],\n",
       "        [0.6517, 0.6807, 0.8509, 0.9282, 0.7293, 0.6807, 0.9572, 0.8752, 0.6807,\n",
       "         0.9572],\n",
       "        [1.2479, 1.3034, 1.6292, 1.7773, 1.3965, 1.3034, 1.8329, 1.6758, 1.3034,\n",
       "         1.8329],\n",
       "        [0.5926, 0.6189, 0.7737, 0.8440, 0.6632, 0.6189, 0.8704, 0.7958, 0.6189,\n",
       "         0.8704]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f77f316-816b-4fe5-963b-2336d2004c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:2')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6d1e9-c17b-4aed-b3e9-218e3be4343d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
