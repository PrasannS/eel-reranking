{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52988157-efd6-4541-b558-f5cb0e89aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-30 07:12:58.537439: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-30 07:12:58.537468: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# notebook to get numbers for, and plot for diversity trade-off\n",
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from encode_utils.new_mask_utils import randomsingle, useall\n",
    "from encode_utils.eval_utils import all_lattice_multi, mean, all_unnoun_multi, get_hyp_sco\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6533f47-3337-48ec-bae2-bc8887cdbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up information for set\n",
    "col = {\n",
    "    \"noun_xsum\": [\"nounsum_reversed/\", \"nounxsumlargeexplodev2.csv\"],\n",
    "    \"noun_fren\": [\"frtest_reversed/\", \"nounlargeexplodev1.csv\"],\n",
    "    \"mt_fren\": [\"frtest_reversed/\", \"frenchlargeexplodev1.csv\"],\n",
    "    \"mt_ende\": [\"detest_reversed/\", \"germanlargeexplodev1.csv\"],\n",
    "    \"mt_enru\": [\"rutest_reversed/\", \"russianlargeexplodev1.csv\"],\n",
    "    \"mt_fren_b12\": ['reversed_mtfren_beam12/', 'mtfrenbeam12v2.csv'],\n",
    "    \"mt_fren_b50\": ['reversed_mtfren_beam50/', 'mtfrenbeam50v2.csv'],\n",
    "    \"noun_xsum_b12\": ['reversed_xsum_beam12/', 'nounxsumbeam12v2.csv'],\n",
    "    \"noun_xsum_b50\": ['reversed_xsum_beam50/', 'nounxsumbeam50v2.csv'],\n",
    "}\n",
    "curcol = \"mt_fren_b12\"\n",
    "gsuffix = col[curcol][0]\n",
    "expl_fname = col[curcol][1]\n",
    "base = \"outputs/graph_pickles/\"+gsuffix\n",
    "goldmetric = \"dupcqe\"\n",
    "explode_df = pd.read_csv(\"outputs/score_csvs/\"+expl_fname)\n",
    "#TODO switch back for french-english\n",
    "if \"fren\" in curcol:\n",
    "    SETLEN = len(os.listdir(base))\n",
    "else:\n",
    "    SETLEN = int(len(os.listdir(base))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3e7db4d-873c-4697-8948-34a58a4896c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>hyp</th>\n",
       "      <th>dcqeold</th>\n",
       "      <th>comet</th>\n",
       "      <th>cqe</th>\n",
       "      <th>posthoc</th>\n",
       "      <th>dupcqeprev1</th>\n",
       "      <th>dupcqe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would hav...</td>\n",
       "      <td>0.672990</td>\n",
       "      <td>0.776076</td>\n",
       "      <td>0.526303</td>\n",
       "      <td>0.390460</td>\n",
       "      <td>0.640510</td>\n",
       "      <td>0.640568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would hav...</td>\n",
       "      <td>0.664692</td>\n",
       "      <td>0.766729</td>\n",
       "      <td>0.548467</td>\n",
       "      <td>0.393152</td>\n",
       "      <td>0.635732</td>\n",
       "      <td>0.635744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would hav...</td>\n",
       "      <td>0.636959</td>\n",
       "      <td>0.759802</td>\n",
       "      <td>0.545454</td>\n",
       "      <td>0.405204</td>\n",
       "      <td>0.610568</td>\n",
       "      <td>0.610579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, the stakeholders would...</td>\n",
       "      <td>0.667578</td>\n",
       "      <td>0.771617</td>\n",
       "      <td>0.517116</td>\n",
       "      <td>0.406245</td>\n",
       "      <td>0.643053</td>\n",
       "      <td>0.643061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would bot...</td>\n",
       "      <td>0.720887</td>\n",
       "      <td>0.795047</td>\n",
       "      <td>0.398527</td>\n",
       "      <td>0.419682</td>\n",
       "      <td>0.700219</td>\n",
       "      <td>0.700228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, the stakeholders would...</td>\n",
       "      <td>0.691595</td>\n",
       "      <td>0.778509</td>\n",
       "      <td>0.498138</td>\n",
       "      <td>0.411911</td>\n",
       "      <td>0.663014</td>\n",
       "      <td>0.663021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, the stakeholders would...</td>\n",
       "      <td>0.640385</td>\n",
       "      <td>0.761480</td>\n",
       "      <td>0.510370</td>\n",
       "      <td>0.414320</td>\n",
       "      <td>0.619864</td>\n",
       "      <td>0.619871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would bot...</td>\n",
       "      <td>0.715924</td>\n",
       "      <td>0.801589</td>\n",
       "      <td>0.427046</td>\n",
       "      <td>0.425352</td>\n",
       "      <td>0.700422</td>\n",
       "      <td>0.700460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would hav...</td>\n",
       "      <td>0.686557</td>\n",
       "      <td>0.801615</td>\n",
       "      <td>0.481410</td>\n",
       "      <td>0.426145</td>\n",
       "      <td>0.656755</td>\n",
       "      <td>0.656579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would hav...</td>\n",
       "      <td>0.677211</td>\n",
       "      <td>0.804226</td>\n",
       "      <td>0.498468</td>\n",
       "      <td>0.429284</td>\n",
       "      <td>0.652845</td>\n",
       "      <td>0.652715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, stakeholders would hav...</td>\n",
       "      <td>0.643357</td>\n",
       "      <td>0.756336</td>\n",
       "      <td>0.514181</td>\n",
       "      <td>0.429024</td>\n",
       "      <td>0.608002</td>\n",
       "      <td>0.607864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Comme pour tout compromis, les parties prenant...</td>\n",
       "      <td>As with any compromise, the contending parties...</td>\n",
       "      <td>As with any compromise, there would be both lo...</td>\n",
       "      <td>0.744644</td>\n",
       "      <td>0.745927</td>\n",
       "      <td>0.508022</td>\n",
       "      <td>0.427095</td>\n",
       "      <td>0.727786</td>\n",
       "      <td>0.727687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"big three\" are increasingly pursuin...</td>\n",
       "      <td>0.687743</td>\n",
       "      <td>0.819861</td>\n",
       "      <td>0.448231</td>\n",
       "      <td>0.338663</td>\n",
       "      <td>0.673443</td>\n",
       "      <td>0.673552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"big three\" are increasingly pursuin...</td>\n",
       "      <td>0.668884</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.460306</td>\n",
       "      <td>0.337319</td>\n",
       "      <td>0.649865</td>\n",
       "      <td>0.649989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"Big Three\" are increasingly pursuin...</td>\n",
       "      <td>0.689769</td>\n",
       "      <td>0.807715</td>\n",
       "      <td>0.445308</td>\n",
       "      <td>0.345398</td>\n",
       "      <td>0.680725</td>\n",
       "      <td>0.680743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"Big Three\" are increasingly pursuin...</td>\n",
       "      <td>0.672723</td>\n",
       "      <td>0.791984</td>\n",
       "      <td>0.457578</td>\n",
       "      <td>0.343199</td>\n",
       "      <td>0.659764</td>\n",
       "      <td>0.659786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"big three\" are increasingly pursuin...</td>\n",
       "      <td>0.679331</td>\n",
       "      <td>0.810885</td>\n",
       "      <td>0.428179</td>\n",
       "      <td>0.344295</td>\n",
       "      <td>0.664017</td>\n",
       "      <td>0.664106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"big three\" increasingly pursue thei...</td>\n",
       "      <td>0.691249</td>\n",
       "      <td>0.821834</td>\n",
       "      <td>0.424395</td>\n",
       "      <td>0.351748</td>\n",
       "      <td>0.674435</td>\n",
       "      <td>0.674433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"big three\" increasingly pursue thei...</td>\n",
       "      <td>0.664603</td>\n",
       "      <td>0.812127</td>\n",
       "      <td>0.380931</td>\n",
       "      <td>0.346658</td>\n",
       "      <td>0.648280</td>\n",
       "      <td>0.648280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"big three\" are increasingly pursuin...</td>\n",
       "      <td>0.696184</td>\n",
       "      <td>0.825174</td>\n",
       "      <td>0.469667</td>\n",
       "      <td>0.351585</td>\n",
       "      <td>0.681297</td>\n",
       "      <td>0.681298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>Pendant que les « trois grands » poursuivent d...</td>\n",
       "      <td>As the “big three” increasingly pursue their o...</td>\n",
       "      <td>While the \"Big Three\" are increasingly pursuin...</td>\n",
       "      <td>0.682615</td>\n",
       "      <td>0.799408</td>\n",
       "      <td>0.430417</td>\n",
       "      <td>0.350184</td>\n",
       "      <td>0.672932</td>\n",
       "      <td>0.672997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                                src  \\\n",
       "0            0  Comme pour tout compromis, les parties prenant...   \n",
       "1            1  Comme pour tout compromis, les parties prenant...   \n",
       "2            2  Comme pour tout compromis, les parties prenant...   \n",
       "3            3  Comme pour tout compromis, les parties prenant...   \n",
       "4            4  Comme pour tout compromis, les parties prenant...   \n",
       "5            5  Comme pour tout compromis, les parties prenant...   \n",
       "6            6  Comme pour tout compromis, les parties prenant...   \n",
       "7            7  Comme pour tout compromis, les parties prenant...   \n",
       "8            8  Comme pour tout compromis, les parties prenant...   \n",
       "9            9  Comme pour tout compromis, les parties prenant...   \n",
       "10          10  Comme pour tout compromis, les parties prenant...   \n",
       "11          11  Comme pour tout compromis, les parties prenant...   \n",
       "12          12  Pendant que les « trois grands » poursuivent d...   \n",
       "13          13  Pendant que les « trois grands » poursuivent d...   \n",
       "14          14  Pendant que les « trois grands » poursuivent d...   \n",
       "15          15  Pendant que les « trois grands » poursuivent d...   \n",
       "16          16  Pendant que les « trois grands » poursuivent d...   \n",
       "17          17  Pendant que les « trois grands » poursuivent d...   \n",
       "18          18  Pendant que les « trois grands » poursuivent d...   \n",
       "19          19  Pendant que les « trois grands » poursuivent d...   \n",
       "20          20  Pendant que les « trois grands » poursuivent d...   \n",
       "\n",
       "                                                  ref  \\\n",
       "0   As with any compromise, the contending parties...   \n",
       "1   As with any compromise, the contending parties...   \n",
       "2   As with any compromise, the contending parties...   \n",
       "3   As with any compromise, the contending parties...   \n",
       "4   As with any compromise, the contending parties...   \n",
       "5   As with any compromise, the contending parties...   \n",
       "6   As with any compromise, the contending parties...   \n",
       "7   As with any compromise, the contending parties...   \n",
       "8   As with any compromise, the contending parties...   \n",
       "9   As with any compromise, the contending parties...   \n",
       "10  As with any compromise, the contending parties...   \n",
       "11  As with any compromise, the contending parties...   \n",
       "12  As the “big three” increasingly pursue their o...   \n",
       "13  As the “big three” increasingly pursue their o...   \n",
       "14  As the “big three” increasingly pursue their o...   \n",
       "15  As the “big three” increasingly pursue their o...   \n",
       "16  As the “big three” increasingly pursue their o...   \n",
       "17  As the “big three” increasingly pursue their o...   \n",
       "18  As the “big three” increasingly pursue their o...   \n",
       "19  As the “big three” increasingly pursue their o...   \n",
       "20  As the “big three” increasingly pursue their o...   \n",
       "\n",
       "                                                  hyp   dcqeold     comet  \\\n",
       "0   As with any compromise, stakeholders would hav...  0.672990  0.776076   \n",
       "1   As with any compromise, stakeholders would hav...  0.664692  0.766729   \n",
       "2   As with any compromise, stakeholders would hav...  0.636959  0.759802   \n",
       "3   As with any compromise, the stakeholders would...  0.667578  0.771617   \n",
       "4   As with any compromise, stakeholders would bot...  0.720887  0.795047   \n",
       "5   As with any compromise, the stakeholders would...  0.691595  0.778509   \n",
       "6   As with any compromise, the stakeholders would...  0.640385  0.761480   \n",
       "7   As with any compromise, stakeholders would bot...  0.715924  0.801589   \n",
       "8   As with any compromise, stakeholders would hav...  0.686557  0.801615   \n",
       "9   As with any compromise, stakeholders would hav...  0.677211  0.804226   \n",
       "10  As with any compromise, stakeholders would hav...  0.643357  0.756336   \n",
       "11  As with any compromise, there would be both lo...  0.744644  0.745927   \n",
       "12  While the \"big three\" are increasingly pursuin...  0.687743  0.819861   \n",
       "13  While the \"big three\" are increasingly pursuin...  0.668884  0.803493   \n",
       "14  While the \"Big Three\" are increasingly pursuin...  0.689769  0.807715   \n",
       "15  While the \"Big Three\" are increasingly pursuin...  0.672723  0.791984   \n",
       "16  While the \"big three\" are increasingly pursuin...  0.679331  0.810885   \n",
       "17  While the \"big three\" increasingly pursue thei...  0.691249  0.821834   \n",
       "18  While the \"big three\" increasingly pursue thei...  0.664603  0.812127   \n",
       "19  While the \"big three\" are increasingly pursuin...  0.696184  0.825174   \n",
       "20  While the \"Big Three\" are increasingly pursuin...  0.682615  0.799408   \n",
       "\n",
       "         cqe   posthoc  dupcqeprev1    dupcqe  \n",
       "0   0.526303  0.390460     0.640510  0.640568  \n",
       "1   0.548467  0.393152     0.635732  0.635744  \n",
       "2   0.545454  0.405204     0.610568  0.610579  \n",
       "3   0.517116  0.406245     0.643053  0.643061  \n",
       "4   0.398527  0.419682     0.700219  0.700228  \n",
       "5   0.498138  0.411911     0.663014  0.663021  \n",
       "6   0.510370  0.414320     0.619864  0.619871  \n",
       "7   0.427046  0.425352     0.700422  0.700460  \n",
       "8   0.481410  0.426145     0.656755  0.656579  \n",
       "9   0.498468  0.429284     0.652845  0.652715  \n",
       "10  0.514181  0.429024     0.608002  0.607864  \n",
       "11  0.508022  0.427095     0.727786  0.727687  \n",
       "12  0.448231  0.338663     0.673443  0.673552  \n",
       "13  0.460306  0.337319     0.649865  0.649989  \n",
       "14  0.445308  0.345398     0.680725  0.680743  \n",
       "15  0.457578  0.343199     0.659764  0.659786  \n",
       "16  0.428179  0.344295     0.664017  0.664106  \n",
       "17  0.424395  0.351748     0.674435  0.674433  \n",
       "18  0.380931  0.346658     0.648280  0.648280  \n",
       "19  0.469667  0.351585     0.681297  0.681298  \n",
       "20  0.430417  0.350184     0.672932  0.672997  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explode_df.loc[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8a9d10-f81a-41fd-9b46-18c364a476cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'roberta.pooler.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_43/checkpoints/epoch=3-step=130000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# use noun model\n",
    "if \"noun\" in expl_fname:\n",
    "    encodemod = get_effrerank_model(\"noun\")\n",
    "# use mt model (causal)\n",
    "else:\n",
    "    encodemod = get_effrerank_model(\"comstyle\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aaba354-6aaa-441f-a45d-a383158f9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'setlen':int(SETLEN),\n",
    "    'tok':xlm_tok, \n",
    "    'dev':device,\n",
    "    'model':encodemod,\n",
    "    'explode_df':explode_df,\n",
    "    'base':base,\n",
    "    'goldmetric':goldmetric,\n",
    "    'device':device, \n",
    "    'efficient':False,\n",
    "    'noregen':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c9f17f-63ec-4dcb-92e5-14746ada89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "#DIVWEIGHT = 1\n",
    "#doadd = True\n",
    "DIVWEIGHT = 1\n",
    "doadd = True\n",
    "    \n",
    "def tokenprobdiverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def tokendiverse (node, used, norm):\n",
    "    if hasattr(node, \"score\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def nodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            if doadd:\n",
    "                return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def extranodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*used.count(node)\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38691c25-3cf8-4c34-9caf-0393b1ea5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRUNS = 10\n",
    "\n",
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct, metric):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_comstyle(g, encodemod, scofunct, metric, {'afunc':randomsingle}, False, NRUNS)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f61c2350-3fd9-4ec7-968a-b9d106d92de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques\n",
    "\n",
    "def count_unique_ngrams(sentences, n):\n",
    "    return len(cand_unique_ngrams(sentences, xlm_tok, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "660b6809-4c3d-46f5-8725-67a4b2a22b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show -> \n",
    "\n",
    "# Plot 1\n",
    "# - include random baseline for selecting in terms of quality\n",
    "# - go from left to right (number of candidates generated, and show score of each)\n",
    "\n",
    "# Plot 2 \n",
    "# - show beam search 50 baseline\n",
    "# - go from left to right, show n-gram diversity metric for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a89921c6-e753-4ba2-9b91-ce2301763555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind_diverse(ind, metric):\n",
    "    result = test_graph_ind(0, base, tokendiverse, metric)\n",
    "    # get number of unique n-grams added with more generation\n",
    "    cgrams = []\n",
    "    for i in range(1, len(result[2])+1):\n",
    "        cgrams.append(count_unique_ngrams(result[2][:i], 4))\n",
    "    if \"noun\" in metric:\n",
    "        source = \"noun\"\n",
    "    else:\n",
    "        source = result[0]\n",
    "    # get hypothesis scores\n",
    "    cscos = []\n",
    "    # TODO set this up with batching\n",
    "    for c in result[2]:\n",
    "        cscos.append(float(torch.sum(get_hyp_sco(c[4:], source, args))))\n",
    "    return cscos, cgrams, result\n",
    "\n",
    "def get_diverse_distr(metric, total):\n",
    "    allcs, allcg = [0]*NRUNS, [0]*NRUNS\n",
    "    for i in range(total):\n",
    "        print(i)\n",
    "        cstmp, cgtmp, r = get_ind_diverse(i, metric)\n",
    "        for i in range(NRUNS):\n",
    "            allcs[i] += cstmp[i]\n",
    "            allcg[i] += cgtmp[i]\n",
    "    return [c/total for c in allcs], [g/total for g in allcg]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e622787c-94dd-4e1c-affe-ff929d9756a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "overall = get_diverse_distr(\"utnoun\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c23511fa-c431-4d8d-8b0d-588ca85c44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8b8f6b9ee0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(NRUNS)), y=overall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2faab66-1eb9-44f5-83c6-e9fa7b0034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc3eb7-b182-409f-9d04-08ce951b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741494c2-e102-4b90-9b52-faa5bf044d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_graph_ind(0, base, tokendiverse, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0215fb4-bae7-4346-a9be-23998cfbfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgrams = []\n",
    "for i in range(1, len(result[2])+1):\n",
    "    cgrams.append(count_unique_ngrams(result[2][:i], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1073ff6-a924-4941-a1a0-f749d2106aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 68, 89, 106, 106, 125, 132, 137, 137, 137]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c5443d-87b3-4cc3-88f6-46725577d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> A senior army officer in the Democratic Republic of Congo has been accused by at least five women of ordering a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Day.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Eve.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of more than 50 women and girls in a single day.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been arrested on suspicion of raping dozens of women and girls in a single attack.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been accused of carrying out a mass rape in the north-eastern province of Kasai.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been accused of being behind a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Eve.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27f9f3-d775-497e-9272-120aeedc75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 100 examples, generate diverse options (up to 20), score each of them\n",
    "SET = 100\n",
    "i = 0\n",
    "while SET>0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8109df-b81f-4717-a3b2-8a29de29523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8467394-8aa5-408f-ac52-ee60b5611b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/graph_pickles/exploded_mtfren_beam12/0\", \"rb\") as file:\n",
    "    res = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2675fcd5-d945-409d-b93c-654351f05ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A slow new year for the world economy',\n",
       " 'A new slow year for the world economy',\n",
       " 'A slow new year for the global economy',\n",
       " 'A new slow year for the global economy',\n",
       " 'A Slow New Year for the World Economy',\n",
       " 'A New Slow Year for the World Economy',\n",
       " 'A Slow New Year for the Global Economy',\n",
       " 'A New Slow Year for the Global Economy',\n",
       " 'A slow new year for the world economy.',\n",
       " 'A slow new year for the global economy.',\n",
       " 'A new slow year for the world economy.',\n",
       " 'A new slow year for the global economy.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a133b4-2d37-4e3c-9efe-71660394af92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_graph_ind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_ind_diverse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutnoun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_ind_diverse\u001b[0;34m(ind, metric)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ind_diverse\u001b[39m(ind, metric):\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_graph_ind\u001b[49m(\u001b[38;5;241m0\u001b[39m, base, tokendiverse, metric)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# get number of unique n-grams added with more generation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     cgrams \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_graph_ind' is not defined"
     ]
    }
   ],
   "source": [
    "res = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550ab83f-7047-4b5f-8ce9-7f300c8c8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = [r[4:] for r in res[2][2]]\n",
    "scos = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2228117-b955-4e9b-ba8c-cec715e44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45810b0a-ffc3-4c32-906c-a02eec7fd0e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[1, 2, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[1, 2, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (3)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abdab085-3e02-4414-9ec5-e75b0a4e39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put elsewhere - make batched version of get_hyp_sco (TODO also do dataloader setup or smth)\n",
    "def causalmask (a, dev):\n",
    "    masksdef = torch.zeros((a.shape[0], a.shape[1],a.shape[1]), device=dev)\n",
    "    for i in range(len(a)):\n",
    "        lim = int(torch.sum(a[i]))\n",
    "        masksdef[i, :lim, :lim] = torch.tril(torch.ones((lim, lim)))\n",
    "    return masksdef\n",
    "\n",
    "def batch_hyp_sco(srcs, hyps, metric):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "    \n",
    "    out_toks = tok(hyps, return_tensors='pt', padding=True, truncation=True).to(dev)\n",
    "    out_tokens = out_toks.input_ids\n",
    "    hypmask = causalmask(out_toks.attention_mask, device)\n",
    "    \n",
    "    positionids = None\n",
    "    toked_inp = tok(srcs, padding=True, truncation=True, return_tensors=\"pt\").to(dev)\n",
    "    \n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, out_tokens, positionids, \\\n",
    "        hypmask)\n",
    "    \n",
    "    return torch.sum(predout['score'], 1)#, toked_inp, out_tokens, positionids, hypmask\n",
    "    \n",
    "# get token level scores from model, given hypothesis and input source\n",
    "def get_hyp_sco(inphyp, inpsrc, args):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "\n",
    "    # calculate inputs\n",
    "    tokens = tok(inphyp, return_tensors='pt', truncation=True).to(dev)\n",
    "    tokens = tokens.input_ids\n",
    "    positionids = None\n",
    "    toked_inp = tok([inpsrc], return_tensors=\"pt\").to(dev)\n",
    "    # get causal mask\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(dev)\n",
    "    # run through model\n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    return torch.sum(predout['score'])#, toked_inp, tokens, positionids, tmpmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4348518d-e7c5-4e4f-8775-96ee787f9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2, 3, 1)\n",
    "b = torch.ones(2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f34c1eb-2f3c-46e3-84ca-deee68e33d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0af82a9-0d33-4fab-9fb8-789ab0f0034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btest = batch_hyp_sco([\"noun\"]*10, cands, args)\n",
    "htest = get_hyp_sco(cands[3], \"noun\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2bcd0b-1425-4de7-9a52-3f29d5e97c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22332ce9-9a1d-4aad-b192-68640e8971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = explode_df.loc[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "558da394-3b6f-4432-9731-2dd96084d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05416083335876465\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "batch_hyp_sco([\"noun\"]*len(tmp), list(tmp['hyp']), args)\n",
    "tot = time.time()-s\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227a5c27-6d97-411b-bdd6-27c56494bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                     0\n",
       "src            Comme pour tout compromis, les parties prenant...\n",
       "ref            As with any compromise, the contending parties...\n",
       "hyp            As with any compromise, stakeholders would hav...\n",
       "dcqeold                                                  0.67299\n",
       "comet                                                   0.776076\n",
       "cqe                                                     0.526303\n",
       "posthoc                                                  0.39046\n",
       "dupcqeprev1                                              0.64051\n",
       "dupcqe                                                  0.640568\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tind = tmp.loc[0]\n",
    "tind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d616cce8-fa84-468a-86cd-e403063e9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comme pour tout compromis, les parties prenantes auraient à la fois à perdre et à gagner dans cet arrangement. '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tind['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61b7887-395a-48c9-bfff-8f1e10bb99c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6200, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hyp_sco(tind['hyp'], tind['src'], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d24fed-27f7-477d-9a4c-6e24c2c14f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6200],\n",
       "        [0.6123],\n",
       "        [0.5721],\n",
       "        [0.6260],\n",
       "        [0.6966],\n",
       "        [0.6428],\n",
       "        [0.5876],\n",
       "        [0.7055],\n",
       "        [0.6402],\n",
       "        [0.6341],\n",
       "        [0.5645],\n",
       "        [0.7112],\n",
       "        [0.6950],\n",
       "        [0.6687],\n",
       "        [0.6928],\n",
       "        [0.6689],\n",
       "        [0.6937],\n",
       "        [0.6920],\n",
       "        [0.6818],\n",
       "        [0.6978],\n",
       "        [0.6919],\n",
       "        [0.6104],\n",
       "        [0.6473],\n",
       "        [0.6588],\n",
       "        [0.8014],\n",
       "        [0.7982],\n",
       "        [0.7970],\n",
       "        [0.7946],\n",
       "        [0.7982],\n",
       "        [0.7975],\n",
       "        [0.7970],\n",
       "        [0.8056],\n",
       "        [0.8075]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_hyp_sco(list(tmp['src']), list(tmp['hyp']), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb50fac-0eba-4535-b7de-9603cdb66b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3034],\n",
       "        [1.1236],\n",
       "        [1.2539],\n",
       "        [1.3034],\n",
       "        [0.9848],\n",
       "        [0.9704],\n",
       "        [0.8752],\n",
       "        [1.2966],\n",
       "        [0.8793],\n",
       "        [1.3001]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa212be-14d8-4c84-b861-934f78322265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3034, device='cuda:0', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7f1ff06-a3ef-4189-ac24-b89bfd2d6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpstmp = btest[1].input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d8c1962-2723-409e-8e39-3b4e12e0ee97",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minpstmp\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpstmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "inpstmp/(torch.max(inpstmp, 1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6011385-1b23-4a7c-a871-00c6cadf2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2]], device='cuda:0')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpstmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34932db-97e9-4b02-b7c1-5b057fe225e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2586, 1.3145, 1.6432, 1.7925, 1.4084, 1.3145, 1.8486, 1.6901, 1.3145,\n",
       "         1.8486],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.7550, 0.7885, 0.9856, 1.0752, 0.8448, 0.7885, 1.1088, 1.0138, 0.7885,\n",
       "         1.1088],\n",
       "        [0.6813, 0.7116, 0.8895, 0.9704, 0.7624, 0.7116, 1.0007, 0.9149, 0.7116,\n",
       "         1.0007],\n",
       "        [1.1618, 1.2134, 1.5167, 1.6546, 1.3001, 1.2134, 1.7063, 1.5601, 1.2134,\n",
       "         1.7063],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.5986, 0.6253, 0.7816, 0.8526, 0.6699, 0.6253, 0.8793, 0.8039, 0.6253,\n",
       "         0.8793],\n",
       "        [0.6517, 0.6807, 0.8509, 0.9282, 0.7293, 0.6807, 0.9572, 0.8752, 0.6807,\n",
       "         0.9572],\n",
       "        [1.2479, 1.3034, 1.6292, 1.7773, 1.3965, 1.3034, 1.8329, 1.6758, 1.3034,\n",
       "         1.8329],\n",
       "        [0.5926, 0.6189, 0.7737, 0.8440, 0.6632, 0.6189, 0.8704, 0.7958, 0.6189,\n",
       "         0.8704]], device='cuda:0', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f77f316-816b-4fe5-963b-2336d2004c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:0')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6d1e9-c17b-4aed-b3e9-218e3be4343d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
