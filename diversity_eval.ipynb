{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52988157-efd6-4541-b558-f5cb0e89aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-01-01 10:13:04.256716: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-01-01 10:13:04.256737: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# notebook to get numbers for, and plot for diversity trade-off\n",
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from encode_utils.new_mask_utils import randomsingle, useall\n",
    "from encode_utils.eval_utils import all_lattice_multi, mean, all_unnoun_multi, get_hyp_sco\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6533f47-3337-48ec-bae2-bc8887cdbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up information for set\n",
    "col = {\n",
    "    \"noun_xsum\": [\"nounsum_reversed/\", \"nounxsumlargeexplodev2.csv\"],\n",
    "    \"noun_fren\": [\"frtest_reversed/\", \"nounlargeexplodev1.csv\"],\n",
    "    \"mt_fren\": [\"frtest_reversed/\", \"frenchlargeexplodev1.csv\"],\n",
    "    \"mt_ende\": [\"detest_reversed/\", \"germanlargeexplodev1.csv\"],\n",
    "    \"mt_enru\": [\"rutest_reversed/\", \"russianlargeexplodev1.csv\"],\n",
    "    \"mt_fren_b12\": ['reversed_mtfren_beam12/', 'mtfrenbeam12v2.csv'],\n",
    "    \"mt_fren_b50\": ['reversed_mtfren_beam50/', 'mtfrenbeam50v2.csv'],\n",
    "    \"noun_xsum_b12\": ['reversed_xsum_beam12/', 'nounxsumbeam12v2.csv'],\n",
    "    \"noun_xsum_b50\": ['reversed_xsum_beam50/', 'nounxsumbeam50v2.csv'],\n",
    "}\n",
    "curcol = \"noun_xsum\"\n",
    "gsuffix = col[curcol][0]\n",
    "expl_fname = col[curcol][1]\n",
    "base = \"outputs/graph_pickles/\"+gsuffix\n",
    "goldmetric = \"utnoun\"\n",
    "explode_df = pd.read_csv(\"outputs/score_csvs/\"+expl_fname)\n",
    "#TODO switch back for french-english\n",
    "if \"fren\" in curcol:\n",
    "    SETLEN = len(os.listdir(base))\n",
    "else:\n",
    "    SETLEN = int(len(os.listdir(base))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8ba53b-fba8-4fae-ae6b-c1633032f6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "SETLEN = len(os.listdir(base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c8a9d10-f81a-41fd-9b46-18c364a476cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.bias', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# use noun model\n",
    "if \"noun\" in expl_fname:\n",
    "    encodemod = get_effrerank_model(\"noun\")\n",
    "# use mt model (causal)\n",
    "else:\n",
    "    encodemod = get_effrerank_model(\"comstyle\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6aaba354-6aaa-441f-a45d-a383158f9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'setlen':int(SETLEN),\n",
    "    'tok':xlm_tok, \n",
    "    'dev':device,\n",
    "    'model':encodemod,\n",
    "    'explode_df':explode_df,\n",
    "    'base':base,\n",
    "    'goldmetric':goldmetric,\n",
    "    'device':device, \n",
    "    'efficient':False,\n",
    "    'noregen':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58c9f17f-63ec-4dcb-92e5-14746ada89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "#DIVWEIGHT = 1\n",
    "#doadd = True\n",
    "DIVWEIGHT = 1\n",
    "doadd = True\n",
    "    \n",
    "def tokenprobdiverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def tokendiverse (node, used, norm):\n",
    "    if hasattr(node, \"score\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def nodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            if doadd:\n",
    "                return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def extranodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*used.count(node)\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94f670d3-31b2-4a72-8e7b-47830d4add9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrefs = list(explode_df['ref'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38691c25-3cf8-4c34-9caf-0393b1ea5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRUNS = 10\n",
    "\n",
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct, metric):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    if g['ref'] not in lrefs:\n",
    "        return None, None, None\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_comstyle(g, encodemod, scofunct, metric, {'afunc':randomsingle}, False, NRUNS)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f61c2350-3fd9-4ec7-968a-b9d106d92de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques\n",
    "\n",
    "def count_unique_ngrams(sentences, n):\n",
    "    return len(cand_unique_ngrams(sentences, xlm_tok, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92d1a73c-5579-43eb-a774-2683abfe063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def base_unique_ngrams(edf, n):\n",
    "    uns = edf['ref'].unique()\n",
    "    ndist = []\n",
    "    for u in uns:\n",
    "        segment = edf[edf['ref']==u]\n",
    "        \n",
    "        if len(segment)>0:\n",
    "            ndist.append(count_unique_ngrams(list(segment['hyp']), n))\n",
    "    return ndist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36411396-acd6-4b54-b2cc-cc42244310d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndist = base_unique_ngrams(explode_df, 4)\n",
    "#print(sum(ndist)/len(ndist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "660b6809-4c3d-46f5-8725-67a4b2a22b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show -> \n",
    "\n",
    "# Plot 1\n",
    "# - include random baseline for selecting in terms of quality\n",
    "# - go from left to right (number of candidates generated, and show score of each)\n",
    "\n",
    "# Plot 2 \n",
    "# - show beam search 50 baseline\n",
    "# - go from left to right, show n-gram diversity metric for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a89921c6-e753-4ba2-9b91-ce2301763555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind_diverse(ind, metric):\n",
    "    result = test_graph_ind(ind, base, tokendiverse, metric)\n",
    "    if result[0] is None:\n",
    "        return None, None, None\n",
    "    # get number of unique n-grams added with more generation\n",
    "    cgrams = []\n",
    "    for i in range(1, len(result[2])+1):\n",
    "        cgrams.append(count_unique_ngrams(result[2][:i], 4))\n",
    "\n",
    "    if \"noun\" in metric:\n",
    "        source = \"noun\"\n",
    "    else:\n",
    "        source = result[0]\n",
    "    # get hypothesis scores\n",
    "    cscos = []\n",
    "    # TODO set this up with batching\n",
    "    for c in result[2]:\n",
    "        cscos.append(float(torch.sum(get_hyp_sco(c[4:], source, args))))\n",
    "    return cscos, cgrams, result\n",
    "\n",
    "def get_diverse_distr(metric, total):\n",
    "    allcs, allcg = [0]*NRUNS, [0]*NRUNS\n",
    "    tvals = 0\n",
    "    for i in range(total):\n",
    "        cstmp, cgtmp, r = get_ind_diverse(i, metric)\n",
    "        if cstmp is None:\n",
    "            #print(\"skip\")\n",
    "            continue\n",
    "        for j in range(NRUNS):\n",
    "            allcs[j] += cstmp[j]\n",
    "            allcg[j] += cgtmp[j]\n",
    "        tvals+=1\n",
    "        print(tvals, \" \", i)\n",
    "    return [c/tvals for c in allcs], [g/tvals for g in allcg]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e622787c-94dd-4e1c-affe-ff929d9756a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557   1087\n",
      "558   1091\n",
      "559   1092\n",
      "560   1097\n",
      "561   1098\n",
      "562   1099\n",
      "563   1100\n",
      "564   1102\n",
      "565   1103\n",
      "566   1105\n",
      "567   1108\n",
      "568   1109\n",
      "569   1110\n",
      "570   1112\n",
      "571   1114\n",
      "572   1119\n",
      "573   1120\n",
      "574   1122\n",
      "575   1123\n",
      "576   1124\n",
      "577   1126\n",
      "578   1127\n",
      "579   1130\n",
      "580   1131\n",
      "581   1132\n",
      "582   1135\n",
      "583   1136\n",
      "584   1140\n",
      "585   1143\n",
      "586   1144\n",
      "587   1145\n",
      "588   1146\n",
      "589   1147\n",
      "590   1148\n",
      "591   1150\n",
      "592   1155\n",
      "593   1156\n",
      "594   1157\n",
      "595   1158\n",
      "596   1161\n",
      "597   1162\n",
      "598   1163\n",
      "599   1166\n",
      "600   1167\n"
     ]
    }
   ],
   "source": [
    "overall = get_diverse_distr(\"utnoun\", SETLEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "957e1d41-5fe9-4aeb-9c71-896bdb3c0973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1.1223565481603146,\n",
       "  0.9676461719721555,\n",
       "  0.9060725154479344,\n",
       "  0.861249197560052,\n",
       "  0.8511633169402679,\n",
       "  0.832240644544363,\n",
       "  0.8293558774205546,\n",
       "  0.8174281796316306,\n",
       "  0.8179277575900779,\n",
       "  0.8056926445538799],\n",
       " [38.94166666666667,\n",
       "  62.505,\n",
       "  80.26333333333334,\n",
       "  94.01333333333334,\n",
       "  104.20666666666666,\n",
       "  111.94666666666667,\n",
       "  117.91,\n",
       "  123.01166666666667,\n",
       "  126.5,\n",
       "  129.79166666666666])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5f5026d-7d35-4b38-8701-a0157cbca290",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall = ([1.1223565481603146,\n",
    "  0.9676461719721555,\n",
    "  0.9060725154479344,\n",
    "  0.861249197560052,\n",
    "  0.8511633169402679,\n",
    "  0.832240644544363,\n",
    "  0.8293558774205546,\n",
    "  0.8174281796316306,\n",
    "  0.8179277575900779,\n",
    "  0.8056926445538799],\n",
    " [38.94166666666667,\n",
    "  62.505,\n",
    "  80.26333333333334,\n",
    "  94.01333333333334,\n",
    "  104.20666666666666,\n",
    "  111.94666666666667,\n",
    "  117.91,\n",
    "  123.01166666666667,\n",
    "  126.5,\n",
    "  129.79166666666666])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c23511fa-c431-4d8d-8b0d-588ca85c44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f567b744ca0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(NRUNS)), y=overall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ff7bf4f-0e5b-490b-ac7c-712f91e74bbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f757c378190>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(NRUNS)), y=overall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2faab66-1eb9-44f5-83c6-e9fa7b0034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc3eb7-b182-409f-9d04-08ce951b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741494c2-e102-4b90-9b52-faa5bf044d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_graph_ind(0, base, tokendiverse, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0215fb4-bae7-4346-a9be-23998cfbfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgrams = []\n",
    "for i in range(1, len(result[2])+1):\n",
    "    cgrams.append(count_unique_ngrams(result[2][:i], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1073ff6-a924-4941-a1a0-f749d2106aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 68, 89, 106, 106, 125, 132, 137, 137, 137]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c5443d-87b3-4cc3-88f6-46725577d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> A senior army officer in the Democratic Republic of Congo has been accused by at least five women of ordering a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Day.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Eve.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of more than 50 women and girls in a single day.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been arrested on suspicion of raping dozens of women and girls in a single attack.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been accused of carrying out a mass rape in the north-eastern province of Kasai.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been accused of being behind a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Eve.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27f9f3-d775-497e-9272-120aeedc75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 100 examples, generate diverse options (up to 20), score each of them\n",
    "SET = 100\n",
    "i = 0\n",
    "while SET>0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8109df-b81f-4717-a3b2-8a29de29523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8467394-8aa5-408f-ac52-ee60b5611b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/graph_pickles/exploded_mtfren_beam12/0\", \"rb\") as file:\n",
    "    res = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2675fcd5-d945-409d-b93c-654351f05ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A slow new year for the world economy',\n",
       " 'A new slow year for the world economy',\n",
       " 'A slow new year for the global economy',\n",
       " 'A new slow year for the global economy',\n",
       " 'A Slow New Year for the World Economy',\n",
       " 'A New Slow Year for the World Economy',\n",
       " 'A Slow New Year for the Global Economy',\n",
       " 'A New Slow Year for the Global Economy',\n",
       " 'A slow new year for the world economy.',\n",
       " 'A slow new year for the global economy.',\n",
       " 'A new slow year for the world economy.',\n",
       " 'A new slow year for the global economy.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a133b4-2d37-4e3c-9efe-71660394af92",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_graph_ind' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mget_ind_diverse\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutnoun\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mget_ind_diverse\u001b[0;34m(ind, metric)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_ind_diverse\u001b[39m(ind, metric):\n\u001b[0;32m----> 2\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mtest_graph_ind\u001b[49m(\u001b[38;5;241m0\u001b[39m, base, tokendiverse, metric)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# get number of unique n-grams added with more generation\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     cgrams \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_graph_ind' is not defined"
     ]
    }
   ],
   "source": [
    "res = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550ab83f-7047-4b5f-8ce9-7f300c8c8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = [r[4:] for r in res[2][2]]\n",
    "scos = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f2228117-b955-4e9b-ba8c-cec715e44c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "45810b0a-ffc3-4c32-906c-a02eec7fd0e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "expand(torch.FloatTensor{[1, 2, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [46]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexpand\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: expand(torch.FloatTensor{[1, 2, 3]}, size=[3]): the number of sizes provided (1) must be greater or equal to the number of dimensions in the tensor (3)"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abdab085-3e02-4414-9ec5-e75b0a4e39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put elsewhere - make batched version of get_hyp_sco (TODO also do dataloader setup or smth)\n",
    "def causalmask (a, dev):\n",
    "    masksdef = torch.zeros((a.shape[0], a.shape[1],a.shape[1]), device=dev)\n",
    "    for i in range(len(a)):\n",
    "        lim = int(torch.sum(a[i]))\n",
    "        masksdef[i, :lim, :lim] = torch.tril(torch.ones((lim, lim)))\n",
    "    return masksdef\n",
    "\n",
    "def batch_hyp_sco(srcs, hyps, metric):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "    \n",
    "    out_toks = tok(hyps, return_tensors='pt', padding=True, truncation=True).to(dev)\n",
    "    out_tokens = out_toks.input_ids\n",
    "    hypmask = causalmask(out_toks.attention_mask, device)\n",
    "    \n",
    "    positionids = None\n",
    "    toked_inp = tok(srcs, padding=True, truncation=True, return_tensors=\"pt\").to(dev)\n",
    "    \n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, out_tokens, positionids, \\\n",
    "        hypmask)\n",
    "    \n",
    "    return torch.sum(predout['score'], 1)#, toked_inp, out_tokens, positionids, hypmask\n",
    "    \n",
    "# get token level scores from model, given hypothesis and input source\n",
    "def get_hyp_sco(inphyp, inpsrc, args):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "\n",
    "    # calculate inputs\n",
    "    tokens = tok(inphyp, return_tensors='pt', truncation=True).to(dev)\n",
    "    tokens = tokens.input_ids\n",
    "    positionids = None\n",
    "    toked_inp = tok([inpsrc], return_tensors=\"pt\").to(dev)\n",
    "    # get causal mask\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(dev)\n",
    "    # run through model\n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    return torch.sum(predout['score'])#, toked_inp, tokens, positionids, tmpmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4348518d-e7c5-4e4f-8775-96ee787f9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2, 3, 1)\n",
    "b = torch.ones(2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f34c1eb-2f3c-46e3-84ca-deee68e33d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0af82a9-0d33-4fab-9fb8-789ab0f0034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btest = batch_hyp_sco([\"noun\"]*10, cands, args)\n",
    "htest = get_hyp_sco(cands[3], \"noun\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e2bcd0b-1425-4de7-9a52-3f29d5e97c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22332ce9-9a1d-4aad-b192-68640e8971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = explode_df.loc[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "558da394-3b6f-4432-9731-2dd96084d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05416083335876465\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "batch_hyp_sco([\"noun\"]*len(tmp), list(tmp['hyp']), args)\n",
    "tot = time.time()-s\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "227a5c27-6d97-411b-bdd6-27c56494bf54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                     0\n",
       "src            Comme pour tout compromis, les parties prenant...\n",
       "ref            As with any compromise, the contending parties...\n",
       "hyp            As with any compromise, stakeholders would hav...\n",
       "dcqeold                                                  0.67299\n",
       "comet                                                   0.776076\n",
       "cqe                                                     0.526303\n",
       "posthoc                                                  0.39046\n",
       "dupcqeprev1                                              0.64051\n",
       "dupcqe                                                  0.640568\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tind = tmp.loc[0]\n",
    "tind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d616cce8-fa84-468a-86cd-e403063e9b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Comme pour tout compromis, les parties prenantes auraient à la fois à perdre et à gagner dans cet arrangement. '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tind['src']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c61b7887-395a-48c9-bfff-8f1e10bb99c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6200, device='cuda:2', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_hyp_sco(tind['hyp'], tind['src'], args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d9d24fed-27f7-477d-9a4c-6e24c2c14f23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6200],\n",
       "        [0.6123],\n",
       "        [0.5721],\n",
       "        [0.6260],\n",
       "        [0.6966],\n",
       "        [0.6428],\n",
       "        [0.5876],\n",
       "        [0.7055],\n",
       "        [0.6402],\n",
       "        [0.6341],\n",
       "        [0.5645],\n",
       "        [0.7112],\n",
       "        [0.6950],\n",
       "        [0.6687],\n",
       "        [0.6928],\n",
       "        [0.6689],\n",
       "        [0.6937],\n",
       "        [0.6920],\n",
       "        [0.6818],\n",
       "        [0.6978],\n",
       "        [0.6919],\n",
       "        [0.6104],\n",
       "        [0.6473],\n",
       "        [0.6588],\n",
       "        [0.8014],\n",
       "        [0.7982],\n",
       "        [0.7970],\n",
       "        [0.7946],\n",
       "        [0.7982],\n",
       "        [0.7975],\n",
       "        [0.7970],\n",
       "        [0.8056],\n",
       "        [0.8075]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_hyp_sco(list(tmp['src']), list(tmp['hyp']), args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb50fac-0eba-4535-b7de-9603cdb66b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3034],\n",
       "        [1.1236],\n",
       "        [1.2539],\n",
       "        [1.3034],\n",
       "        [0.9848],\n",
       "        [0.9704],\n",
       "        [0.8752],\n",
       "        [1.2966],\n",
       "        [0.8793],\n",
       "        [1.3001]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa212be-14d8-4c84-b861-934f78322265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3034, device='cuda:2', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7f1ff06-a3ef-4189-ac24-b89bfd2d6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpstmp = btest[1].input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d8c1962-2723-409e-8e39-3b4e12e0ee97",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minpstmp\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpstmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "inpstmp/(torch.max(inpstmp, 1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6011385-1b23-4a7c-a871-00c6cadf2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2]], device='cuda:2')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpstmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34932db-97e9-4b02-b7c1-5b057fe225e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2586, 1.3145, 1.6432, 1.7925, 1.4084, 1.3145, 1.8486, 1.6901, 1.3145,\n",
       "         1.8486],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.7550, 0.7885, 0.9856, 1.0752, 0.8448, 0.7885, 1.1088, 1.0138, 0.7885,\n",
       "         1.1088],\n",
       "        [0.6813, 0.7116, 0.8895, 0.9704, 0.7624, 0.7116, 1.0007, 0.9149, 0.7116,\n",
       "         1.0007],\n",
       "        [1.1618, 1.2134, 1.5167, 1.6546, 1.3001, 1.2134, 1.7063, 1.5601, 1.2134,\n",
       "         1.7063],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.5986, 0.6253, 0.7816, 0.8526, 0.6699, 0.6253, 0.8793, 0.8039, 0.6253,\n",
       "         0.8793],\n",
       "        [0.6517, 0.6807, 0.8509, 0.9282, 0.7293, 0.6807, 0.9572, 0.8752, 0.6807,\n",
       "         0.9572],\n",
       "        [1.2479, 1.3034, 1.6292, 1.7773, 1.3965, 1.3034, 1.8329, 1.6758, 1.3034,\n",
       "         1.8329],\n",
       "        [0.5926, 0.6189, 0.7737, 0.8440, 0.6632, 0.6189, 0.8704, 0.7958, 0.6189,\n",
       "         0.8704]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f77f316-816b-4fe5-963b-2336d2004c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:2')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6d1e9-c17b-4aed-b3e9-218e3be4343d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
