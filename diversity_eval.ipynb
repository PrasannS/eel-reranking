{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52988157-efd6-4541-b558-f5cb0e89aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-27 07:12:56.723629: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-27 07:12:56.723651: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# notebook to get numbers for, and plot for diversity trade-off\n",
    "\n",
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "from encode_utils.new_mask_utils import randomsingle, useall\n",
    "from encode_utils.eval_utils import all_lattice_multi, mean, all_unnoun_multi\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6533f47-3337-48ec-bae2-bc8887cdbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up information for set\n",
    "col = {\n",
    "    \"noun_xsum\": [\"nounsum_reversed/\", \"nounxsumlargeexplodev2.csv\"],\n",
    "    \"noun_fren\": [\"frtest_reversed/\", \"nounlargeexplodev1.csv\"],\n",
    "    \"mt_fren\": [\"frtest_reversed/\", \"frenchlargeexplodev1.csv\"],\n",
    "    \"mt_ende\": [\"detest_reversed/\", \"germanlargeexplodev1.csv\"],\n",
    "    \"mt_enru\": [\"rutest_reversed/\", \"russianlargeexplodev1.csv\"],\n",
    "    \"mt_fren_b12\": ['reversed_mtfren_beam12/', 'mtfrenbeam12.csv'],\n",
    "    \"mt_fren_b50\": ['reversed_mtfren_beam50/', 'mtfrenbeam50.csv'],\n",
    "    \"noun_xsum_b12\": ['reversed_xsum_beam12/', 'nounxsumbeam12.csv'],\n",
    "    \"noun_xsum_b50\": ['reversed_xsum_beam50/', 'nounxsumbeam50.csv'],\n",
    "}\n",
    "curcol = \"noun_xsum_b12\"\n",
    "gsuffix = col[curcol][0]\n",
    "expl_fname = col[curcol][1]\n",
    "base = \"outputs/graph_pickles/\"+gsuffix\n",
    "goldmetric = \"utnoun\"\n",
    "explode_df = pd.read_csv(\"outputs/score_csvs/\"+expl_fname)\n",
    "#TODO switch back for french-english\n",
    "if \"fren\" in curcol:\n",
    "    SETLEN = len(os.listdir(base))\n",
    "else:\n",
    "    SETLEN = int(len(os.listdir(base))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c8a9d10-f81a-41fd-9b46-18c364a476cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use noun model\n",
    "if \"noun\" in expl_fname:\n",
    "    encodemod = get_effrerank_model(\"noun\")\n",
    "# use mt model (causal)\n",
    "else:\n",
    "    encodemod = get_effrerank_model(\"comstyle\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aaba354-6aaa-441f-a45d-a383158f9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'setlen':int(SETLEN),\n",
    "    'tok':xlm_tok, \n",
    "    'dev':device,\n",
    "    'model':encodemod,\n",
    "    'explode_df':explode_df,\n",
    "    'base':base,\n",
    "    'goldmetric':goldmetric,\n",
    "    'device':device, \n",
    "    'efficient':False,\n",
    "    'noregen':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c9f17f-63ec-4dcb-92e5-14746ada89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "#DIVWEIGHT = 1\n",
    "#doadd = True\n",
    "DIVWEIGHT = 1\n",
    "doadd = True\n",
    "    \n",
    "def tokenprobdiverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def tokendiverse (node, used):\n",
    "    if hasattr(node, \"score\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def nodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            if doadd:\n",
    "                return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def extranodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*used.count(node)\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fee3ada6-33d5-46f2-95b0-b27af403e60c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 100 examples, generate diverse options (up to 20), score each of them\n",
    "SET = 100\n",
    "i = 0\n",
    "while SET>0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38691c25-3cf8-4c34-9caf-0393b1ea5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_pipeline(g, model, scofunct, False, 20)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61c2350-3fd9-4ec7-968a-b9d106d92de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660b6809-4c3d-46f5-8725-67a4b2a22b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show -> \n",
    "\n",
    "# Plot 1\n",
    "# - include random baseline for selecting in terms of quality\n",
    "# - go from left to right (number of candidates generated, and show score of each)\n",
    "\n",
    "# Plot 2 \n",
    "# - show beam search 50 baseline\n",
    "# - go from left to right, show n-gram diversity metric for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8109df-b81f-4717-a3b2-8a29de29523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8467394-8aa5-408f-ac52-ee60b5611b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/graph_pickles/exploded_mtfren_beam12/0\", \"rb\") as file:\n",
    "    res = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2675fcd5-d945-409d-b93c-654351f05ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A slow new year for the world economy',\n",
       " 'A new slow year for the world economy',\n",
       " 'A slow new year for the global economy',\n",
       " 'A new slow year for the global economy',\n",
       " 'A Slow New Year for the World Economy',\n",
       " 'A New Slow Year for the World Economy',\n",
       " 'A Slow New Year for the Global Economy',\n",
       " 'A New Slow Year for the Global Economy',\n",
       " 'A slow new year for the world economy.',\n",
       " 'A slow new year for the global economy.',\n",
       " 'A new slow year for the world economy.',\n",
       " 'A new slow year for the global economy.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a9c092-0a1a-44d8-8ac2-03b2df1c41e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
