{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52988157-efd6-4541-b558-f5cb0e89aa66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-29 11:34:41.192602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-29 11:34:41.192624: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# notebook to get numbers for, and plot for diversity trade-off\n",
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "import os\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from encode_utils.new_mask_utils import randomsingle, useall\n",
    "from encode_utils.eval_utils import all_lattice_multi, mean, all_unnoun_multi, get_hyp_sco\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6533f47-3337-48ec-bae2-bc8887cdbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up information for set\n",
    "col = {\n",
    "    \"noun_xsum\": [\"nounsum_reversed/\", \"nounxsumlargeexplodev2.csv\"],\n",
    "    \"noun_fren\": [\"frtest_reversed/\", \"nounlargeexplodev1.csv\"],\n",
    "    \"mt_fren\": [\"frtest_reversed/\", \"frenchlargeexplodev1.csv\"],\n",
    "    \"mt_ende\": [\"detest_reversed/\", \"germanlargeexplodev1.csv\"],\n",
    "    \"mt_enru\": [\"rutest_reversed/\", \"russianlargeexplodev1.csv\"],\n",
    "    \"mt_fren_b12\": ['reversed_mtfren_beam12/', 'mtfrenbeam12v2.csv'],\n",
    "    \"mt_fren_b50\": ['reversed_mtfren_beam50/', 'mtfrenbeam50v2.csv'],\n",
    "    \"noun_xsum_b12\": ['reversed_xsum_beam12/', 'nounxsumbeam12v2.csv'],\n",
    "    \"noun_xsum_b50\": ['reversed_xsum_beam50/', 'nounxsumbeam50v2.csv'],\n",
    "}\n",
    "curcol = \"noun_xsum\"\n",
    "gsuffix = col[curcol][0]\n",
    "expl_fname = col[curcol][1]\n",
    "base = \"outputs/graph_pickles/\"+gsuffix\n",
    "goldmetric = \"utnoun\"\n",
    "explode_df = pd.read_csv(\"outputs/score_csvs/\"+expl_fname)\n",
    "#TODO switch back for french-english\n",
    "if \"fren\" in curcol:\n",
    "    SETLEN = len(os.listdir(base))\n",
    "else:\n",
    "    SETLEN = int(len(os.listdir(base))/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c8a9d10-f81a-41fd-9b46-18c364a476cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# use noun model\n",
    "if \"noun\" in expl_fname:\n",
    "    encodemod = get_effrerank_model(\"noun\")\n",
    "# use mt model (causal)\n",
    "else:\n",
    "    encodemod = get_effrerank_model(\"comstyle\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aaba354-6aaa-441f-a45d-a383158f9e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = {\n",
    "    'setlen':int(SETLEN),\n",
    "    'tok':xlm_tok, \n",
    "    'dev':device,\n",
    "    'model':encodemod,\n",
    "    'explode_df':explode_df,\n",
    "    'base':base,\n",
    "    'goldmetric':goldmetric,\n",
    "    'device':device, \n",
    "    'efficient':False,\n",
    "    'noregen':False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58c9f17f-63ec-4dcb-92e5-14746ada89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "#DIVWEIGHT = 1\n",
    "#doadd = True\n",
    "DIVWEIGHT = 1\n",
    "doadd = True\n",
    "    \n",
    "def tokenprobdiverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def tokendiverse (node, used, norm):\n",
    "    if hasattr(node, \"score\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def nodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            if doadd:\n",
    "                return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def extranodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*used.count(node)\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38691c25-3cf8-4c34-9caf-0393b1ea5da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "NRUNS = 10\n",
    "\n",
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct, metric):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_comstyle(g, encodemod, scofunct, metric, {'afunc':randomsingle}, False, NRUNS)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f61c2350-3fd9-4ec7-968a-b9d106d92de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques\n",
    "\n",
    "def count_unique_ngrams(sentences, n):\n",
    "    return len(cand_unique_ngrams(sentences, xlm_tok, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "660b6809-4c3d-46f5-8725-67a4b2a22b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots to show -> \n",
    "\n",
    "# Plot 1\n",
    "# - include random baseline for selecting in terms of quality\n",
    "# - go from left to right (number of candidates generated, and show score of each)\n",
    "\n",
    "# Plot 2 \n",
    "# - show beam search 50 baseline\n",
    "# - go from left to right, show n-gram diversity metric for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a89921c6-e753-4ba2-9b91-ce2301763555",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ind_diverse(ind, metric):\n",
    "    result = test_graph_ind(0, base, tokendiverse, metric)\n",
    "    # get number of unique n-grams added with more generation\n",
    "    cgrams = []\n",
    "    for i in range(1, len(result[2])+1):\n",
    "        cgrams.append(count_unique_ngrams(result[2][:i], 4))\n",
    "    if \"noun\" in metric:\n",
    "        source = \"noun\"\n",
    "    else:\n",
    "        source = result[0]\n",
    "    # get hypothesis scores\n",
    "    cscos = []\n",
    "    # TODO set this up with batching\n",
    "    for c in result[2]:\n",
    "        cscos.append(float(torch.sum(get_hyp_sco(c[4:], source, args))))\n",
    "    return cscos, cgrams, result\n",
    "\n",
    "def get_diverse_distr(metric, total):\n",
    "    allcs, allcg = [0]*NRUNS, [0]*NRUNS\n",
    "    for i in range(total):\n",
    "        print(i)\n",
    "        cstmp, cgtmp, r = get_ind_diverse(i, metric)\n",
    "        for i in range(NRUNS):\n",
    "            allcs[i] += cstmp[i]\n",
    "            allcg[i] += cgtmp[i]\n",
    "    return [c/total for c in allcs], [g/total for g in allcg]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e622787c-94dd-4e1c-affe-ff929d9756a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "overall = get_diverse_distr(\"utnoun\", 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c23511fa-c431-4d8d-8b0d-588ca85c44c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f8b8f6b9ee0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x=list(range(NRUNS)), y=overall[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2faab66-1eb9-44f5-83c6-e9fa7b0034ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc3eb7-b182-409f-9d04-08ce951b9147",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "741494c2-e102-4b90-9b52-faa5bf044d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = test_graph_ind(0, base, tokendiverse, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0215fb4-bae7-4346-a9be-23998cfbfa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "cgrams = []\n",
    "for i in range(1, len(result[2])+1):\n",
    "    cgrams.append(count_unique_ngrams(result[2][:i], 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1073ff6-a924-4941-a1a0-f749d2106aa2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46, 68, 89, 106, 106, 125, 132, 137, 137, 137]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cgrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13c5443d-87b3-4cc3-88f6-46725577d510",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"<s> A senior army officer in the Democratic Republic of Congo has been accused by at least five women of ordering a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Day.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Eve.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of more than 50 women and girls in a single day.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been arrested on suspicion of raping dozens of women and girls in a single attack.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo has been accused of carrying out a mass rape in the north-eastern province of Kasai.',\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.',\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been accused of being behind a mass rape of more than 50 women in the capital, Kinshasa, on New Year's Eve.\",\n",
       " \"<s> A senior army officer in the Democratic Republic of Congo has been charged with rape, according to three women who have been treated in a hospital in the capital, Kinshasa, on New Year's Day.\",\n",
       " '<s> A senior army officer in the Democratic Republic of Congo is being investigated for alleged involvement in the rape of at least 51 women and girls.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e27f9f3-d775-497e-9272-120aeedc75f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for 100 examples, generate diverse options (up to 20), score each of them\n",
    "SET = 100\n",
    "i = 0\n",
    "while SET>0:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a8109df-b81f-4717-a3b2-8a29de29523d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8467394-8aa5-408f-ac52-ee60b5611b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"outputs/graph_pickles/exploded_mtfren_beam12/0\", \"rb\") as file:\n",
    "    res = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2675fcd5-d945-409d-b93c-654351f05ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A slow new year for the world economy',\n",
       " 'A new slow year for the world economy',\n",
       " 'A slow new year for the global economy',\n",
       " 'A new slow year for the global economy',\n",
       " 'A Slow New Year for the World Economy',\n",
       " 'A New Slow Year for the World Economy',\n",
       " 'A Slow New Year for the Global Economy',\n",
       " 'A New Slow Year for the Global Economy',\n",
       " 'A slow new year for the world economy.',\n",
       " 'A slow new year for the global economy.',\n",
       " 'A new slow year for the world economy.',\n",
       " 'A new slow year for the global economy.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "03a133b4-2d37-4e3c-9efe-71660394af92",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_ind_diverse(0, \"utnoun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550ab83f-7047-4b5f-8ce9-7f300c8c8f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cands = [r[4:] for r in res[2][2]]\n",
    "scos = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "abdab085-3e02-4414-9ec5-e75b0a4e39de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO put elsewhere - make batched version of get_hyp_sco (TODO also do dataloader setup or smth)\n",
    "def causalmask (a, dev):\n",
    "    masksdef = torch.zeros((a.shape[0], a.shape[1],a.shape[1]), device=dev)\n",
    "    for i in range(len(a)):\n",
    "        lim = int(torch.sum(a[i]))\n",
    "        masksdef[i, :lim, :lim] = torch.tril(torch.ones((lim, lim)))\n",
    "    return masksdef\n",
    "\n",
    "def batch_hyp_sco(srcs, hyps, metric):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "    \n",
    "    out_toks = tok(hyps, return_tensors='pt', padding=True, truncation=True).to(dev)\n",
    "    out_tokens = out_toks.input_ids\n",
    "    hypmask = causalmask(out_toks.attention_mask, device)\n",
    "    \n",
    "    positionids = None\n",
    "    toked_inp = tok(srcs, return_tensors=\"pt\").to(dev)\n",
    "    \n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, out_tokens, positionids, \\\n",
    "        hypmask)\n",
    "    \n",
    "    return torch.sum(predout['score'], 1)#, toked_inp, out_tokens, positionids, hypmask\n",
    "    \n",
    "# get token level scores from model, given hypothesis and input source\n",
    "def get_hyp_sco(inphyp, inpsrc, args):\n",
    "    tok = args['tok']\n",
    "    dev = args['device']\n",
    "    model = args['model']\n",
    "\n",
    "    # calculate inputs\n",
    "    tokens = tok(inphyp, return_tensors='pt', truncation=True).to(dev)\n",
    "    tokens = tokens.input_ids\n",
    "    positionids = None\n",
    "    toked_inp = tok([inpsrc], return_tensors=\"pt\").to(dev)\n",
    "    # get causal mask\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(dev)\n",
    "    # run through model\n",
    "    predout = model(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    return torch.sum(predout['score'])#, toked_inp, tokens, positionids, tmpmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4348518d-e7c5-4e4f-8775-96ee787f9ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(2, 3, 1)\n",
    "b = torch.ones(2)/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6f34c1eb-2f3c-46e3-84ca-deee68e33d22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a/b.unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b0af82a9-0d33-4fab-9fb8-789ab0f0034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "btest = batch_hyp_sco([\"noun\"]*10, cands, args)\n",
    "htest = get_hyp_sco(cands[3], \"noun\", args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e2bcd0b-1425-4de7-9a52-3f29d5e97c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "22332ce9-9a1d-4aad-b192-68640e8971eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = explode_df.loc[:32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "558da394-3b6f-4432-9731-2dd96084d15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05416083335876465\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "batch_hyp_sco([\"noun\"]*len(tmp), list(tmp['hyp']), args)\n",
    "tot = time.time()-s\n",
    "print(tot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c61b7887-395a-48c9-bfff-8f1e10bb99c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>hyp</th>\n",
       "      <th>utnounprev</th>\n",
       "      <th>unique_nouns</th>\n",
       "      <th>utnoun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The gunmen had approached the restaurant from ...</td>\n",
       "      <td>Somali security forces have retaken control of...</td>\n",
       "      <td>Somali troops have killed all the militants wh...</td>\n",
       "      <td>0.512872</td>\n",
       "      <td>6</td>\n",
       "      <td>0.542059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The gunmen had approached the restaurant from ...</td>\n",
       "      <td>Somali security forces have retaken control of...</td>\n",
       "      <td>Somalia's security forces have killed all the ...</td>\n",
       "      <td>0.682395</td>\n",
       "      <td>7</td>\n",
       "      <td>0.720953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The gunmen had approached the restaurant from ...</td>\n",
       "      <td>Somali security forces have retaken control of...</td>\n",
       "      <td>Somali security forces have killed all the mil...</td>\n",
       "      <td>0.633267</td>\n",
       "      <td>7</td>\n",
       "      <td>0.672587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The gunmen had approached the restaurant from ...</td>\n",
       "      <td>Somali security forces have retaken control of...</td>\n",
       "      <td>Somali forces have killed all the militants wh...</td>\n",
       "      <td>0.540708</td>\n",
       "      <td>6</td>\n",
       "      <td>0.573508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                src  \\\n",
       "0           0  The gunmen had approached the restaurant from ...   \n",
       "1           1  The gunmen had approached the restaurant from ...   \n",
       "2           2  The gunmen had approached the restaurant from ...   \n",
       "3           3  The gunmen had approached the restaurant from ...   \n",
       "\n",
       "                                                 ref  \\\n",
       "0  Somali security forces have retaken control of...   \n",
       "1  Somali security forces have retaken control of...   \n",
       "2  Somali security forces have retaken control of...   \n",
       "3  Somali security forces have retaken control of...   \n",
       "\n",
       "                                                 hyp  utnounprev  \\\n",
       "0  Somali troops have killed all the militants wh...    0.512872   \n",
       "1  Somalia's security forces have killed all the ...    0.682395   \n",
       "2  Somali security forces have killed all the mil...    0.633267   \n",
       "3  Somali forces have killed all the militants wh...    0.540708   \n",
       "\n",
       "   unique_nouns    utnoun  \n",
       "0             6  0.542059  \n",
       "1             7  0.720953  \n",
       "2             7  0.672587  \n",
       "3             6  0.573508  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fb50fac-0eba-4535-b7de-9603cdb66b2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.3034],\n",
       "        [1.1236],\n",
       "        [1.2539],\n",
       "        [1.3034],\n",
       "        [0.9848],\n",
       "        [0.9704],\n",
       "        [0.8752],\n",
       "        [1.2966],\n",
       "        [0.8793],\n",
       "        [1.3001]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0fa212be-14d8-4c84-b861-934f78322265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.3034, device='cuda:2', grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e7f1ff06-a3ef-4189-ac24-b89bfd2d6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpstmp = btest[1].input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0d8c1962-2723-409e-8e39-3b4e12e0ee97",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [47]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43minpstmp\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax\u001b[49m\u001b[43m(\u001b[49m\u001b[43minpstmp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "inpstmp/(torch.max(inpstmp, 1).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a6011385-1b23-4a7c-a871-00c6cadf2c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2],\n",
       "        [  0, 110, 309,   2]], device='cuda:2')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpstmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e34932db-97e9-4b02-b7c1-5b057fe225e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2586, 1.3145, 1.6432, 1.7925, 1.4084, 1.3145, 1.8486, 1.6901, 1.3145,\n",
       "         1.8486],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.7550, 0.7885, 0.9856, 1.0752, 0.8448, 0.7885, 1.1088, 1.0138, 0.7885,\n",
       "         1.1088],\n",
       "        [0.6813, 0.7116, 0.8895, 0.9704, 0.7624, 0.7116, 1.0007, 0.9149, 0.7116,\n",
       "         1.0007],\n",
       "        [1.1618, 1.2134, 1.5167, 1.6546, 1.3001, 1.2134, 1.7063, 1.5601, 1.2134,\n",
       "         1.7063],\n",
       "        [1.2415, 1.2966, 1.6208, 1.7681, 1.3893, 1.2966, 1.8234, 1.6671, 1.2966,\n",
       "         1.8234],\n",
       "        [0.5986, 0.6253, 0.7816, 0.8526, 0.6699, 0.6253, 0.8793, 0.8039, 0.6253,\n",
       "         0.8793],\n",
       "        [0.6517, 0.6807, 0.8509, 0.9282, 0.7293, 0.6807, 0.9572, 0.8752, 0.6807,\n",
       "         0.9572],\n",
       "        [1.2479, 1.3034, 1.6292, 1.7773, 1.3965, 1.3034, 1.8329, 1.6758, 1.3034,\n",
       "         1.8329],\n",
       "        [0.5926, 0.6189, 0.7737, 0.8440, 0.6632, 0.6189, 0.8704, 0.7958, 0.6189,\n",
       "         0.8704]], device='cuda:2', grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "btest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8f77f316-816b-4fe5-963b-2336d2004c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 0., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 0.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]], device='cuda:2')"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htest[4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b6d1e9-c17b-4aed-b3e9-218e3be4343d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
