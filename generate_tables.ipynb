{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfc22724-2b2f-466c-97dd-6e3d360c25ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-05 10:41:57.529243: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-05 10:41:57.529265: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from process_traindata import lset_to_explodeddf, load_cands, create_sortedbatch_data\n",
    "from new_mt_train import XLMCometRegressorAvg, XLMCometRegressor\n",
    "from mt_scores import get_scores_auto\n",
    "import torch\n",
    "import pandas as pd\n",
    "from os.path import exists\n",
    "import baseline_cands as bc\n",
    "#from rerank_data import rerank_df, rerank_nogold, rerank_single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c26ba23-70b6-4d34-b550-a0d007e773af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS TO GENERATING COMPLETE SET OF TABLES - \n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "# 1. Get a distilled causal model\n",
    "BESTMODS = {\n",
    "    'en_de_comet': 'derlcausalfine45.pt',\n",
    "    'fr_en_comet': 'maskedcont4.pt',\n",
    "    'fr_en_bleurt': 'frenbleurtfine5.pt'\n",
    "}\n",
    "SETTING = 'en_de_comet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56d8b7d5-7b23-41c8-a7a1-8970c4861f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "if SETTING == 'fr_en_comet':\n",
    "    model = XLMCometRegressor(drop_rate=0.1).to(device)\n",
    "else:\n",
    "    model = XLMCometRegressorAvg(drop_rate=0.1).to(device)\n",
    "model.load_state_dict(torch.load('torchsaved/'+BESTMODS[SETTING]))\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7af344e8-b0d2-4cd1-94b7-5aed8c4063b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Have a test set with post-hoc, distilled model score, gold score, 32 samples per example\n",
    "\n",
    "# ASSUME that we'vePAIRalled create_sortedbatch_data for our data\n",
    "def load_dset_existing(pairname, goldsco):\n",
    "    datacsv = None\n",
    "    if goldsco== \"comet\":\n",
    "        datacsv = pd.read_csv(\"torchsaved/cometen_detrain.csv\")\n",
    "        #extracsv = pd.read_csv(\"torchsaved/cqeen_detrain.csv\")\n",
    "        # since we have for comet and for cqe\n",
    "        datacsv['comet'] = datacsv['score']\n",
    "        #datacsv['cqe'] = extracsv['score']\n",
    "    elif goldsco == \"bleurt\":\n",
    "        datacsv = pd.read_csv(\"torchsaved/bleurten_detrain.csv\")\n",
    "    \n",
    "    return datacsv.drop(columns=['score', 'Unnamed: 0'])\n",
    "        \n",
    "TRAINSET_NAMES = {\n",
    "    'en_de_comet': 'cometen_detrain.csv',\n",
    "    'fr_en_comet': 'cometen_detrain.pt',\n",
    "    'fr_en_bleurt': 'frenbleurtfine5.pt'\n",
    "}\n",
    "\n",
    "PAIR = 'en_de'\n",
    "SCORER = 'comet'\n",
    "SPLIT = .9\n",
    "\n",
    "if exists(\"torchsaved/testdata\"+PAIR+SCORER+\".csv\"):\n",
    "    testset = pd.read_csv(\"torchsaved/testdata\"+PAIR+SCORER+\".csv\")\n",
    "else:\n",
    "\n",
    "    testset = load_dset_existing(PAIR, SCORER)\n",
    "    testset = testset.iloc[int(len(testset)*SPLIT/32)*32:]\n",
    "\n",
    "    hyps, srcs, refs = list(testset['hyp']), list(testset['src']), list(testset['ref'])\n",
    "    # get cqe, post-hoc score, distilled model score (already have gold)\n",
    "    with torch.no_grad():\n",
    "        utmod = get_scores_auto(hyps, srcs, refs, \"custom\", model)\n",
    "        cqe = get_scores_auto(hyps, srcs, refs, \"cqe\", \"\")\n",
    "        posthoc = get_scores_auto(hyps, srcs, refs, \"posthoc\", PAIR)\n",
    "\n",
    "    testset['utscore'] = utmod\n",
    "    testset['cqe'] = cqe\n",
    "    testset['posthoc'] = posthoc\n",
    "    testset.to_csv(\"torchsaved/testdata\"+PAIR+SCORER+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9db740bc-6d01-4389-9aa1-88f3724b2fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c775c90-84b2-4160-9b25-fd665eace5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rerank batch based on some metric\n",
    "def rerank_single(selected, metric, target):\n",
    "    if metric==\"posthoc\":\n",
    "        mbind = np.argmin(selected[metric])\n",
    "    else:\n",
    "        mbind = np.argmax(selected[metric])\n",
    "    return list(selected[target])[mbind]\n",
    "\n",
    "# rerank single but ignore last thing in each batch\n",
    "def rerank_nogold(selected, metric, target):\n",
    "    if metric==\"posthoc\":\n",
    "        mbind = np.argmin(list(selected[metric])[:-1])\n",
    "    else:\n",
    "        mbind = np.argmax(list(selected[metric])[:-1])\n",
    "    return list(selected[target])[mbind]\n",
    "\n",
    "# rerank single but ignore last thing in each batch\n",
    "def rerank_nogweight(selected, metric, target):\n",
    "    met = list(selected[metric])\n",
    "    phoc = list(selected['posthoc'])\n",
    "    newvec = [met[i]*.9-phoc[i]*1.25 for i in range(len(met))]\n",
    "    mbind = np.argmax(newvec[:-1])\n",
    "    return list(selected[target])[mbind]\n",
    "\n",
    "# TODO changes for with / without gold\n",
    "def rerank_weighted(selected, metric, target):\n",
    "    met = list(selected[metric])\n",
    "    phoc = list(selected['posthoc'])\n",
    "    newvec = [met[i]*.9-phoc[i]*1.25 for i in range(len(met))]\n",
    "    mbind = np.argmax(newvec)\n",
    "    return list(selected[target])[mbind]\n",
    "\n",
    "def rerank_rand(selected, metric, target):\n",
    "    return random.choice(list(selected[target])[:-1])\n",
    "\n",
    "def rerank_df(df, scofunct, scoparam):\n",
    "    reflist = list(df['ref'].unique())\n",
    "    rrdf = []\n",
    "    for r in reflist:\n",
    "        # extract dataframe corresponding to smth\n",
    "        exsamps = df[df['ref']==r]\n",
    "        rrdf.append(scofunct(exsamps, scoparam[0], scoparam[1]))\n",
    "    return sum(rrdf)/len(rrdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fca0d24b-8a2a-4b6f-8f73-95e84512f591",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bcdf50 = pd.read_csv(\"torchsaved/bc50en_decomet.csv\")\n",
    "bcdf50 = pd.read_csv(\"testbeam50fr_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9db4288-a96a-46c2-9e8b-7922ce30c54e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#latencheck = pd.read_csv(\"torchsaved/testdataen_decomet.csv\")\n",
    "frtest = pd.read_csv(\"torchsaved/testdatafr_encomet.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b76d14ee-843d-4be6-b012-1182975a653b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0.6', 'Unnamed: 0.5', 'Unnamed: 0.4', 'Unnamed: 0.3',\n",
       "       'level_0', 'Unnamed: 0.2', 'index', 'Unnamed: 0.1', 'Unnamed: 0', 'src',\n",
       "       'hyp', 'ref', 'utscore', 'cqe', 'posthoc', 'comet', 'dupcqe'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bcdf50.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e81f272f-6628-4e66-9877-25df401af583",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6923318155736187"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank_df(bcdf50, rerank_weighted, ['cqe', 'comet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d613156-e2a6-4fe1-82d7-95804d248a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. For a smaller set, get exploded stuff and run stuff from above on that\n",
    "MINISET = 100\n",
    "exploded_dirs = {\n",
    "    \"en_de\":\"./candoutputs/explodedmt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.904_0.0_0.9.jsonl\",\n",
    "    \"fr_en\":\"./candoutputs/explodedmtn1_fr-en_bfs_recom_4_-1_False_0.4_True_False_4_5_rcb_0.904_0.0_0.9.jsonl\",\n",
    "    \"en_deb1\":\"./candoutputs/testbeam1en_de.jsonl\",\n",
    "    \"en_deb50\":\"./candoutputs/testbeam50en_de.jsonl\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081af570-1c8a-4927-80d3-9093bb667536",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1c7a3c-9819-4c26-abc1-da020bb2e8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if exists(\"torchsaved/exlpodedmini\"+PAIR+SCORER+\".csv\"):\n",
    "    expdf = pd.read_csv(\"torchsaved/exlpodedmini\"+PAIR+SCORER+\".csv\")\n",
    "else:\n",
    "    lcands = load_cands(exploded_dirs[PAIR])\n",
    "    lcands = lcands[-100:]\n",
    "    len(lcands)\n",
    "    expdf = lset_to_explodeddf(lcands)\n",
    "\n",
    "    hyps, srcs, refs = list(expdf['hyp']), list(expdf['src']), list(expdf['ref'])\n",
    "    # get cqe, post-hoc score, distilled model score (already have gold)\n",
    "    with torch.no_grad():\n",
    "        utmode = get_scores_auto(hyps, srcs, refs, \"custom\", model)\n",
    "        golde = get_scores_auto(hyps, srcs, refs, \"comet\", \"\")\n",
    "        cqee = get_scores_auto(hyps, srcs, refs, \"cqe\", \"\")\n",
    "        posthoce = get_scores_auto(hyps, srcs, refs, \"posthoc\", PAIR)\n",
    "\n",
    "    expdf['utscore'] = utmode\n",
    "    expdf['cqe'] = cqee\n",
    "    expdf['posthoc'] = posthoce\n",
    "    expdf['comet'] = golde\n",
    "\n",
    "    expdf.to_csv(\"torchsaved/exlpodedmini\"+PAIR+SCORER+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "871c428d-4acb-4548-a7e9-553a8815506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1050"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset['src'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a49557a7-351a-4328-b805-666e0e90902d",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8727e4-2915-4b54-bc1a-e49443f6b9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import baseline_cands as bc\n",
    "# 4. Get beam search 1 and beam search 50 for these\n",
    "if exists(\"./candoutputs/testbeam\"+str(50)+PAIR+\".jsonl\"):\n",
    "    print(\"already generated\")\n",
    "else:\n",
    "    btok, bmodel = bc.load_model(PAIR, \"cuda:2\")\n",
    "    bmodel.eval()\n",
    "    with torch.no_grad():\n",
    "        bscands = bc.get_generate_candidates(bc.beam_generate, list(testset['src'].unique()), list(testset['ref'].unique())\n",
    "                    , btok, bmodel, 50, 1, PAIR, \"cuda:2\", \"beam\", 80)\n",
    "        bscands = bc.get_generate_candidates(bc.beam_generate, list(testset['src'].unique()), list(testset['ref'].unique())\n",
    "                    , btok, bmodel, 1, 1, PAIR, \"cuda:2\", \"beam\", 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1206c642-9616-4536-a3b0-2b1f43dae43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_scores(inpdf):\n",
    "    hyps, srcs, refs = list(inpdf['hyp']), list(inpdf['src']), list(inpdf['ref'])\n",
    "    # get cqe, post-hoc score, distilled model score (already have gold)\n",
    "    with torch.no_grad():\n",
    "        utmode = get_scores_auto(hyps, srcs, refs, \"custom\", model)\n",
    "        golde = get_scores_auto(hyps, srcs, refs, \"comet\", \"\")\n",
    "        cqee = get_scores_auto(hyps, srcs, refs, \"cqe\", \"\")\n",
    "        posthoce = get_scores_auto(hyps, srcs, refs, \"posthoc\", PAIR)\n",
    "\n",
    "    inpdf['utscore'] = utmode\n",
    "    inpdf['cqe'] = cqee\n",
    "    inpdf['posthoc'] = posthoce\n",
    "    inpdf['comet'] = golde\n",
    "    return inpdf\n",
    "\n",
    "# 4.5 Generate appropriate scores for these candidates\n",
    "bcdf1 = lset_to_explodeddf(load_cands(exploded_dirs[PAIR+\"b1\"]))\n",
    "bcdf50 = lset_to_explodeddf(load_cands(exploded_dirs[PAIR+\"b50\"]))\n",
    "# generate suite of scores\n",
    "bcdf50 = generate_scores(bcdf50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcf5602e-0588-4de6-bfce-474d31777177",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rescoring candidates\n",
      "0\n",
      "500\n",
      "1000\n",
      "TOTAL TIME  16.95\n"
     ]
    }
   ],
   "source": [
    "bcdf50.to_csv(\"torchsaved/bc50\"+PAIR+SCORER+\".csv\")\n",
    "bcdf1 = generate_scores(bcdf1)\n",
    "bcdf1.to_csv(\"torchsaved/bc1\"+PAIR+SCORER+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d625692-97da-4a97-9ceb-24bc0bf3e796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Run lattice pipeline on the whole thing, evaluate generated options\n",
    "\n",
    "# TODO for german pinpoint the right lattices"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
