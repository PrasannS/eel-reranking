{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2bc696d-e037-4ab8-beb0-b2917453b5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07651a78-03e7-4da8-a480-a1da77822bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fren = './rerank_outputs/post1explodedmtn1_fr-en_bfs_recom_4_-1_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9.json'\n",
    "ende = './rerank_outputs/post1explodedmt1n_en-de_bfs_recom_4_80_False_0.4_True_False_4_5_rcb_0.9_0.0_0.9.json'\n",
    "# Opening JSON file\n",
    "with open(fren) as json_file:\n",
    "    lat4 = json.load(json_file)['data']\n",
    "    \n",
    "with open('./rerank_outputs/post1cpybeam4fr_en.json') as json_file:\n",
    "    beam49 = json.load(json_file)['data']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "748acf7c-1398-4cb7-9545-2c61d762305f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_example(ex, topof=\"comet\"):\n",
    "    print(\"INPUT - \"+ex['src'])\n",
    "    print(\"REFERENCE - \"+ex['ref'])\n",
    "    print()\n",
    "    qebest = np.argsort(ex['qescores']).tolist()\n",
    "    combest = np.argsort(ex['cometscores']).tolist()\n",
    "    #rebest = np.argsort(ex['rescores']).tolist()\n",
    "    #mbartbest = np.argsort(ex['mbartqescores']).tolist()\n",
    "    #transqbest = np.argsort(ex['tquestscores']).tolist()\n",
    "    slen = len(ex['modelscores'])\n",
    "    try:\n",
    "        for i in range(0, 5):\n",
    "            ind = -1\n",
    "            if topof == \"cometscores\":\n",
    "                ind = combest[slen-i-1]\n",
    "            elif topof == \"qescores\":\n",
    "                ind = qebest[slen-i-1]\n",
    "            elif topof == \"rescores\":\n",
    "                ind = rebest[i]\n",
    "            elif topof == \"mbartqescores\":\n",
    "                ind = mbartbest[slen-i-1]\n",
    "            elif topof == \"tquestscores\":\n",
    "                ind = transqbest[slen-i-1]\n",
    "            else:\n",
    "                ind = i\n",
    "            print(\"QE: \"+str(ex['qescores'][ind])+\" | POST: \"+str(ex['rescores'][ind])+\" | MODEL: \"+str(ex[\"modelscores\"][ind])+\" | COMET: \"+str(ex[\"cometscores\"][ind]))\n",
    "            #print(\"MBART: \"+str(ex['mbartqescores'][ind])+\" | TRANS: \"+str(ex['tquestscores'][ind]))\n",
    "            print(ex['cands'][ind])\n",
    "            print()\n",
    "            \n",
    "    except:\n",
    "        \"\"\n",
    "        \n",
    "def topsco_avg(cand, n):\n",
    "    scores = cand['rescores']\n",
    "    if len(cand) > n:\n",
    "        scores = scores[:n]\n",
    "    return sum(scores)/len(scores)\n",
    "\n",
    "def all_topsco_distr(c_list, n):\n",
    "    topdistr = []\n",
    "    for c in c_list:\n",
    "        if len(str(c['ref']))>10 and len(str(c['src']))>10:\n",
    "            topdistr.append(topsco_avg(c, n))\n",
    "    return topdistr\n",
    "\n",
    "def print_several_examples(n, ranker):\n",
    "    for i in range(0, n):\n",
    "        print(\"LATTICE\")\n",
    "        print()\n",
    "        print_example(lat4[i], ranker)\n",
    "        print(\"BEAM\")\n",
    "        print()\n",
    "        print_example(beam49[i], ranker)\n",
    "        \n",
    "def get_pairs_complete(cands, k1, k2):\n",
    "    x = []\n",
    "    y = []\n",
    "    for c in cands:\n",
    "        x.extend(c[k1])\n",
    "        y.extend(c[k2])\n",
    "    return x, y\n",
    "\n",
    "# method returns the comet score (average for top-n) after re-ranking for an example\n",
    "def rerank_sco (ex, n, ranker):\n",
    "    rank_list = ex[ranker]\n",
    "    indlist = np.argsort(rank_list).tolist()\n",
    "    comdistr = []\n",
    "    if ranker=='rescores':\n",
    "        for i in range(0, n):\n",
    "            comdistr.append(ex['cometscores'][indlist[i]])\n",
    "    else:\n",
    "        assert len(indlist) == len(ex['cometscores'])\n",
    "        for i in range(0, n):\n",
    "            comdistr.append(ex['cometscores'][indlist[-(i+1)]])\n",
    "    return sum(comdistr)/len(comdistr)\n",
    "\n",
    "def rerank_all (cands, n, ranker):\n",
    "    rer_distr = []\n",
    "    for c in cands:\n",
    "        rer_distr.append(rerank_sco(c, n, ranker))\n",
    "    return rer_distr\n",
    "\n",
    "def get_comp_distr(before, after):\n",
    "    res = []\n",
    "    assert len(before) == len(after)\n",
    "    for i in range(0, len(before)):\n",
    "        res.append(after[i]-before[i])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f886216-ac8c-46ef-82b2-eb49c0e938fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_ref_match(cand, clist):\n",
    "    for c in clist:\n",
    "        if c['src'] == cand['src']:\n",
    "            assert c['ref'] == cand['ref']\n",
    "            return c\n",
    "    print(\"no match\")\n",
    "    return None\n",
    "\n",
    "def get_top_diff():\n",
    "    distr = []\n",
    "    latcands = []\n",
    "    bcands = []\n",
    "    lscos = []\n",
    "    bscos = []\n",
    "    for b in beam49:\n",
    "        m = find_ref_match(b, lat4)\n",
    "        val = find_ref_match(b, beam49)\n",
    "        if m is not None and val is not None:\n",
    "            mbest = min(m['rescores'])\n",
    "            bbest = min(b['rescores'])\n",
    "            if abs(mbest-bbest)<.5:\n",
    "                lscos.append(bbest)\n",
    "                bscos.append(mbest)\n",
    "                mind = m['rescores'].index(mbest)\n",
    "                bind = b['rescores'].index(bbest)\n",
    "                distr.append(mbest-bbest)\n",
    "                latcands.append(m['cands'][mind])\n",
    "                bcands.append(m['cands'][bind])\n",
    "        # print(b['src'])\n",
    "    print(len(distr))\n",
    "    return distr, latcands, bcands, lscos, bscos\n",
    "\n",
    "def print_big_diffs(d, l, b):\n",
    "    for i in range(0, len(d)):\n",
    "        if abs(d[i])>.05:\n",
    "            print()\n",
    "            print(\"Score diff\", d[i])\n",
    "            print(\"LATTICE: \", l[i])\n",
    "            print(\"BEAM SEARCH: \", b[i])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "11858d02-5492-4794-b2c9-e98e9c12eabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "0.34295325850447017\n",
      "0.351233580460151\n"
     ]
    }
   ],
   "source": [
    "#get_top_diff()\n",
    "d, l, b, latsco, bsco = get_top_diff()\n",
    "#print_big_diffs(d, l, b)\n",
    "print(mean(latsco))\n",
    "print(mean(bsco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36cb6e9-357c-4e54-a2a0-25aa68d8da97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lat4[0]['cands']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e68c616a-fe5a-46b8-bfd3-75867165dcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'rescores':0,\n",
    "    'mbartqescores':0,\n",
    "    'tquestscores':0,\n",
    "    'qescores':0, \n",
    "}\n",
    "\n",
    "scorer = \"modelscores\"\n",
    "# reranking approaches\n",
    "def rerank_thresh (ex, thresh):\n",
    "    rank_list = ex['qescores']\n",
    "    indlist = np.argsort(rank_list).tolist()\n",
    "    comdistr = []\n",
    "    assert len(indlist) == len(ex['cometscores'])\n",
    "    for i in range(0, len(indlist)):\n",
    "        if abs(ex[scorer][indlist[-(i+1)]])>thresh:\n",
    "            continue\n",
    "        return ex['cometscores'][indlist[-(i+1)]]\n",
    "    print(\"No values within thresh\")\n",
    "    return ex['cometscores'][indlist[-(i+1)]]\n",
    "\n",
    "def rerank_weighted (ex, weights):\n",
    "    \n",
    "    resultvec = []\n",
    "    for i in range(0, len(ex['cands'])):\n",
    "        score = 0\n",
    "        for w in weights.keys():\n",
    "            score+=ex[w][i]*weights[w]\n",
    "        resultvec.append(score)\n",
    "    indlist = np.argsort(resultvec).tolist()\n",
    "    return ex['cometscores'][indlist[-1]]\n",
    "\n",
    "def rerank_all_thresh (cands, thresh):\n",
    "    rer_distr = []\n",
    "    for c in cands:\n",
    "        rer_distr.append(rerank_thresh(c, thresh))\n",
    "    return rer_distr\n",
    "\n",
    "bad = []\n",
    "def rerank_all_weighted (cands, weights):\n",
    "    global bad\n",
    "    rer_distr = []\n",
    "    num = 0\n",
    "    ind = 0\n",
    "    for c in cands:\n",
    "        m = find_ref_match(c, beam49)\n",
    "        l = find_ref_match(c, lat4)\n",
    "        if m is not None and l is not None:\n",
    "            if len(str(c['src']))>10:\n",
    "                rer_distr.append(rerank_weighted(c, weights))\n",
    "                num+=1\n",
    "        ind+=1\n",
    "    print(num)\n",
    "    return rer_distr\n",
    "\n",
    "def mean(l):\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "maxweights = []\n",
    "maxsco = 0\n",
    "def weights_rer_search(weightarr, *args):\n",
    "    global maxsco\n",
    "    global maxweights\n",
    "    weightvals = weights\n",
    "    i = 0\n",
    "    for w in weights.keys():\n",
    "        weightvals[w] = weightarr[i]\n",
    "        i+=1\n",
    "        if i==len(weightarr):\n",
    "            break\n",
    "    #print(args[0])\n",
    "    #print(len(args))\n",
    "    val = -1*mean(rerank_all_weighted(args[0], weightvals))\n",
    "    if val<maxsco:\n",
    "        maxsco = val\n",
    "        maxweights = weightarr\n",
    "    return val\n",
    "\n",
    "def manual_search(cands):\n",
    "    mval = -1\n",
    "    mweights = []\n",
    "    for i in range(0, 5):\n",
    "        for j in range(0, 5):\n",
    "            for k in range(0, 5):\n",
    "                weightvec = [-1.25, 0.0+0.1*i, 0.1*j, 0.5+0.1*k]\n",
    "                weightvals = weights\n",
    "                i = 0\n",
    "                for w in weights.keys():\n",
    "                    weightvals[w] = weightvec[i]\n",
    "                    i+=1\n",
    "                    if i==len(weightvec):\n",
    "                        break\n",
    "                val = mean(rerank_all_weighted(cands, weightvals))\n",
    "                if val > mval:\n",
    "                    mval = val\n",
    "                    mweights = weightvec\n",
    "                    print(mval)\n",
    "    return mval, mweights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a71269-051a-4e9b-bf21-2b806e83ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestsco, bestweights = manual_search(lat4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f810cd3f-24f0-44d1-977a-35055d06aa86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7735961552451153"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestsco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "63d339f8-d404-44e2-8b93-25b327fd901f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_greedy(cands):\n",
    "    cnt = 0\n",
    "    tot = 0\n",
    "    for c in cands:\n",
    "        if len(c['rescores'])>0:\n",
    "            tot+=c['rescores'][0]\n",
    "            cnt+=1\n",
    "    return tot/cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fb7d35c3-afab-451d-8a98-682e5404f8cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34844683576375246"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(all_topsco_distr(beam49, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dfcf69c8-fa6e-4647-9cd7-23c148a87798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7791122259416928"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#rranges = (slice(-2, 0, 0.5), slice(0, .5, 0.5), slice(0, .5, 0.5), slice(0, .5, 0.5), slice(0, 2, 0.5))\n",
    "#resbrute = optimize.brute(weights_rer_search, rranges, args=(lat4,), full_output=True, finish=optimize.fmin, disp=True)\n",
    "\n",
    "mean(rerank_all_weighted(beam49, {\n",
    "    'rescores':0,\n",
    "    #'mbartqescores':0,\n",
    "    #'tquestscores':0,\n",
    "    'qescores':1, \n",
    "    'cometscores':0,\n",
    "    'modelscores':0\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1fac2368-ead5-431f-a4a3-938946f0ae08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-2.04e+00, -2.50e-04,  1.00e-04,  1.00e-04,  1.00e-04])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def manual_search():\n",
    "    global weights\n",
    "    for "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1c236f93-b329-497c-844b-56f88907cf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([15., 62., 15.,  6.,  1.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,\n",
       "         0.,  0.,  0.,  0.,  0.,  0.,  1.]),\n",
       " array([-0.0917402 , -0.02910655,  0.03352709,  0.09616074,  0.15879438,\n",
       "         0.22142803,  0.28406168,  0.34669532,  0.40932897,  0.47196261,\n",
       "         0.53459626,  0.5972299 ,  0.65986355,  0.72249719,  0.78513084,\n",
       "         0.84776449,  0.91039813,  0.97303178,  1.03566542,  1.09829907,\n",
       "         1.16093271]),\n",
       " <BarContainer object of 20 artists>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "a = rerank_all(beam49, 10, \"qescores\")\n",
    "b = rerank_all(beam49, 10, \"rescores\")\n",
    "comp = get_comp_distr(b, a)\n",
    "plt.hist(comp, bins =20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7297dad6-2619-4f3e-aed8-4049ece2b250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.027135396971929782\n"
     ]
    }
   ],
   "source": [
    "print(sum(comp)/len(comp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7bdf6e62-5fff-4cf2-a12c-911833e777b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = get_pairs_complete(lat4, \"modelscores\", \"rescores\")\n",
    "  \n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c0a600a8-b278-4301-97a6-853dd713810f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#x, y = get_pairs_complete(beam49, \"modelscores\", \"cometscores\")\n",
    "\n",
    "heatmap, xedges, yedges = np.histogram2d(x, y, bins=(10, 10))\n",
    "extent = [xedges[0], xedges[-1], yedges[0], yedges[-1]]\n",
    "\n",
    "plt.clf()\n",
    "plt.imshow(heatmap.T, extent=extent, origin='lower')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e8f76482-81c7-4a9f-9c3f-a0147c1ebf38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([16., 27., 22., 15.,  9.,  4.,  4.,  2.,  0.,  2.]),\n",
       " array([0.47536054, 0.56476725, 0.65417396, 0.74358066, 0.83298737,\n",
       "        0.92239407, 1.01180078, 1.10120748, 1.19061419, 1.2800209 ,\n",
       "        1.3694276 ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "bdistr = all_topsco_distr(beam49, 20)\n",
    "latdistr = all_topsco_distr(lat4, 20)\n",
    "plt.hist(latdistr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eebcfff2-27a9-49b0-b116-e97603cb99a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7219551513372303"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(latdistr)/len(latdistr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20dce9e2-0991-4419-8148-e09ec3ddef35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4211500431189852"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bdistr)/len(bdistr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbba863-8735-4856-9f26-0eec861dc2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "dev = \"cuda:3\"\n",
    "mname = \"facebook/mbart-large-50-one-to-many-mmt\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(mname)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(mname)\n",
    "tok = AutoTokenizer.from_pretrained(mname, src_lang='en_XX', tgt_lang='de_DE')\n",
    "model.to(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fcfc7b42-a3a1-490c-bc8e-1fbb85a49f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sanity_beam(ind, lcode='de_DE', beams=4, mlen=80):\n",
    "    \n",
    "    model_inputs = tokenizer([beam49[ind]['src']], return_tensors=\"pt\", truncation=True, padding=True).to(dev)\n",
    "    outs = model.generate(\n",
    "        **model_inputs,\n",
    "        forced_bos_token_id=tokenizer.lang_code_to_id[lcode],\n",
    "        num_beams=beams,\n",
    "        max_length=mlen, \n",
    "        num_return_sequences=beams,\n",
    "        return_dict_in_generate=True,\n",
    "        output_scores=True,\n",
    "    )\n",
    "    \n",
    "    print(outs.sequences_scores)\n",
    "    print(beam49[ind]['modelscores'])\n",
    "    print(beam49[ind]['rescores'])\n",
    "    inputs = tokenizer(beam49[ind]['src'], return_tensors=\"pt\").to(dev)\n",
    "    for c in beam49[ind]['cands']:\n",
    "        #print(inputs)\n",
    "        with tok.as_target_tokenizer():\n",
    "            labels = tok([c], return_tensors=\"pt\").to(dev)\n",
    "        output = model(**inputs, labels=labels.input_ids)\n",
    "        print(output.loss)\n",
    "    mis = 0\n",
    "    m = np.argsort(beam49[ind]['modelscores']).tolist()\n",
    "    print(m)\n",
    "    t = np.argsort(beam49[ind]['rescores']).tolist()\n",
    "    t.reverse()\n",
    "    print(t)\n",
    "    return t==m\n",
    "\n",
    "def sanity_lattice(ind, lcode='de_DE', beams=4, mlen=80):\n",
    "    \n",
    "    #print(outs.sequences_scores)\n",
    "    #print(lat4[ind]['modelscores'])\n",
    "    #print(lat4[ind]['rescores'])\n",
    "    inputs = tokenizer(lat4[ind]['src'], return_tensors=\"pt\").to(dev)\n",
    "    for c in lat4[ind]['cands'][:10]:\n",
    "        #print(inputs)\n",
    "        with tok.as_target_tokenizer():\n",
    "            labels = tok([c], return_tensors=\"pt\").to(dev)\n",
    "        output = model(**inputs, labels=labels.input_ids)\n",
    "        #print(output.loss)\n",
    "    m = np.argsort(lat4[ind]['modelscores']).tolist()\n",
    "    #print(m)\n",
    "    t = np.argsort(lat4[ind]['rescores']).tolist()\n",
    "    t.reverse()\n",
    "    #print(t)\n",
    "    print(t[:5])\n",
    "    print(m[-5:])\n",
    "    return t[:5]==m[-5:]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "07513c24-13b1-45d3-bb42-2ec1a8efa736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[928, 1013, 1015, 891, 908]\n",
      "[4, 3, 2, 1, 0]\n",
      "1\n",
      "[4739, 4689, 4113, 4062, 4532]\n",
      "[4, 3, 2, 1, 0]\n",
      "2\n",
      "[112, 75, 68, 117, 116]\n",
      "[4, 3, 2, 1, 0]\n",
      "3\n",
      "[2873, 2872, 2795, 2764, 2871]\n",
      "[4, 3, 2, 1, 0]\n",
      "4\n",
      "[471, 462, 469, 458, 467]\n",
      "[4, 3, 2, 1, 0]\n",
      "5\n",
      "[4207, 4268, 4254, 2764, 3777]\n",
      "[4, 3, 2, 1, 0]\n",
      "6\n",
      "[1225, 1227, 1205, 1207, 1140]\n",
      "[4, 3, 2, 1, 0]\n",
      "7\n",
      "[835, 833, 834, 832, 831]\n",
      "[4, 3, 2, 1, 0]\n",
      "8\n",
      "[6190, 6178, 6139, 5635, 6106]\n",
      "[4, 3, 2, 1, 0]\n",
      "9\n",
      "[552, 423, 565, 578, 574]\n",
      "[4, 3, 2, 1, 0]\n",
      "10\n",
      "[1460, 1470, 1458, 1425, 1464]\n",
      "[4, 3, 2, 1, 0]\n",
      "11\n",
      "[641, 636, 643, 633, 607]\n",
      "[4, 3, 2, 1, 0]\n",
      "12\n",
      "[7369, 8375, 8096, 5174, 5430]\n",
      "[4, 3, 2, 1, 0]\n",
      "13\n",
      "[2036, 1819, 1785, 1806, 1752]\n",
      "[4, 3, 2, 1, 0]\n",
      "14\n",
      "[4590, 4406, 3818, 4157, 4545]\n",
      "[4, 3, 2, 1, 0]\n",
      "15\n",
      "[1608, 1590, 1587, 1564, 1434]\n",
      "[4, 3, 2, 1, 0]\n",
      "16\n",
      "[735, 972, 962, 838, 847]\n",
      "[4, 3, 2, 1, 0]\n",
      "17\n",
      "[3841, 3752, 5824, 3852, 5821]\n",
      "[4, 3, 2, 1, 0]\n",
      "18\n",
      "[1322, 1338, 1396, 1398, 1399]\n",
      "[4, 3, 2, 1, 0]\n",
      "19\n",
      "[419, 393, 263, 538, 487]\n",
      "[4, 3, 2, 1, 0]\n",
      "20\n",
      "[2353, 2319, 2371, 2282, 2129]\n",
      "[4, 3, 2, 1, 0]\n",
      "21\n",
      "[1804, 2415, 1668, 2360, 2271]\n",
      "[4, 3, 2, 1, 0]\n",
      "22\n",
      "[950, 986, 976, 975, 935]\n",
      "[4, 3, 2, 1, 0]\n",
      "23\n",
      "[868, 798, 835, 866, 856]\n",
      "[4, 3, 2, 1, 0]\n",
      "24\n",
      "[311, 305, 275, 292, 278]\n",
      "[4, 3, 2, 1, 0]\n",
      "25\n",
      "[2011, 2128, 2480, 1855, 1954]\n",
      "[4, 3, 2, 1, 0]\n",
      "26\n",
      "[5528, 5535, 5556, 5534, 5439]\n",
      "[4, 3, 2, 1, 0]\n",
      "27\n",
      "[318, 325, 319, 326, 304]\n",
      "[4, 3, 2, 1, 0]\n",
      "28\n",
      "[2027, 2067, 1687, 1965, 1878]\n",
      "[4, 3, 2, 1, 0]\n",
      "29\n",
      "[2374, 2711, 2639, 2212, 2863]\n",
      "[4, 3, 2, 1, 0]\n",
      "30\n",
      "[1610, 1620, 1592, 1533, 1520]\n",
      "[4, 3, 2, 1, 0]\n",
      "31\n",
      "[916, 898, 883, 851, 907]\n",
      "[4, 3, 2, 1, 0]\n",
      "32\n",
      "[501, 511, 504, 537, 543]\n",
      "[4, 3, 2, 1, 0]\n",
      "33\n",
      "[5798, 5795, 5792, 5799, 5793]\n",
      "[4, 3, 2, 1, 0]\n",
      "34\n",
      "[687, 686, 680, 679, 670]\n",
      "[4, 3, 2, 1, 0]\n",
      "35\n",
      "[3020, 3015, 2998, 2995, 2913]\n",
      "[4, 3, 2, 1, 0]\n",
      "36\n",
      "[1380, 1421, 1363, 1190, 1338]\n",
      "[4, 3, 2, 1, 0]\n",
      "37\n",
      "[1233, 1171, 1256, 1204, 1168]\n",
      "[4, 3, 2, 1, 0]\n",
      "38\n",
      "[1032, 1145, 1362, 1494, 1278]\n",
      "[4, 3, 2, 1, 0]\n",
      "39\n",
      "[277, 301, 276, 275, 298]\n",
      "[4, 3, 2, 1, 0]\n",
      "40\n",
      "[1630, 774, 1031, 1126, 1713]\n",
      "[4, 3, 2, 1, 0]\n",
      "41\n",
      "[515, 513, 506, 486, 489]\n",
      "[4, 3, 2, 1, 0]\n",
      "42\n",
      "[5529, 5519, 5135, 5594, 5126]\n",
      "[4, 3, 2, 1, 0]\n",
      "43\n",
      "[651, 559, 790, 864, 802]\n",
      "[4, 3, 2, 1, 0]\n",
      "44\n",
      "[8560, 8485, 8310, 8169, 8478]\n",
      "[4, 3, 2, 1, 0]\n",
      "45\n",
      "[1299, 932, 1279, 429, 1227]\n",
      "[4, 3, 2, 1, 0]\n",
      "46\n",
      "[673, 674, 672, 663, 669]\n",
      "[4, 3, 2, 1, 0]\n",
      "47\n",
      "[339, 238, 404, 646, 636]\n",
      "[4, 3, 2, 1, 0]\n",
      "48\n",
      "[810, 676, 806, 773, 587]\n",
      "[4, 3, 2, 1, 0]\n",
      "49\n",
      "[1676, 1675, 1674, 1673, 1671]\n",
      "[4, 3, 2, 1, 0]\n",
      "50\n",
      "[1021, 970, 874, 936, 906]\n",
      "[4, 3, 2, 1, 0]\n",
      "51\n",
      "[911, 1483, 1358, 1021, 726]\n",
      "[4, 3, 2, 1, 0]\n",
      "52\n",
      "[4675, 4139, 3956, 4190, 4853]\n",
      "[4, 3, 2, 1, 0]\n",
      "53\n",
      "[3115, 3114, 2771, 2774, 3342]\n",
      "[4, 3, 2, 1, 0]\n",
      "54\n",
      "[1833, 1812, 1784, 1097, 1801]\n",
      "[4, 3, 2, 1, 0]\n",
      "55\n",
      "[2200, 3042, 3024, 3049, 3031]\n",
      "[4, 3, 2, 1, 0]\n",
      "56\n",
      "[1505, 1504, 1495, 1498, 1501]\n",
      "[4, 3, 2, 1, 0]\n",
      "57\n",
      "[3887, 3899, 3624, 3564, 3836]\n",
      "[4, 3, 2, 1, 0]\n",
      "58\n",
      "[288, 294, 269, 270, 291]\n",
      "[4, 3, 2, 1, 0]\n",
      "59\n",
      "[703, 479, 463, 556, 375]\n",
      "[4, 3, 2, 1, 0]\n",
      "60\n",
      "[1123, 1132, 1131, 1120, 1005]\n",
      "[4, 3, 2, 1, 0]\n",
      "61\n",
      "[815, 767, 821, 748, 819]\n",
      "[4, 3, 2, 1, 0]\n",
      "62\n",
      "[73, 11, 5291, 5289, 5275]\n",
      "[4, 3, 2, 1, 0]\n",
      "63\n",
      "[128, 127, 126, 125, 123]\n",
      "[4, 3, 2, 1, 0]\n",
      "64\n",
      "[1062, 1444, 974, 987, 931]\n",
      "[4, 3, 2, 1, 0]\n",
      "65\n",
      "[987, 868, 1006, 1023, 886]\n",
      "[4, 3, 2, 1, 0]\n",
      "66\n",
      "[106, 102, 95, 66, 56]\n",
      "[4, 3, 2, 1, 0]\n",
      "67\n",
      "[2342, 2312, 2350, 2446, 2231]\n",
      "[4, 3, 2, 1, 0]\n",
      "68\n",
      "[151, 175, 192, 253, 255]\n",
      "[4, 3, 2, 1, 0]\n",
      "69\n",
      "[1591, 1590, 1589, 1587, 1588]\n",
      "[4, 3, 2, 1, 0]\n",
      "70\n",
      "[3060, 3059, 3058, 3028, 3015]\n",
      "[4, 3, 2, 1, 0]\n",
      "71\n",
      "[318, 293, 322, 200, 203]\n",
      "[4, 3, 2, 1, 0]\n",
      "72\n",
      "[876, 865, 871, 870, 808]\n",
      "[4, 3, 2, 1, 0]\n",
      "73\n",
      "[2941, 2903, 1773, 1451, 2934]\n",
      "[4, 3, 2, 1, 0]\n",
      "74\n",
      "[401, 431, 430, 429, 420]\n",
      "[4, 3, 2, 1, 0]\n",
      "75\n",
      "[1287, 1285, 1261, 1275, 1251]\n",
      "[4, 3, 2, 1, 0]\n",
      "76\n",
      "[4258, 4089, 3685, 4077, 4226]\n",
      "[4, 3, 2, 1, 0]\n",
      "77\n",
      "[1111, 1025, 1158, 1142, 802]\n",
      "[4, 3, 2, 1, 0]\n",
      "78\n",
      "[948, 799, 1046, 964, 1299]\n",
      "[4, 3, 2, 1, 0]\n",
      "79\n",
      "[333, 332, 326, 311, 324]\n",
      "[4, 3, 2, 1, 0]\n",
      "80\n",
      "[1075, 1071, 1079, 1070, 1072]\n",
      "[4, 3, 2, 1, 0]\n",
      "81\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [109]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(lat4)):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msanity_lattice\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m      5\u001b[0m             cnt\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(cnt)\n",
      "Input \u001b[0;32mIn [108]\u001b[0m, in \u001b[0;36msanity_lattice\u001b[0;34m(ind, lcode, beams, mlen)\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tok\u001b[38;5;241m.\u001b[39mas_target_tokenizer():\n\u001b[1;32m     41\u001b[0m         labels \u001b[38;5;241m=\u001b[39m tok([c], return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mto(dev)\n\u001b[0;32m---> 42\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m#print(output.loss)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m m \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(lat4[ind][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelscores\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/mbart/modeling_mbart.py:1298\u001b[0m, in \u001b[0;36mMBartForConditionalGeneration.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m decoder_input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1296\u001b[0m         decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(labels, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[0;32m-> 1298\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1299\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1300\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1301\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1302\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1303\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1304\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1305\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1308\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1310\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1311\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1312\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1313\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1314\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1315\u001b[0m lm_logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlm_head(outputs[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfinal_logits_bias\n\u001b[1;32m   1317\u001b[0m masked_lm_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/mbart/modeling_mbart.py:1167\u001b[0m, in \u001b[0;36mMBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1164\u001b[0m     decoder_input_ids \u001b[38;5;241m=\u001b[39m shift_tokens_right(input_ids, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpad_token_id)\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1167\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1176\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/mbart/modeling_mbart.py:798\u001b[0m, in \u001b[0;36mMBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    791\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    792\u001b[0m             create_custom_forward(encoder_layer),\n\u001b[1;32m    793\u001b[0m             hidden_states,\n\u001b[1;32m    794\u001b[0m             attention_mask,\n\u001b[1;32m    795\u001b[0m             (head_mask[idx] \u001b[38;5;28;01mif\u001b[39;00m head_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    796\u001b[0m         )\n\u001b[1;32m    797\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 798\u001b[0m         layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mencoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    799\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    800\u001b[0m \u001b[43m            \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    801\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    802\u001b[0m \u001b[43m            \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    803\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/mbart/modeling_mbart.py:307\u001b[0m, in \u001b[0;36mMBartEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    305\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    306\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_layer_norm(hidden_states)\n\u001b[0;32m--> 307\u001b[0m hidden_states, attn_weights, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    313\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[1;32m    314\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/transformers/models/mbart/modeling_mbart.py:265\u001b[0m, in \u001b[0;36mMBartAttention.forward\u001b[0;34m(self, hidden_states, key_value_states, past_key_value, attention_mask, layer_head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    262\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    263\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m attn_output\u001b[38;5;241m.\u001b[39mreshape(bsz, tgt_len, embed_dim)\n\u001b[0;32m--> 265\u001b[0m attn_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mattn_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m attn_output, attn_weights_reshaped, past_key_value\n",
      "File \u001b[0;32m~/miniconda3/envs/latenv/lib/python3.8/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for i in range(0, len(lat4)):\n",
    "    print(i)\n",
    "    if sanity_lattice(i):\n",
    "            cnt+=1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "23c91fc3-83cb-43e2-a97f-9bfadcafcf3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.4107227325439453,\n",
       " -0.4116992652416229,\n",
       " -0.41290998458862305,\n",
       " -0.4169265627861023]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "beam49[3]['modelscores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9bb8e0-acdd-4dcc-944b-33a1c0eaa33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# forward pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
