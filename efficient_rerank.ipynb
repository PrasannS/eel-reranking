{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5a58ca6e-bcd0-4f8e-9c3b-3dfb947ade77",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-25 06:36:30.374135: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-25 06:36:30.374157: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import flatten_lattice as fl\n",
    "import torch\n",
    "from bert_models import LinearPOSBertV1\n",
    "from encoding_utils import *\n",
    "from transformers import AutoTokenizer\n",
    "import pickle\n",
    "from mask_utils import *\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "xlm_tok = fl.bert_tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21e66a54-cc6a-4e12-963b-fbef8fdca248",
   "metadata": {},
   "outputs": [],
   "source": [
    "#V12 first attempt with inputs prepended\n",
    "VNUM = 12\n",
    "MOD_NAME = 'bertonewayv1.pth'\n",
    "\n",
    "# specifies files for pre-loading\n",
    "LOADED = {\n",
    "    'amasks': 'attmasksallv'+str(VNUM)+'.pt',\n",
    "    'tmaps': 'tmapsmaskedv'+str(VNUM)+'/'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4baeca25-5712-4a9e-9623-ca376cae506b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepend_input(pgraph, inp):\n",
    "    inptoks = xlm_tok(inp).input_ids\n",
    "    posadd = len(inptoks)\n",
    "    inpflat = []\n",
    "    ind = 0\n",
    "    for i in range(len(inptoks)):\n",
    "        nl = []\n",
    "        inp = inptoks[i]\n",
    "        if i<(len(inptoks)-1):\n",
    "            nl.append(str(inptoks[i+1])+\" \"+str(ind+1))\n",
    "        inpflat.append({\n",
    "            'token_idx':inp, \n",
    "            'pos':ind,\n",
    "            'id': str(inp)+\" \"+str(ind),\n",
    "            'nexts':nl,\n",
    "            'score':0,\n",
    "        })\n",
    "        ind+=1\n",
    "    inpflat[-1]['nexts'].append(pgraph[0]['id'].split()[0]+\" \"+str(posadd))\n",
    "    inpflat.extend(pgraph)\n",
    "    for i in range(posadd, len(inpflat)):\n",
    "        extok = inpflat[i]\n",
    "        extok['pos']+=posadd\n",
    "        extok['id']= str(extok['token_idx'])+\" \"+str(extok['pos'])\n",
    "        for j in range(len(extok['nexts'])):\n",
    "            newpos = int(extok['nexts'][j].split()[1])+posadd\n",
    "            extok['nexts'][j] = extok['nexts'][j].split()[0]+\" \"+str(newpos)\n",
    "    return inpflat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b18febff-5025-40fa-b962-188a9b6f5176",
   "metadata": {},
   "outputs": [],
   "source": [
    "STOPS = -1\n",
    "\n",
    "# Get examples (just use the normal lattice examples ig?)\n",
    "processedgraphs, inps, refs = fl.get_processed_graph_data(fl.frenbase, -1, STOPS)\n",
    "\n",
    "# get exploded candidates to generate gold labels\n",
    "resarrs = [fl.get_cover_paths(p)[0] for p in processedgraphs]\n",
    "\n",
    "# extra step for greedy \n",
    "if STOPS==1:\n",
    "    processedgraphs = filter_greedy(processedgraphs)\n",
    "    \n",
    "\n",
    "# ensure no empty examples\n",
    "clean_empty(resarrs, processedgraphs)\n",
    "\n",
    "processedgraphs=[prepend_input(processedgraphs[i], inps[i]) for i in range(len(processedgraphs))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "22a3c6d1-199e-4c8e-bc39-daaeafe6a065",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctest = get_adjac_mat(processedgraphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10841d94-a661-476a-89bc-66ce065c195a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_idx': 581, 'pos': 49, 'id': '581 49', 'nexts': ['7082 50'], 'score': 0}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedgraphs[0][49]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8961a15d-3c99-447e-a79e-024c98f777a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>\n",
      "Le\n",
      "président\n",
      "américain\n",
      "devait\n",
      "recevoir\n",
      "vendredi\n",
      "1\n",
      "er\n",
      "novembre\n",
      "2013\n",
      "le\n",
      "premier\n",
      "ministre\n",
      "ir\n",
      "a\n",
      "kien\n",
      "No\n",
      "uri\n",
      "Al\n",
      "Malik\n",
      "i\n",
      ",\n",
      "en\n",
      "quê\n",
      "te\n",
      "d\n",
      "'\n",
      "aide\n",
      "des\n",
      "États\n",
      "-\n",
      "Unis\n",
      "pour\n",
      "lutte\n",
      "r\n",
      "contre\n",
      "la\n",
      "plus\n",
      "forte\n",
      "va\n",
      "gue\n",
      "de\n",
      "violence\n",
      "depuis\n",
      "cinq\n",
      "ans\n",
      ".\n",
      "</s>\n",
      "The\n",
      "US\n",
      "President\n",
      "was\n",
      "to\n",
      "receive\n",
      "Iraq\n",
      "i\n",
      "Prime\n",
      "Minister\n",
      "No\n",
      "uri\n",
      "Al\n",
      "Malik\n",
      "i\n",
      "Friday\n",
      ",\n",
      "November\n",
      "1\n",
      ",\n",
      "2013\n",
      "in\n",
      "an\n",
      "effort\n",
      "to\n",
      "se\n",
      "ek\n",
      "US\n",
      "assistance\n",
      "in\n",
      "fighting\n",
      "the\n",
      "worst\n",
      "wa\n",
      "ve\n",
      "of\n",
      "violence\n",
      "in\n",
      "five\n",
      "years\n",
      ".\n",
      "2 90\n"
     ]
    }
   ],
   "source": [
    "processedgraphs[0]\n",
    "\n",
    "def get_validnext (pos, nlist):\n",
    "    retval = \"\"\n",
    "    for n in nlist:\n",
    "        if pos< int(n.split()[1]):\n",
    "            retval = n\n",
    "            if \"2 \" not in n:\n",
    "                return retval\n",
    "    if len(retval)>0:\n",
    "        return retval\n",
    "    print(\"no valid\")\n",
    "    print(pos)\n",
    "    print(nlist)\n",
    "    return \"\"\n",
    "\n",
    "def p_wnext(pgraph):\n",
    "    nid = '0 0'\n",
    "    for tokd in pgraph:\n",
    "        if tokd['id']==nid:\n",
    "            print(xlm_tok.decode(tokd['token_idx']))\n",
    "            nid = get_validnext(tokd['pos'], tokd['nexts'])\n",
    "            \n",
    "            #print(tokd)\n",
    "    print(nid)\n",
    "            \n",
    "p_wnext(processedgraphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa2808-238b-4eb9-83e5-7ce27432f94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a list of sub-scores (topological flattening of the graph), use dp to get the highest scoring path\n",
    "# idlist has the corresponding graph ids for \n",
    "# would need to do a sort on pgrapaps that makes sure that no next node is before in the linear ordering\n",
    "# reverse since we're using nexts\n",
    "# TODO simplify code to not need so many data structures\n",
    "def dp_best_path(pgraphs, graph):\n",
    "    assert len(pgraphs)==len(scores)\n",
    "    bplist = []\n",
    "    bsco_list =[]\n",
    "    for i in range(len(idlist)):\n",
    "        bpath = []\n",
    "        cur = pgraphs[i]\n",
    "        # first instance, assume direct all endings to a single node, score 0\n",
    "        if len(cur['nextlist'])==0:\n",
    "            bpath.append(i)\n",
    "            bplist.append(bpath)\n",
    "            bsco_list.append(cur['score'])\n",
    "            # check if this is how things work in python\n",
    "            graph[pgraphs['id']]['bestsco'] = cur['score']\n",
    "            graph[pgraphs['id']]['plist'] = bpath\n",
    "            continue\n",
    "        # get the highest prev from ahead to use\n",
    "        mval = -1\n",
    "        maxnext = None\n",
    "        for n in cur['nextlist']:\n",
    "            if graph[n]['bestsco']>mval:\n",
    "                mval = graph[n]['bestsco']\n",
    "                maxnext = graph[n]\n",
    "        # add in scores / path from that prev\n",
    "        bpath.extend(maxnext['plist']+[i])\n",
    "        bplist.append(bpath)\n",
    "        bsco_list.append(cur['score']+mval)\n",
    "        graph[pgraphs['id']]['bestsco'] = cur['score']+mval\n",
    "        graph[pgraphs['id']]['plist'] = bpath\n",
    "    return bplist[-1], bsco_list[-1]\n",
    "\n",
    "def get_idlist(pgraph):\n",
    "    return [p['id'] for p in pgraph]\n",
    "        \n",
    "def dp_sort_pgraph(pgraphs):\n",
    "    idlist = get_idlist(pgraph)\n",
    "    for p in pgraphs:\n",
    "        \n",
    "    \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8b3dc5a7-19a5-4318-914e-923759308394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating new masks\n"
     ]
    }
   ],
   "source": [
    "# Attention mask code (TODO needs some updating)\n",
    "if os.path.exists('./torchsaved/'+LOADED['amasks']):\n",
    "        print(\"using loaded masks\")\n",
    "        attmasks = torch.load('./torchsaved/'+LOADED['amasks']).to(device)\n",
    "else:\n",
    "    print(\"creating new masks\")\n",
    "    masktmp = [connect_mat(p) for p in processedgraphs]\n",
    "    attmasks = torch.stack(masktmp).to(device)\n",
    "    torch.save(attmasks, './torchsaved/'+LOADED['amasks'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74115fb8-0b82-4d78-9548-26e2ad618164",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctest = connect_mat(processedgraphs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4ae73-0af5-462d-b7c9-7ced12257cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b201852-f4c9-4dee-8a54-18928413ca6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "        90, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86,\n",
       "        87, 65, 66, 67, 68, 69, 70, 71, 72, 71, 69, 70, 71, 72, 73, 70, 71, 72,\n",
       "        73, 74, 75, 76, 77, 78, 79, 80, 71, 72, 73, 74, 75, 76, 77, 78, 71, 67,\n",
       "        68, 68, 69, 70, 70, 71, 68, 69, 70, 71, 72, 73, 71, 72, 72, 73, 74, 72,\n",
       "        73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n",
       "        91, 92, 75, 76, 77, 78, 79, 80, 81, 82, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 82, 83, 85, 86, 83, 84, 87, 83, 78, 72, 73, 74, 75, 78, 75, 76, 77,\n",
       "        75, 75, 76, 76, 77, 78, 80, 81, 82, 81, 73, 74, 75, 74, 75, 76, 77, 80,\n",
       "        81, 82, 86, 82, 83, 81, 82, 83, 84, 85, 86, 87, 77, 78, 79, 80, 78, 76,\n",
       "        78, 79, 80, 83, 84, 84, 85, 87, 88, 83, 85, 76, 77, 76, 77, 78, 77, 78,\n",
       "        79, 80, 78, 79, 77, 78, 79, 77, 78, 79, 80, 80, 81, 82, 83, 70, 71, 71,\n",
       "        72, 73, 71, 72, 73, 74, 75, 76, 77, 78, 81, 73, 72, 71, 72, 73, 74, 72,\n",
       "        73, 74, 75, 74, 75, 72, 73, 74, 75, 76, 77, 78, 79, 73, 74, 75, 75, 76,\n",
       "        77, 76, 77, 78, 78, 73, 74, 75, 76, 71, 73, 75, 75, 72, 73, 74, 75, 76,\n",
       "        77, 78, 79, 73, 75, 76, 77, 76, 73, 74, 75, 77, 73, 74, 72, 73, 74, 77,\n",
       "        75, 74, 75, 73, 74, 93,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       device='cuda:3')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139afa72-166d-4226-90ec-4b87d608f959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get tokenized inputs with posids (TODO needs an update for src/tgt format)\n",
    "sents, posids = create_inputs(processedgraphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d491274a-1c2a-4ad5-a6ae-9b4f910f9d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "        18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "        36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
       "        54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71,\n",
       "        72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,\n",
       "        90, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86,\n",
       "        87, 65, 66, 67, 68, 69, 70, 71, 72, 71, 69, 70, 71, 72, 73, 70, 71, 72,\n",
       "        73, 74, 75, 76, 77, 78, 79, 80, 71, 72, 73, 74, 75, 76, 77, 78, 71, 67,\n",
       "        68, 68, 69, 70, 70, 71, 68, 69, 70, 71, 72, 73, 71, 72, 72, 73, 74, 72,\n",
       "        73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90,\n",
       "        91, 92, 75, 76, 77, 78, 79, 80, 81, 82, 77, 78, 79, 80, 81, 82, 83, 84,\n",
       "        85, 82, 83, 85, 86, 83, 84, 87, 83, 78, 72, 73, 74, 75, 78, 75, 76, 77,\n",
       "        75, 75, 76, 76, 77, 78, 80, 81, 82, 81, 73, 74, 75, 74, 75, 76, 77, 80,\n",
       "        81, 82, 86, 82, 83, 81, 82, 83, 84, 85, 86, 87, 77, 78, 79, 80, 78, 76,\n",
       "        78, 79, 80, 83, 84, 84, 85, 87, 88, 83, 85, 76, 77, 76, 77, 78, 77, 78,\n",
       "        79, 80, 78, 79, 77, 78, 79, 77, 78, 79, 80, 80, 81, 82, 83, 70, 71, 71,\n",
       "        72, 73, 71, 72, 73, 74, 75, 76, 77, 78, 81, 73, 72, 71, 72, 73, 74, 72,\n",
       "        73, 74, 75, 74, 75, 72, 73, 74, 75, 76, 77, 78, 79, 73, 74, 75, 75, 76,\n",
       "        77, 76, 77, 78, 78, 73, 74, 75, 76, 71, 73, 75, 75, 72, 73, 74, 75, 76,\n",
       "        77, 78, 79, 73, 75, 76, 77, 76, 73, 74, 75, 77, 73, 74, 72, 73, 74, 77,\n",
       "        75, 74, 75, 73, 74, 93,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       device='cuda:3')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "95ecd978-39b5-4d0e-aef4-49db4749d18f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"_<s> Le président américain devait recevoir vendredi 1er novembre 2013 le premier ministre irakien Nouri Al Maliki, en quête d'aide des États-Unis pour lutter contre la plus forte vague de violence depuis cinq ans.</s> The US President was to receive Iraqi Prime Minister Nouri Al Maliki Friday, November 1, 2013 in an effort to seek US assistance in fighting the worst wave of violence in five years. 2013, in search of US assistance to fight the worst wave of violence in five years. on Friday 1 November 2013 in search of an 2013, seeking US assistance in in a bid to help the United States fight the worst an effort to seek US assistance in search, 1 November 2013 2013, seeking November 1 st 2013, in search, in an effort 2013 in an attempt to seek US assistance in fighting the worst wave of violence in five years. effort to find US support to fight the help the United States combat the worst wave the biggestve of strongest of worstek 2013, seeking US aid the support in fighting help assistance to in combating worst waveve in an effort search of assistance from States to combatve fight the in combating the worst wave States aid to fight assistance help the US States the worst strongestve of theest U. US support to help to fight the in fighting aid to combat assistance in combating the worst wave, seeking US assistance in a bid to help the United States worst of an 2013 to seek as he sought seeks in the hopes of seeking US assistance a bid for to seek help the country US search of U. 2013, heeksught seeking assistance from the US in fighting the help the US to United United States assistance fighting U. in his quest assistances bid for an attemptta<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\""
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# todo correct 101, 102 added before and after input\n",
    "xlm_tok.decode(sents[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d64186-97d3-41c5-b8a3-a6416c002f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'token_idx': 0, 'pos': 0, 'id': '0 0', 'nexts': ['636 1'], 'score': 0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for t in processedgraphs[0]:\n",
    "    if t['token_idx']==0:\n",
    "        print(t)\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "33da7ecc-d06a-491d-8507-c61bfcc93fd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tok.decode(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c0ea641-ce74-4cb7-9c5d-e8dafb4ba9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'token_idx': 0, 'pos': 0, 'id': '0 0', 'nexts': ['581 1'], 'score': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processedgraphs[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ddbc6a49-81b8-4005-90e1-3fd0ba81715a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [0, 0, 2], 'attention_mask': [1, 1, 1]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tok(\"<s>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107809d6-014b-4d85-9463-2adfcbb8db6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "' </s> en_XX The US President was to receive Iraq i Prime Minister No uri Al Malik i Friday , November 1 , 2013 in an effort to se ek US assistance in fighting the worst wa ve of violence in five years'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f68d6-96dd-4311-893e-99e8298bb5ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
