{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7403237-4abe-4b50-9669-6c2575ac73b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-10 12:22:09.615618: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-10 12:22:09.615652: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "\n",
    "from encoding_utils import *\n",
    "from flatten_lattice import *\n",
    "from model_construct import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3dcd8c2-f679-4d12-8b1f-a065095cba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def submask_help(words):\n",
    "    msk = []\n",
    "    for i in range(len(words)-1):\n",
    "        if \"#\" in words[i+1]:\n",
    "            msk.append(0)\n",
    "        else:\n",
    "            msk.append(1)\n",
    "    msk.append(1)\n",
    "    return torch.tensor(msk)\n",
    "\n",
    "def subword_mask_all ():\n",
    "    msk = torch.ones_like(sents)\n",
    "    for i in range(0, len(sents)):\n",
    "        tmp = [tok.decode(s) for s in sents[i]]\n",
    "        msk[i] = submask_help(tmp)\n",
    "    return msk\n",
    "\n",
    "def get_acc():\n",
    "    # simplify prediction tensors\n",
    "    ysimp = ylabels\n",
    "    psimp = torch.argmax(pred1, dim=2)\n",
    "    # clean up labels\n",
    "    sm = subword_mask_all()\n",
    "    ysimp[sents==0] = 0\n",
    "    ysimp[sents==102] = 0\n",
    "    ysimp[sm==0] = 0\n",
    "    ysimp[:, 0] = 0\n",
    "    # apply cleanaup to x \n",
    "    psimp[ysimp==0] = 0\n",
    "    # apply cleanaup to x \n",
    "    psimp[ysimp==0] = 0\n",
    "    # compute accuracy\n",
    "    acc = 1 - ((ysimp-psimp).count_nonzero())/ysimp.count_nonzero()\n",
    "    return acc, ysimp, psimp\n",
    "\n",
    "def get_err_tensors():\n",
    "    diff = ysimp-psimp\n",
    "    diff = diff.abs().bool().int()\n",
    "    errg = ysimp\n",
    "    errp = psimp\n",
    "    errg[diff==0] = 0\n",
    "    errp[diff==0] = 0\n",
    "    return errg, errp\n",
    "\n",
    "\n",
    "def print_decoded(toks):\n",
    "    nt = []\n",
    "    for t in toks:\n",
    "        if t==100 or t==101 or t==102 or t==0:\n",
    "            continue\n",
    "        nt.append(t)\n",
    "    print(tok.decode(nt))\n",
    "    return tok.decode(nt)\n",
    "    \n",
    "# \n",
    "def error_vis(ind):\n",
    "    nt = print_decoded(sents[ind])\n",
    "    p = [lablist[int(errp[ind][i])] for i in errp[ind].nonzero()]\n",
    "    g = [lablist[int(errg[ind][i])] for i in errp[ind].nonzero()]\n",
    "    s = [tok.decode(int(sents[ind][i])) for i in errp[ind].nonzero()]\n",
    "    print(\"ERRORS : \")\n",
    "    print(\"(predicted, gold, token)\")\n",
    "    print(list(zip(p, g, s)))\n",
    "    return nt\n",
    "    \n",
    "def vis_model_pred(strinp):\n",
    "    tokinps = tok(strinp, return_tensors='pt').input_ids.to(device)\n",
    "    msk = torch.tril(torch.ones((len(tokinps[0]), len(tokinps[0]))))\n",
    "    preds = bmodel(tokinps, attmasks=torch.stack([msk]).to(device))\n",
    "    preds = torch.argmax(preds, dim=2)\n",
    "    labs = [lablist[int(p)] for p in preds[0]]\n",
    "    tinps = [tok.decode(int(t))for t in tokinps[0]]\n",
    "    #print(list(zip(labs, tinps)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ceb1b1b5-1ac4-4359-b648-4766009c7117",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Mem Used =  534572544\n",
      "accuracy:  tensor(0.8894, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tok = fl.bert_tok\n",
    "\n",
    "# loads in odata with keys: tmaps, masks, pgraphs\n",
    "with open('torchsaved/outputv5.pkl', 'rb') as file:\n",
    "    odata = pickle.load(file)\n",
    "    \n",
    "with open('./a3distrib/lab_vocab.json') as json_file:\n",
    "    labels = json.load(json_file)\n",
    "    \n",
    "# load in other metadata\n",
    "bmodel = load_model(labels)\n",
    "sents, posids = create_inputs(odata['pgraphs'])\n",
    "\n",
    "ylabels = tmap_pos_goldlabels(odata['tmaps'], sents)   \n",
    "lablist = [l for l in labels.keys()]\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "pg = odata['pgraphs']\n",
    "\n",
    "sents, posids = create_inputs(odata['pgraphs'])\n",
    "pred1 = bmodel(sents, mod_posids(posids), odata['masks'])\n",
    "accuracy, ysimp, psimp = get_acc()\n",
    "\n",
    "print(\"accuracy: \", accuracy)\n",
    "\n",
    "errg, errp = get_err_tensors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4b559c-5ba3-4d69-bdc7-6dc77998a3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previous vaccines against tobacco had been ineffective because of antibodies.\n",
      "ERRORS : \n",
      "(predicted, gold, token)\n",
      "[('JJ', 'IN', 'Previous'), ('.', 'IN', '.')]\n"
     ]
    }
   ],
   "source": [
    "# can put any number between 0-100 and it will show an example and errors with the example\n",
    "INP = 0\n",
    "vis_model_pred(error_vis(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe237ad8-1616-4002-802c-acb1a31d8c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### BEYOND THIS IS RANDOM SANITY CHECKING ########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288865bd-bd23-43bb-a401-ca65dc84db2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "goldlist = []\n",
    "predlist = []\n",
    "toklist = []\n",
    "for e in errg.nonzero():\n",
    "    goldlist.append(lablist[int(errg[e[0], e[1]])])\n",
    "    predlist.append(lablist[int(errp[e[0], e[1]])])\n",
    "    toklist.append(tok.decode(int(sents[e[0], e[1]])))\n",
    "    \n",
    "zipped = list(zip(goldlist, predlist, toklist))\n",
    "zipcln = []\n",
    "cnt = 0\n",
    "for z in zipped:\n",
    "    if z[1]==z[2]:\n",
    "        cnt+=1\n",
    "        continue\n",
    "    zipcln.append(z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6af233c-0509-4fe6-b206-e36c1223efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check masking \n",
    "sents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de6baedd-5b4f-48ca-9f19-f71e503b3566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([101, 500, 500])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odata['masks'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bc72c18-3032-4004-82cb-07174b36d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_mask_leadup(ind):\n",
    "    msk = odata['masks'][ind]\n",
    "    smat = torch.zeros_like(msk)\n",
    "    smat[:, :] = sents[ind]\n",
    "    assert msk.shape == smat.shape\n",
    "    return smat, msk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4e0d5e23-c281-4bef-a3de-c8f87cd50221",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm, m = print_mask_leadup(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9e467f88-eba6-4366-b924-674d77fbae6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sm[m==0]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "231027a3-0ede-48d8-8bd0-bcc58b055b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = tok.batch_decode(sm.int())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f6b3a408-bfc4-494f-a63d-175c05f3deda",
   "metadata": {},
   "outputs": [],
   "source": [
    "inps = [txt.replace(\" [PAD]\", \"\") for txt in inps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8cba68b3-260d-4f0a-896a-1bc38e7e88ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,\n",
       "         14,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  21,  22,  23,\n",
       "         24,  25,  26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,\n",
       "         38,  16,  17,  18,  19,  20,  21,  22,  23,  22,  20,  21,  21,  22,\n",
       "         23,  24,  21,  22,  23,  24,  25,  26,  27,  28,  31,  22,  23,  24,\n",
       "         25,  27,  28,  22,  18,  19,  20,  21,  22,  22,  19,  20,  21,  22,\n",
       "         22,  23,  24,  25,  22,  23,  24,  25,  23,  24,  25,  26,  27,  28,\n",
       "         29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  26,\n",
       "         27,  28,  29,  30,  31,  32,  33,  28,  29,  30,  31,  32,  35,  33,\n",
       "         34,  36,  34,  34,  28,  23,  24,  24,  25,  26,  27,  28,  29,  26,\n",
       "         27,  28,  26,  26,  27,  27,  28,  29,  32,  29,  30,  31,  24,  25,\n",
       "         26,  25,  26,  27,  28,  31,  32,  33,  34,  35,  36,  33,  34,  32,\n",
       "         33,  34,  35,  36,  37,  33,  28,  29,  30,  31,  29,  27,  29,  30,\n",
       "         31,  32,  34,  35,  35,  36,  37,  34,  35,  27,  28,  27,  28,  29,\n",
       "         29,  28,  29,  30,  31,  28,  29,  30,  28,  29,  30,  31,  33,  21,\n",
       "         22,  23,  24,  22,  23,  24,  25,  26,  27,  28,  29,  32,  23,  24,\n",
       "         23,  22,  23,  24,  23,  24,  25,  25,  23,  24,  25,  26,  27,  28,\n",
       "         29,  24,  25,  26,  26,  27,  27,  28,  29,  29,  25,  26,  27,  23,\n",
       "         24,  25,  25,  23,  24,  25,  26,  27,  28,  29,  30,  24,  26,  27,\n",
       "         27,  24,  25,  26,  28,  24,  25,  23,  24,  25,  28,  25,  25,  26,\n",
       "         24,  25,  42, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307,\n",
       "        308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321,\n",
       "        322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335,\n",
       "        336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349,\n",
       "        350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363,\n",
       "        364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377,\n",
       "        378, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391,\n",
       "        392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405,\n",
       "        406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419,\n",
       "        420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433,\n",
       "        434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447,\n",
       "        448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461,\n",
       "        462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475,\n",
       "        476, 477, 478, 479, 480, 481, 482, 483, 484, 485, 486, 487, 488, 489,\n",
       "        490, 491, 492, 493, 494, 495, 496, 497, 498, 499], device='cuda:0')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "71194890-0f05-4132-99af-8d1001cc9c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.zeros(5, 5)\n",
    "a[:3, :3] = torch.ones(3, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e0dd1aa2-9477-4146-b2b4-3907e775af50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0.],\n",
       "        [1., 1., 0., 0., 0.],\n",
       "        [1., 1., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75cbd37a-9de3-4b5f-8e57-044f41c92c18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
