{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e8cfdec-5bf0-404c-9bcd-1a29f2da8665",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-05 04:56:19.986821: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-09-05 04:56:19.986842: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "# Credit, using some code from https://pageperso.lis-lab.fr/benoit.favre/pstaln/09_embedding_evaluation.html\n",
    "# Credit, using data / setup from Assignment 3, Professor Greg Durrett's Masters CS 388 Course \n",
    "\n",
    "from a3distrib.treedata import *\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import numpy as np\n",
    "from modmask_bert_models import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22f0a640-9ba5-453f-b355-71f98ee737ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 39832 sents from ./a3distrib/data/train_sents.conll\n",
      "Read 1700 sents from ./a3distrib/data/dev_sents.conll\n"
     ]
    }
   ],
   "source": [
    "train_sents = read_labeled_sents('./a3distrib/data/train_sents.conll')\n",
    "dev_sents = read_labeled_sents('./a3distrib/data/dev_sents.conll')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27442f3e-ad87-4edd-bc89-4aa78016099e",
   "metadata": {},
   "outputs": [],
   "source": [
    "alltags = []\n",
    "for t in train_sents:\n",
    "    alltags.extend(t.get_tags())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74cc7c3c-d459-4dca-8443-982f6fb06c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [t.get_words() for t in train_sents]\n",
    "train_tags = [t.get_tags() for t in train_sents]\n",
    "dev_words = [t.get_words() for t in dev_sents]\n",
    "dev_tags = [t.get_tags() for t in dev_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "572bd532-122d-45ae-822f-6a4e0a679366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of different tags: 30\n",
      "692438 N\n",
      "172580 P\n",
      "162766 D\n",
      "160692 B\n",
      "132804 J\n",
      "125360 V\n",
      "108863 T\n",
      "98554 I\n",
      "84462 C\n",
      "73722 S\n",
      "68843 R\n",
      "48727 ,\n",
      "39478 .\n",
      "31058 O\n",
      "21672 Z\n",
      "15947 $\n",
      "14846 G\n",
      "14184 `\n",
      "13838 '\n",
      "9861 M\n",
      "9202 W\n",
      "4772 :\n",
      "863 E\n",
      "863 X\n",
      "234 F\n",
      "142 #\n",
      "97 U\n",
      "97 H\n",
      "58 Y\n",
      "36 L\n"
     ]
    }
   ],
   "source": [
    "# use a defaultdict to count the number of occurrences of each tag\n",
    "import collections\n",
    "tagset = collections.defaultdict(int)\n",
    "\n",
    "for tagging in alltags:\n",
    "    for tag in tagging:\n",
    "        tagset[tag] += 1\n",
    "\n",
    "print('number of different tags:', len(tagset))\n",
    "\n",
    "# print count and tag sorted by decreasing count\n",
    "for tag, count in sorted(tagset.items(), reverse=True, key=lambda x: x[1]):\n",
    "  print(count, tag)\n",
    "    \n",
    "# Found 30 tags in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61393a75-3375-4129-8b6f-b4dbe6b0a9a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 139\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# compute and show histogram for sentence length\n",
    "plt.hist([len(sentence) for sentence in train_sents], 20)\n",
    "plt.show()\n",
    "\n",
    "# compute max sentence length\n",
    "print('max length:', max([len(sentence) for sentence in train_sents]))\n",
    "\n",
    "# Found smaller max length (this task is definetely on the easier side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa88878e-276c-46ce-8565-d1634ed5c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670c812f-71b4-4bf5-a1e4-a934ec58ec53",
   "metadata": {},
   "outputs": [],
   "source": [
    "spaced_dset = [' '.join(t) for t in train_words]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2ec188c2-2151-46b7-9187-8b9c02e5b010",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenized_sentence = tokenizer(spaced_dset, padding=\"max_length\", max_length=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88f67188-50ef-411f-93d1-645977e8fabf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoding(num_tokens=500, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokenized_sentence[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db94de7-3317-489b-8041-42d7bb9892aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e19fb2b3-d4a3-4931-8b17-de22485f0193",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def align_tokenizations(sentences, taggings):\n",
    "    bert_tokenized_sentences = []\n",
    "    aligned_taggings = []\n",
    "\n",
    "    for sentence, tagging in zip(sentences, taggings):\n",
    "        # first generate BERT-tokenization\n",
    "        bert_tokenized_sentence = tokenizer.tokenize(' '.join(sentence))\n",
    "\n",
    "        aligned_tagging = []\n",
    "        current_word = ''\n",
    "        index = 0 # index of current word in sentence and tagging\n",
    "        for token in bert_tokenized_sentence:\n",
    "            current_word += re.sub(r'^##', '', token) # recompose word with subtoken\n",
    "            sentence[index] = sentence[index].replace('\\xad', '') # fix bug in data\n",
    "\n",
    "            # note that some word factors correspond to unknown words in BERT\n",
    "            assert token == '[UNK]' or sentence[index].startswith(current_word)\n",
    "\n",
    "            if token == '[UNK]' or sentence[index] == current_word: # if we completed a word\n",
    "                current_word = ''\n",
    "                aligned_tagging.append(tagging[index])\n",
    "                index += 1\n",
    "            else: # otherwise insert padding\n",
    "                aligned_tagging.append(tagging[index])\n",
    "\n",
    "        assert len(bert_tokenized_sentence) == len(aligned_tagging)\n",
    "\n",
    "        bert_tokenized_sentences.append(bert_tokenized_sentence)\n",
    "        aligned_taggings.append(aligned_tagging)\n",
    "\n",
    "    return bert_tokenized_sentences, aligned_taggings\n",
    "\n",
    "train_bert_tokenized_sentences, train_aligned_taggings = align_tokenizations(train_words, train_tags)\n",
    "test_bert_tokenized_sentences, test_aligned_taggings = align_tokenizations(dev_words, dev_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ca3970e-cef4-46bb-8793-fb6b4b7ba383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Also', 'excluded', 'will', 'be', 'investments', 'in', 'companies', 'with', '`', '`', 'significant', \"'\", \"'\", 'business', 'stem', '##ming', 'from', 'weapons', 'manufacture', ',', 'alcoholic', 'beverages', 'or', 'tobacco', '.']\n",
      "['RB', 'VBN', 'MD', 'VB', 'NNS', 'IN', 'NNS', 'IN', '``', '``', 'JJ', \"''\", \"''\", 'NN', 'VBG', 'VBG', 'IN', 'NNS', 'NN', ',', 'JJ', 'NNS', 'CC', 'NN', '.']\n"
     ]
    }
   ],
   "source": [
    "print(train_bert_tokenized_sentences[42])\n",
    "print(train_aligned_taggings[42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ec120a9-e0c2-4044-9876-b9d38f362cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device('cuda:2' if torch.cuda.is_available else 'cpu')\n",
    "\n",
    "import collections\n",
    "\n",
    "label_vocab = collections.defaultdict(lambda: len(label_vocab))\n",
    "label_vocab['<pad>'] = 0\n",
    "label_vocab['<cls>'] = 1\n",
    "label_vocab['<sep>'] = 2\n",
    "\n",
    "\n",
    "# do the BERT SEP CLS thing\n",
    "def convert_to_ids(sentences, taggings):\n",
    "    sentences_ids = []\n",
    "    taggings_ids = []\n",
    "    for sentence, tagging in zip(sentences, taggings):\n",
    "        sentence_tensor = torch.tensor(tokenizer.convert_tokens_to_ids(['[CLS]'] + sentence + ['[SEP]'])).long()\n",
    "        tagging_tensor = torch.tensor([1] + [label_vocab[tag] for tag in tagging] + [2]).long()\n",
    "\n",
    "        sentences_ids.append(sentence_tensor.to(device))\n",
    "        taggings_ids.append(tagging_tensor.to(device))\n",
    "    return sentences_ids, taggings_ids\n",
    "\n",
    "train_sentences_ids, train_taggings_ids = convert_to_ids(train_bert_tokenized_sentences, train_aligned_taggings)\n",
    "test_sentences_ids, test_taggings_ids = convert_to_ids(test_bert_tokenized_sentences, test_aligned_taggings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e5be8ff-0c1e-4147-9a95-563c9b230447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1,  5,  5,  5, 14,  7, 15, 25,  7,  7, 14, 16, 22, 20, 20, 20, 20,  7,\n",
       "         3,  4,  7,  7,  7,  3,  5, 15,  5, 14, 15,  3, 25, 25, 12, 19,  2],\n",
       "       device='cuda:2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_taggings_ids[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c639600-18a3-4ee4-8495-3429cd37f363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f09afee2-f0f4-4112-aaee-56a27fba955d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"lab_vocab.json\", \"w\") as outfile:\n",
    "    json.dump(label_vocab, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e8761b22-4f9b-4d0a-9f30-ef0ac307dcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class PosTaggingDataset(Dataset):\n",
    "    def __init__(self, sentences, taggings):\n",
    "        assert len(sentences) == len(taggings)\n",
    "        self.sentences = sentences\n",
    "        self.taggings = taggings\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.sentences[i], self.taggings[i]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "# function to create a batch from a list of instances\n",
    "def collate_fn(items):\n",
    "    max_len = max(len(item[0]) for item in items)\n",
    "\n",
    "    sentences = torch.zeros((len(items), max_len), device=items[0][0].device).long().to(device)\n",
    "    taggings = torch.zeros((len(items), max_len)).long().to(device)\n",
    "    masks = torch.zeros((len(items), max_len, max_len), device=items[0][0].device).float().to(device)\n",
    "    \n",
    "\n",
    "    for i, (sentence, tagging) in enumerate(items):\n",
    "        assert len(sentence)==len(tagging)\n",
    "        sentences[i][0:len(sentence)] = sentence\n",
    "        taggings[i][0:len(tagging)] = tagging\n",
    "        masks[i][0:len(sentence)] = sentences[i].bool().int()\n",
    "        \n",
    "        # make mask upper-triangular\n",
    "    masks = torch.triu(masks)\n",
    "    #masks[masks==0] = -float('inf')\n",
    "\n",
    "    return sentences, taggings, masks\n",
    "\n",
    "x, y, m = collate_fn([[torch.tensor([1, 2, 3]), torch.tensor([4, 5, 6])], [torch.tensor([1, 2]), torch.tensor([3, 4])]])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5ab3a893-1b74-4d83-8058-275059544a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 1., 1.],\n",
       "         [0., 1., 1.],\n",
       "         [0., 0., 1.]],\n",
       "\n",
       "        [[1., 1., 0.],\n",
       "         [0., 1., 0.],\n",
       "         [0., 0., 0.]]], device='cuda:2')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fe0e1238-6dfc-4c0f-bd47-d874195247cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "train_loader = DataLoader(PosTaggingDataset(train_sentences_ids, train_taggings_ids), batch_size=batch_size, collate_fn=collate_fn, shuffle=True)\n",
    "test_loader = DataLoader(PosTaggingDataset(test_sentences_ids, test_taggings_ids), batch_size=batch_size, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d7e72c4a-9d17-4d43-8b05-983c43fe6e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perf(model, loader):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    model.eval() # do not apply training-specific steps such as dropout\n",
    "    total_loss = correct = num_loss = num_perf = 0\n",
    "    for x, y, m in loader:\n",
    "        with torch.no_grad(): # no need to store computation graph for gradients\n",
    "            # perform inference and compute loss\n",
    "            y_scores = model(x, attmasks=m)\n",
    "            loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1)) # requires tensors of shape (num-instances, num-labels) and (num-instances)\n",
    "\n",
    "            # gather loss statistics\n",
    "            total_loss += loss.item()\n",
    "            num_loss += 1\n",
    "\n",
    "            # gather accuracy statistics\n",
    "            y_pred = torch.max(y_scores, 2)[1] # compute highest-scoring tag\n",
    "            mask = (y != 0) # ignore <pad> tags\n",
    "            correct += torch.sum((y_pred == y) * mask) # compute number of correct predictions\n",
    "            num_perf += torch.sum(mask).item()\n",
    "    return total_loss / num_loss, correct.item() / num_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0f4d3e0-051d-400c-8987-79290a1089d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "def fit(model, epochs, optimizer):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = num = 0\n",
    "        for x, y, mask in train_loader:\n",
    "            optimizer.zero_grad() # start accumulating gradients\n",
    "            y_scores = model(x, attmasks=mask)\n",
    "            loss = criterion(y_scores.view(-1, len(label_vocab)), y.view(-1))\n",
    "            loss.backward() # compute gradients though computation graph\n",
    "            optimizer.step() # modify model parameters\n",
    "            total_loss += loss.item()\n",
    "            num += 1\n",
    "        print(1 + epoch, total_loss / num, *perf(model, test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "46ba052b-b8fc-4f21-a8e1-ab63f5d60c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import AutoConfig\n",
    "\n",
    "class LinearProbeBert(nn.Module):\n",
    "    def __init__(self, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained('bert-base-cased')\n",
    "        #self.bert = LatticeBertModel(AutoConfig.from_pretrained('bert-base-cased'))\n",
    "        self.probe = nn.Linear(self.bert.config.hidden_size, num_labels)\n",
    "        self.to(device)\n",
    "\n",
    "    def parameters(self):\n",
    "        return self.probe.parameters()\n",
    "  \n",
    "    def forward(self, sentences, attmasks=None):\n",
    "        #with torch.no_grad(): # no training of BERT parameters\n",
    "        # yes train BERT parameters\n",
    "        \n",
    "        \"\"\"\n",
    "        for param in self.bert.embeddings.parameters():\n",
    "            param.requires_grad = False\n",
    "        for layer in self.bert.encoder.layer[:4]:\n",
    "            for param in layer.parameters():\n",
    "                param.requires_grad = False\n",
    "        \"\"\"\n",
    "        \n",
    "        assert attmasks is not None\n",
    "        with torch.no_grad(): # no training of BERT parameters\n",
    "            #word_rep, sentence_rep = self.bert(sentences, return_dict=False)\n",
    "            word_rep, sentence_rep = self.bert(sentences, encoder_attention_mask=attmasks, attention_mask=attmasks, return_dict=False)\n",
    "        return self.probe(word_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "80af3f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"lab_vocab.json\", \"w\") as outfile:\n",
    "    json.dump(label_vocab, outfile)\n",
    "#del bert_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f03fa02-1ba5-42fa-9b90-85ac6e26b5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-cased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# the model should return a tensor of shape (batch size, sequence length, number of labels)\n",
    "bert_model = LinearProbeBert(len(label_vocab))\n",
    "#y = bert_model(torch.tensor([[0, 1, 2], [3, 4, 5]]).to(device))\n",
    "#print(y.shape)\n",
    "#bert_model.load_state_dict(torch.load(\"./ckpt/posbert.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3acb9bc5-f419-4e27-8bb9-24e13ba6b50c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fit(bert_model, 20, optim.Adam(bert_model.parameters(), lr=1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1af4c2ed-50f4-4cc9-8e96-c1552e238987",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_model.state_dict(), \"./a3distrib/ckpt/posbert1way.pth\")\n",
    "#bert_model.load_state_dict(torch.load(\"./ckpt/posbert.pth\"))\n",
    "#fit(bert_model, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094ae742-9927-433b-8f15-8bb0233aae89",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf(bert_model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e61e8e-49b5-498e-9aed-85dd7eda5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(bert_model.state_dict(), \"./posbertmodel/posbert.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d64e0736-3a08-49a5-84ad-0db6175b9686",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, m = collate_fn(list(zip(test_sentences_ids, test_taggings_ids))[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "230b6036-83af-405d-8a2f-65ff4595e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0.], device='cuda:2')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827b91c6-a51f-41bd-ad18-7510cfa45ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model(x, attmasks=m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "588c0e1a-fea8-44ba-a699-6fadc490ea36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b13c2e01-d753-49be-950d-cc0ce07a6cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
