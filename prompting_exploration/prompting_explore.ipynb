{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ddb8bb0-6340-4f6e-b04e-4d6181895de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "hfcache = '/mnt/data1/prasann/latticegen/lattice-generation/hfcache'\n",
    "os.environ['TRANSFORMERS_CACHE'] = hfcache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cbef25d-0a8f-459d-af90-e58fef8f78fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reverse_meaning_data.txt',\n",
       " 'reverse_sent_data.txt',\n",
       " 'summdoc_data.txt',\n",
       " '.ipynb_checkpoints',\n",
       " 'formal_hand_data.txt',\n",
       " 'simplification_data.txt',\n",
       " 'infilling_data.txt',\n",
       " 'informal_data.txt',\n",
       " 'easy_hand_data.txt']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('./T0_explore_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c54ce56-fd13-4b5e-9baf-c87d01a5fca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "\n",
    "device = \"cuda:1\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bigscience/T0_3B\", cache_dir=hfcache)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/T0_3B\", cache_dir=hfcache)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e43107a4-a304-41fe-b882-388739b3ddca",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = './T0_explore_data/'\n",
    "\n",
    "def read_input_data (fname):\n",
    "    with open(BASE+fname+\".txt\") as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "    while(\"\" in lines) :\n",
    "        lines.remove(\"\")\n",
    "    \n",
    "    return lines\n",
    "\n",
    "infill_data = read_input_data('infilling_data')\n",
    "informal_data = read_input_data('informal_data')\n",
    "revmean_data = read_input_data('reverse_meaning_data')\n",
    "revsent_data = read_input_data('reverse_sent_data')\n",
    "simplif_data = read_input_data('simplification_data')\n",
    "easy_data = read_input_data('easy_hand_data')\n",
    "summ_data = read_input_data('summdoc_data')\n",
    "formalhand_data = read_input_data('formal_hand_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad13428-71ee-48b2-b692-e349ecb0a4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "inf_prompts = [\n",
    "    \"Task: Copy the sentence but replace _ with the correct words. [TEXT]\",\n",
    "    \"Task: replace _ with the correct words. [TEXT]\",\n",
    "    \"[TEXT] What goes in the _ ?\",\n",
    "    \"Task: Fill in the _ in the following sentence. [TEXT]\",\n",
    "]\n",
    "\n",
    "sent_prompts = [\n",
    "    \"Task: what's the opposite of this sentence? [TEXT]\",\n",
    "    \"Copy but say the opposite: [TEXT]\",\n",
    "    \"[TEXT] What is the opposite of this sentence?\",\n",
    "    \"Task: copy but say the opposite emotion. [TEXT]\",\n",
    "    \"Task: copy but say the opposite. [TEXT]\", #\n",
    "]\n",
    "\n",
    "simplif_prompt = [\n",
    "    \"[TEXT] How would I say this in simple words?\",\n",
    "    \"Task: Paraphrase in simpler terms. [TEXT]\",\n",
    "    \"Task: Copy but simplify. [TEXT]\",\n",
    "    \"Task: Simplify the sentence. [TEXT]\"\n",
    "]\n",
    "\n",
    "summ_prompt = [\n",
    "    \"Task: summarize the following paragraph. [TEXT]\",\n",
    "    \"How can I summarize the following? [TEXT]\",\n",
    "]\n",
    "\n",
    "formal_prompt = [\n",
    "    \"Task: How can I say this with more formal language? [TEXT]\",\n",
    "    \"Task: Copy but use formal words. [TEXT]\",\n",
    "    \"[TEXT] How can I rephrase this formally?\",\n",
    "    \"[TEXT] What is a formal way of saying this?\",\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5024c684-e496-4055-80f0-949c12342ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_T0_output(prompt, raw):\n",
    "    inputstring = get_inputstr(prompt, raw)\n",
    "    inputs = tokenizer.encode(inputstring, return_tensors=\"pt\").to(device)\n",
    "    outputs = model.generate(inputs, max_length=50, num_beams=9, num_return_sequences=9, early_stopping=True, output_scores=True, return_dict_in_generate=True)\n",
    "    res = []\n",
    "    #print(outputs)\n",
    "    for i in range(0, len(outputs.sequences)):\n",
    "        tmp = {}\n",
    "        tmp['out_toks'] = tokenizer.decode(outputs.sequences[i])\n",
    "        tmp['out_sco'] = outputs.sequences_scores[i]\n",
    "        res.append(tmp)\n",
    "        print(tmp)\n",
    "    out = {}\n",
    "    out['data'] = res\n",
    "    out['input'] = inputstring\n",
    "    return out\n",
    "        \n",
    "def get_inputstr(prompt, raw):\n",
    "    return prompt.replace(\"[TEXT]\", raw)\n",
    "\n",
    "alldat = []\n",
    "\n",
    "def run_all_data (promptlist, data, label):\n",
    "    global alldat\n",
    "    alldata = []\n",
    "    for p in promptlist:\n",
    "        curtmp = {}\n",
    "        curtmp['prompt'] = p\n",
    "        curtmp['examples'] = []\n",
    "        for d in data:\n",
    "            curtmp['examples'].append(get_T0_output(p, d))\n",
    "        alldata.append(curtmp)\n",
    "    alldat = alldata\n",
    "    for a in alldata:\n",
    "        for e in a['examples']:\n",
    "            for d in e['data']:\n",
    "                d['out_sco'] = float(d['out_sco'])\n",
    "    alldatajson = {}\n",
    "    alldatajson['data'] = alldata\n",
    "    with open('./prompt_output/'+label+'.txt', 'w') as f:\n",
    "        json.dump(alldatajson, f, ensure_ascii=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a5b6cd-85ee-45ad-be71-bd92ac2ae98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_all_data(simplif_prompt, formalhand_data, 'simplifhand_prompt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7f0a0ebd-9a0d-4b31-859d-f3415ab98dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task: Paraphrase with shakespeare language. The rabbit saw the monkey.\n",
      "{'out_toks': '<pad> The rabbit saw the monkey.</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.2448, device='cuda:1')}\n",
      "{'out_toks': '<pad> The monkey saw the rabbit.</s><pad><pad><pad><pad><pad>', 'out_sco': tensor(-0.2870, device='cuda:1')}\n",
      "{'out_toks': '<pad> The rabbit saw a monkey.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.4586, device='cuda:1')}\n",
      "{'out_toks': '<pad> The rabbit sees the monkey.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.4696, device='cuda:1')}\n",
      "{'out_toks': '<pad> The monkey sees the rabbit.</s><pad><pad><pad><pad>', 'out_sco': tensor(-0.5002, device='cuda:1')}\n",
      "{'out_toks': '<pad> A monkey sees a rabbit.</s><pad><pad><pad>', 'out_sco': tensor(-0.6229, device='cuda:1')}\n",
      "{'out_toks': '<pad> A monkey sees a rabbit in the forest.</s>', 'out_sco': tensor(-0.8220, device='cuda:1')}\n",
      "{'out_toks': '<pad> A monkey sees a rabbit and runs away.</s>', 'out_sco': tensor(-0.8323, device='cuda:1')}\n",
      "{'out_toks': '<pad> A monkey and a rabbit are watching each other.</s>', 'out_sco': tensor(-0.8357, device='cuda:1')}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'data': [{'out_toks': '<pad> The rabbit saw the monkey.</s><pad><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.2448, device='cuda:1')},\n",
       "  {'out_toks': '<pad> The monkey saw the rabbit.</s><pad><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.2870, device='cuda:1')},\n",
       "  {'out_toks': '<pad> The rabbit saw a monkey.</s><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.4586, device='cuda:1')},\n",
       "  {'out_toks': '<pad> The rabbit sees the monkey.</s><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.4696, device='cuda:1')},\n",
       "  {'out_toks': '<pad> The monkey sees the rabbit.</s><pad><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.5002, device='cuda:1')},\n",
       "  {'out_toks': '<pad> A monkey sees a rabbit.</s><pad><pad><pad>',\n",
       "   'out_sco': tensor(-0.6229, device='cuda:1')},\n",
       "  {'out_toks': '<pad> A monkey sees a rabbit in the forest.</s>',\n",
       "   'out_sco': tensor(-0.8220, device='cuda:1')},\n",
       "  {'out_toks': '<pad> A monkey sees a rabbit and runs away.</s>',\n",
       "   'out_sco': tensor(-0.8323, device='cuda:1')},\n",
       "  {'out_toks': '<pad> A monkey and a rabbit are watching each other.</s>',\n",
       "   'out_sco': tensor(-0.8357, device='cuda:1')}],\n",
       " 'input': 'Task: Paraphrase with shakespeare language. The rabbit saw the monkey.'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "krishna_prompt = [\n",
    "    \"Task: How would shakespeare say this? [TEXT]\",\n",
    "    \"Task: Paraphrase with shakespeare language. [TEXT]\",\n",
    "    \"Task: Copy but make it sound like a tweet. [TEXT]\",\n",
    "]\n",
    "\n",
    "prompt = krishna_prompt[1]\n",
    "inp = easy_data[12]\n",
    "inputstr = get_inputstr(prompt, inp)\n",
    "print(inputstr)\n",
    "get_T0_output(prompt, inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09cec981-3855-4125-8b9a-041646e45eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pad> The dry sand was hard to grasp.</s><pad>\n",
      "tensor(-0.1610)\n",
      "<pad> The wet sand was hard to grasp.</s>\n",
      "tensor(-0.2598)\n",
      "<pad> The wet sand was easy to grasp.</s>\n",
      "tensor(-0.2707)\n",
      "<pad> The sand was hard to grasp.</s><pad><pad>\n",
      "tensor(-0.3358)\n",
      "<pad> The dry sand was difficult to grasp.</s><pad>\n",
      "tensor(-0.4160)\n"
     ]
    }
   ],
   "source": [
    "#print(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a587b82a-ba20-417c-a339-4fba614b6241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72717c185c7c42a7b6019a0a39f7ef67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/836 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a841e7f91c294bb395e1ff534b6b0850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/11.3G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89db479fadce4333b9c3b57fc6065c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/619 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289b909f73964169ab4114bfc18b2402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/779k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae98c709681148d4accb336e74417939",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "612d96964a5646e3835525c65281184c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea03cf369ebd4b58b5f0d9a191669e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.94k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bab021a7804f00a07e311e1fc53731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-j-6B\", cache_dir=hfcache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744731f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\n",
    "    \"In a shocking finding, scientists discovered a herd of unicorns living in a remote, \"\n",
    "    \"previously unexplored valley, in the Andes Mountains. Even more surprising to the \"\n",
    "    \"researchers was the fact that the unicorns spoke perfect English.\"\n",
    ")\n",
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072e1ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14d4056-5cb6-426b-bef4-3a69ad4c2c43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('latenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
