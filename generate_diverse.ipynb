{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3708c5-ec0f-47fc-a34a-1c7550df5de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 05:56:23.823065: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-26 05:56:23.823087: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from efficient_rerank import run_pipeline, XLMCometEmbeds\n",
    "import torch\n",
    "device = torch.device('cuda:3' if torch.cuda.is_available() else 'cpu')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.recom_search.model.beam_node_reverse import ReverseNode\n",
    "import numpy as np\n",
    "import math \n",
    "from new_flatten_lattice import get_dictlist\n",
    "import flatten_lattice as fl\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "xlm_tok = fl.bert_tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f522882-9c47-4b3c-b91c-80587ce020f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "594d68de-0b77-4a66-97cc-4d147ee9213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO something that gets metrics for diverse decoding top k\n",
    "\n",
    "# load in model, for french\n",
    "#del model\n",
    "model = XLMCometEmbeds(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/maskedcont4.pt\"))\n",
    "model.eval()\n",
    "torch.cuda.memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc40a08c-91d2-46b4-88b9-93fdff825c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78b9af30-052b-499d-bc44-b1ed1f11f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_pipeline(g, model, scofunct, False, 10)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3da86801-9186-488f-80cf-53df0df8ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "DIVWEIGHT = 1\n",
    "# should this be more complex\n",
    "def weightadddiverse (node, used):\n",
    "    global usedlist\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node.token_idx in used:\n",
    "            # TODO maybe we need to add an element that factors in position as well\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6babb-57d1-4cf9-a16e-23a5a005a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "apreds = get_all_preds(base, weightadddiverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4694d5ed-754f-4507-bacf-5680bc9957ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apreds.to_csv(\"div1latpredsfr-en.csv\")\n",
    "apreds = pd.read_csv(\"div1latpredsfr-en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b409dbc-4b8e-4f72-ad2e-563e5778c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> Another variable is the extent to which other developed countries’ monetary policies will become more flexible.',\n",
       " '</s> Another variable is the degree to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which monetary policies in other developed economies will be flexible.',\n",
       " '</s> Another variable is the extent to which the monetary policies of other developed countries become more flexible.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(apreds.loc[2]['hyp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "76e08ae4-ab89-481e-9c47-ad0f479c9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIM = 3\n",
    "def evaluate_diversity_all (preds, n):\n",
    "    totdiv = 0 \n",
    "    ps = 'hyp'\n",
    "    if 'hyp' not in preds.keys():\n",
    "        ps = 'ahyp'\n",
    "    for h in preds[ps]:\n",
    "        if type(h) is str:\n",
    "            hyps = ast.literal_eval(h)\n",
    "        else:\n",
    "            hyps = h\n",
    "        if len(hyps)>LIM:\n",
    "            hyps = hyps[:LIM]\n",
    "        #print(len(cand_unique_ngrams(row['hyp'], xlm_tok, 3)))\n",
    "        #print(len(cand_unique_ngrams(hyps, xlm_tok, 3)))\n",
    "        totdiv+=len(cand_unique_ngrams(hyps, xlm_tok, n))\n",
    "    return totdiv / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "11a3c807-7114-4170-8297-9ab0f37c8e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.38209606986899"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_diversity_all(apreds, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e69e3e62-71b7-42d1-8942-b448d96b1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO something that gets metrics for beam search top k\n",
    "beampreds = pd.read_csv(\"testbeam50fr_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7089a1b2-672c-46c2-8944-9f7f2c3b3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpclump = beampreds.groupby(\"ref\").agg(list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cd337d19-4e8f-4cc9-a235-885963a6a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.28384279475983"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_diversity_all(bpclump, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8652ae-10a0-4264-ba43-11ba75bd25fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
