{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc3708c5-ec0f-47fc-a34a-1c7550df5de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-26 07:56:09.494796: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-11-26 07:56:09.494816: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from efficient_rerank import run_pipeline, XLMCometEmbeds\n",
    "import torch\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from src.recom_search.model.beam_node_reverse import ReverseNode\n",
    "import numpy as np\n",
    "import math \n",
    "from new_flatten_lattice import get_dictlist\n",
    "import flatten_lattice as fl\n",
    "import json\n",
    "import ast\n",
    "import random\n",
    "xlm_tok = fl.bert_tok\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f522882-9c47-4b3c-b91c-80587ce020f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's use this as our evaluation metric for diversity\n",
    "def get_unique_ngrams(sentence, tok, n, uns):\n",
    "    toks = tok(sentence).input_ids\n",
    "    #print(toks)\n",
    "    for i in range(len(toks)-n):\n",
    "        tmp = \"\"\n",
    "        for j in range(i, i+n):\n",
    "            tmp = tmp+\"_\"+str(toks[j])\n",
    "        uns.add(tmp)\n",
    "\n",
    "def cand_unique_ngrams(sentences, tok, n):\n",
    "    uniques = set()\n",
    "    for s in sentences:\n",
    "        get_unique_ngrams(s, tok, n, uniques)\n",
    "    return uniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "594d68de-0b77-4a66-97cc-4d147ee9213a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO something that gets metrics for diverse decoding top k\n",
    "\n",
    "# load in model, for french\n",
    "#del model\n",
    "model = XLMCometEmbeds(drop_rate=0.1)\n",
    "model.load_state_dict(torch.load(\"./torchsaved/maskedcont4.pt\"))\n",
    "model.eval()\n",
    "torch.cuda.memory_allocated(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc40a08c-91d2-46b4-88b9-93fdff825c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "base = \"frtest_reversed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "78b9af30-052b-499d-bc44-b1ed1f11f7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output for a single index out of available graphs\n",
    "def test_graph_ind(ind, basedir, scofunct):\n",
    "    g = pickle.load(open(basedir+str(ind), 'rb'))\n",
    "    #if g['input'] in old['src']:\n",
    "    #    return None, None, None\n",
    "    #try:\n",
    "    global usedlist\n",
    "    usedlist = []\n",
    "    options = []\n",
    "    # TODO add a verbose option for efficient reranking so that it doesn't blow up nb\n",
    "    return g['input'], g['ref'], run_pipeline(g, model, scofunct, False, 10)\n",
    "\n",
    "# get predictions for a bunch of stuff\n",
    "def get_all_preds(basedir, scofunct):\n",
    "    l = len(os.listdir(basedir))\n",
    "    result = []\n",
    "    print(\"will predict total of \", l)\n",
    "    for i in range(l):\n",
    "        inp, r, p = test_graph_ind(i, basedir, scofunct)\n",
    "        result.append({\n",
    "            'src':inp,\n",
    "            'hyp':p,\n",
    "            'ref':r\n",
    "        })\n",
    "        print(i)\n",
    "    result = pd.DataFrame(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3da86801-9186-488f-80cf-53df0df8ca8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEIGHT=50\n",
    "#DIVWEIGHT = 1\n",
    "#doadd = True\n",
    "DIVWEIGHT = 1\n",
    "doadd = True\n",
    "    \n",
    "def tokendiverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        tcnt = [u.token_idx for u in used].count(node.token_idx)\n",
    "        return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*tcnt\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def nodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            if doadd:\n",
    "                return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1\n",
    "    \n",
    "def extranodediverse (node, used):\n",
    "    if hasattr(node, \"prob\"):\n",
    "        #pcnt+=1\n",
    "        if node in used:\n",
    "            return math.log(node.prob) + WEIGHT*node.score - DIVWEIGHT*used.count(node)\n",
    "        return math.log(node.prob) + WEIGHT*node.score\n",
    "    else:\n",
    "        #npcnt+=1\n",
    "        return 1    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "34a3bc07-fa9f-43f0-8f89-b715d9a9da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original nodes -  595\n",
      "final detokd -  616\n",
      "maxend , 45\n",
      "maxend , 45\n",
      "maxend , 46\n",
      "maxend , 46\n",
      "maxend , 46\n",
      "maxend , 46\n",
      "maxend , 46\n",
      "maxend , 46\n",
      "maxend , 46\n",
      "maxend , 46\n"
     ]
    }
   ],
   "source": [
    "t1 = test_graph_ind(1, base, tokendiverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8a9e9570-f4f9-4034-8a94-e2760c36cc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> As Iran sought to expand its influence and assert its interests, as well as those of its Shiite allies, discussions with the Council became closely linked to regional ambition.',\n",
       " '</s> As Iran sought to extend its influence and assert its interests, along with those of its Shia allies, discussions in the Security Council have become closely tied to regional ambition.',\n",
       " '</s> As Iran sought to expand its influence and advance its interests, as well as those of its Shiite allies, discussions in the Security Council became intimately linked with regional ambition.',\n",
       " '</s> As Iran sought to extend its influence and assert its interests, along with those of its Shiite allies, talks in the Security Council became closely bound up with regional aspirations.',\n",
       " '</s> As Iran sought to expand its influence and advance its interests, as well as those of its Shia allies, discussions in the Security Council have become closely related to regional ambition.',\n",
       " '</s> As Iran sought to extend its influence and assert its interests, along with those of its Shiite allies, the discussion with the Security Council became intimately tied to regional ambition.',\n",
       " '</s> As Iran sought to expand its influence and advance its interests, as well as those of its Shiite allies, talks in the Security Council were closely bound up with regional aspirations.',\n",
       " '</s> As Iran sought to extend its influence and assert its interests, along with those of its Shia allies, talks in the Security Council became tightly linked to regional ambition.',\n",
       " '</s> As Iran sought to expand its influence and assert its interests, along with those of its Shiite allies, the discussions within the Council have become intimately connected with regional ambition.',\n",
       " '</s> As Iran sought to extend its influence and advance its interests, as well as those of its Shiite allies, talks in the Security Council became strongly linked to regional ambition.']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "68d4bb5d-b8da-4177-ba1f-94172e87f455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cand_unique_ngrams(t1[2], xlm_tok, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6fc9211-a1ab-4cb3-b708-a6152104f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd6babb-57d1-4cf9-a16e-23a5a005a652",
   "metadata": {},
   "outputs": [],
   "source": [
    "apreds = get_all_preds(base, tokendiverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4694d5ed-754f-4507-bacf-5680bc9957ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# token, with stacked weighting - stackweightlatpredsfr-en.csv\n",
    "# token, no stacked weighting - div1latpredsfr-en.csv\n",
    "# unrolled with predictions - stackweightcometsfr-en.csv\n",
    "#apreds.to_csv(\"stackweightlatpredsfr-en.csv\")\n",
    "apreds = pd.read_csv(\"stackweightlatpredsfr-en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b409dbc-4b8e-4f72-ad2e-563e5778c216",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['</s> Another variable is the extent to which other developed countries’ monetary policies will become more flexible.',\n",
       " '</s> Another variable is the degree to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the extent to which monetary policy in other developed economies become more flexible.',\n",
       " '</s> Another variable is the degree to which monetary policies in other developed nations will be flexible.',\n",
       " '</s> Another variable is the extent to which other developed countries’ monetary policies will ease.',\n",
       " '</s> Another variable is the degree to which monetary policy in other advanced economies become looser.',\n",
       " '</s> Another variable is the extent to which monetary policies of other advanced countries are becoming more flexible.',\n",
       " '</s> Another variable is the degree to which monetary policy in other developed nations will relax.',\n",
       " '</s> Another variable is the extent to which monetary policies of other advanced economies become less rigid.',\n",
       " '</s> Another variable is the degree to which other developed countries’ monetary policy will liberalize.']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ast.literal_eval(apreds.loc[2]['hyp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76e08ae4-ab89-481e-9c47-ad0f479c9230",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIM = 3\n",
    "def evaluate_diversity_all (preds, n):\n",
    "    totdiv = 0 \n",
    "    ps = 'hyp'\n",
    "    if 'hyp' not in preds.keys():\n",
    "        ps = 'ahyp'\n",
    "    for h in preds[ps]:\n",
    "        if type(h) is str:\n",
    "            hyps = ast.literal_eval(h)\n",
    "        else:\n",
    "            hyps = h\n",
    "        if len(hyps)>LIM:\n",
    "            hyps = hyps[:LIM]\n",
    "        #print(len(cand_unique_ngrams(row['hyp'], xlm_tok, 3)))\n",
    "        #print(len(cand_unique_ngrams(hyps, xlm_tok, 3)))\n",
    "        totdiv+=len(cand_unique_ngrams(hyps, xlm_tok, n))\n",
    "    return totdiv / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11a3c807-7114-4170-8297-9ab0f37c8e14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.86026200873363"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_diversity_all(apreds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e69e3e62-71b7-42d1-8942-b448d96b1127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO something that gets metrics for beam search top k\n",
    "beampreds = pd.read_csv(\"testbeam50fr_en.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7089a1b2-672c-46c2-8944-9f7f2c3b3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpclump = beampreds.groupby(\"ref\").agg(list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd337d19-4e8f-4cc9-a235-885963a6a7eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.7707423580786"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_diversity_all(bpclump, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0b8652ae-10a0-4264-ba43-11ba75bd25fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare preds for COMET rescoring\n",
    "def preds_to_complete(preddf):\n",
    "    res = []\n",
    "    for index, row in preddf.iterrows():\n",
    "        hyps = ast.literal_eval(row['hyp'])\n",
    "        for h in hyps:\n",
    "            \n",
    "            res.append({\n",
    "                'src':row['src'],\n",
    "                'ref':row['ref'],\n",
    "                'hyp':h\n",
    "            })\n",
    "    return pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3aeb89c-b613-4bed-8e86-ce00046596f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mt_scores import get_scores_auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "74634eab-8273-4296-8d32-7de9a1122778",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_act_hyps(hyplist, cutoff):\n",
    "    res = []\n",
    "    for h in hyplist:\n",
    "        cind = h.index(cutoff)+len(cutoff)\n",
    "        res.append(h[cind:])\n",
    "    return res\n",
    "\n",
    "def get_process_lpreds(preddf):\n",
    "    lpreds = preddf\n",
    "    #lpreds['ind'] = lpreds['Unnamed: 0']\n",
    "    lpreds = lpreds.dropna()\n",
    "    if \"ahyp\" not in lpreds.keys():\n",
    "        lpreds['ahyp'] = get_act_hyps(lpreds['hyp'], \"</s>\")\n",
    "    if \"comet\" not in lpreds.keys():\n",
    "        comsco = get_scores_auto(lpreds['ahyp'], lpreds['src'], lpreds['ref'], \"comet\", \"\")\n",
    "        lpreds['comet'] = comsco\n",
    "    return lpreds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "312611a2-2fa5-4be3-a754-1bc0d2b25a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "predprepped = preds_to_complete(apreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0d97e45-1d26-4358-9f1b-ce9468d5dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wmt20-comet-da is already in cache.\n",
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.dense.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\n",
      "Predicting: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0:   0%|                                                                              | 0/144 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|████████████████████████████████████████████████████████████████████| 144/144 [00:40<00:00,  3.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|████████████████████████████████████████████████████████████████████| 144/144 [00:40<00:00,  3.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOOK TIME  41.94\n"
     ]
    }
   ],
   "source": [
    "newdf = get_process_lpreds(predprepped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ac97ece7-167b-4023-91cd-77ca9de02cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4513895671456792"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(newdf['comet'])/len(newdf['comet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7a249f24-81b6-4b88-94ad-b6dc339a8942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6592082606633417"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(beampreds['comet'])/len(beampreds['comet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bcc23c9b-020d-45d9-a6cf-4dcad473f52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>hyp</th>\n",
       "      <th>ahyp</th>\n",
       "      <th>comet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>&lt;/s&gt; After all, as a field investigative journ...</td>\n",
       "      <td>After all, as a field investigative journalis...</td>\n",
       "      <td>-0.211310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>&lt;/s&gt; After all, as a field investigative journ...</td>\n",
       "      <td>After all, as a field investigative journalis...</td>\n",
       "      <td>0.262921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>&lt;/s&gt; After all, as an investigative journalist...</td>\n",
       "      <td>After all, as an investigative journalist on ...</td>\n",
       "      <td>-0.289604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>&lt;/s&gt; After all, as a field investigative journ...</td>\n",
       "      <td>After all, as a field investigative journalis...</td>\n",
       "      <td>0.326253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Après tout, en tant que journaliste d'investig...</td>\n",
       "      <td>After all, as a campaigning investigative jour...</td>\n",
       "      <td>&lt;/s&gt; After all, as an investigative reporter i...</td>\n",
       "      <td>After all, as an investigative reporter in th...</td>\n",
       "      <td>-0.203522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4575</th>\n",
       "      <td>Au plan intérieur également, une méfiance géné...</td>\n",
       "      <td>At home, too, massive distrust will further co...</td>\n",
       "      <td>&lt;/s&gt; At home, too, widespread mistrust would c...</td>\n",
       "      <td>At home, too, widespread mistrust would compl...</td>\n",
       "      <td>0.784285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4576</th>\n",
       "      <td>Au plan intérieur également, une méfiance géné...</td>\n",
       "      <td>At home, too, massive distrust will further co...</td>\n",
       "      <td>&lt;/s&gt; Internally, too, a generalized mistrust w...</td>\n",
       "      <td>Internally, too, a generalized mistrust will ...</td>\n",
       "      <td>0.231514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4577</th>\n",
       "      <td>Au plan intérieur également, une méfiance géné...</td>\n",
       "      <td>At home, too, massive distrust will further co...</td>\n",
       "      <td>&lt;/s&gt; At home, too, widespread distrust will ad...</td>\n",
       "      <td>At home, too, widespread distrust will add to...</td>\n",
       "      <td>0.695930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>Au plan intérieur également, une méfiance géné...</td>\n",
       "      <td>At home, too, massive distrust will further co...</td>\n",
       "      <td>&lt;/s&gt; Internally, too, a generalized mistrust w...</td>\n",
       "      <td>Internally, too, a generalized mistrust would...</td>\n",
       "      <td>0.687333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4579</th>\n",
       "      <td>Au plan intérieur également, une méfiance géné...</td>\n",
       "      <td>At home, too, massive distrust will further co...</td>\n",
       "      <td>&lt;/s&gt; At home, too, widespread distrust will ma...</td>\n",
       "      <td>At home, too, widespread distrust will make i...</td>\n",
       "      <td>0.776998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4580 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    src  \\\n",
       "0     Après tout, en tant que journaliste d'investig...   \n",
       "1     Après tout, en tant que journaliste d'investig...   \n",
       "2     Après tout, en tant que journaliste d'investig...   \n",
       "3     Après tout, en tant que journaliste d'investig...   \n",
       "4     Après tout, en tant que journaliste d'investig...   \n",
       "...                                                 ...   \n",
       "4575  Au plan intérieur également, une méfiance géné...   \n",
       "4576  Au plan intérieur également, une méfiance géné...   \n",
       "4577  Au plan intérieur également, une méfiance géné...   \n",
       "4578  Au plan intérieur également, une méfiance géné...   \n",
       "4579  Au plan intérieur également, une méfiance géné...   \n",
       "\n",
       "                                                    ref  \\\n",
       "0     After all, as a campaigning investigative jour...   \n",
       "1     After all, as a campaigning investigative jour...   \n",
       "2     After all, as a campaigning investigative jour...   \n",
       "3     After all, as a campaigning investigative jour...   \n",
       "4     After all, as a campaigning investigative jour...   \n",
       "...                                                 ...   \n",
       "4575  At home, too, massive distrust will further co...   \n",
       "4576  At home, too, massive distrust will further co...   \n",
       "4577  At home, too, massive distrust will further co...   \n",
       "4578  At home, too, massive distrust will further co...   \n",
       "4579  At home, too, massive distrust will further co...   \n",
       "\n",
       "                                                    hyp  \\\n",
       "0     </s> After all, as a field investigative journ...   \n",
       "1     </s> After all, as a field investigative journ...   \n",
       "2     </s> After all, as an investigative journalist...   \n",
       "3     </s> After all, as a field investigative journ...   \n",
       "4     </s> After all, as an investigative reporter i...   \n",
       "...                                                 ...   \n",
       "4575  </s> At home, too, widespread mistrust would c...   \n",
       "4576  </s> Internally, too, a generalized mistrust w...   \n",
       "4577  </s> At home, too, widespread distrust will ad...   \n",
       "4578  </s> Internally, too, a generalized mistrust w...   \n",
       "4579  </s> At home, too, widespread distrust will ma...   \n",
       "\n",
       "                                                   ahyp     comet  \n",
       "0      After all, as a field investigative journalis... -0.211310  \n",
       "1      After all, as a field investigative journalis...  0.262921  \n",
       "2      After all, as an investigative journalist on ... -0.289604  \n",
       "3      After all, as a field investigative journalis...  0.326253  \n",
       "4      After all, as an investigative reporter in th... -0.203522  \n",
       "...                                                 ...       ...  \n",
       "4575   At home, too, widespread mistrust would compl...  0.784285  \n",
       "4576   Internally, too, a generalized mistrust will ...  0.231514  \n",
       "4577   At home, too, widespread distrust will add to...  0.695930  \n",
       "4578   Internally, too, a generalized mistrust would...  0.687333  \n",
       "4579   At home, too, widespread distrust will make i...  0.776998  \n",
       "\n",
       "[4580 rows x 5 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2546bf75-07a6-4bed-b209-5c9480c6f355",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12 (default, Oct 12 2021, 13:49:34) \n[GCC 7.5.0]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c2f77846b0243d2dee26bbaa6fd0a0b34a7adea800a5063b4b91f2f98ac96800"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
