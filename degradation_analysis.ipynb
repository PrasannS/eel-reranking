{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b33fc0-6d93-4f8f-8413-57dde477187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook to pinpoint degradation, rapid fire some more ideas, using noun setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b5cec5-1c20-41d8-b5fa-e2255b2f3d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-19 05:44:28.260715: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-19 05:44:28.260738: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3cb914-a97a-496c-926f-846c3a76368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get graph to examine\n",
    "ind = 3\n",
    "#base = \"outputs/graph_pickles/frenchbeam50_reversed/\"\n",
    "base = \"outputs/graph_pickles/frtest_reversed/\"\n",
    "graph = pickle.load(open(base+str(ind), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bedae011-9503-4b80-95dc-ec0e18a4b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get exploded paths, scored, for the graph\n",
    "#noun_explode = pd.read_csv(\"outputs/score_csvs/frenbeam50v1.csv\")\n",
    "noun_explode = pd.read_csv(\"outputs/score_csvs/nounexplodev1.csv\")\n",
    "texplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "bestcand = np.argmax(list(texplode['utnoun']))\n",
    "bestcand = texplode.iloc[bestcand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be428eea-a3a3-4a73-a395-31710aa11d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n"
     ]
    }
   ],
   "source": [
    "bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "            flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, default_scofunct, \"noun\", {'afunc':useall}, True)\n",
    "predhyp = bestpath[0][4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54d10c42-6c6f-45ee-934b-562347bef46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                      108283\n",
       "Unnamed: 0                                                 108283\n",
       "src             Il nous faut négocier un nouvel accord de part...\n",
       "ref             A new Partnership and Cooperation Agreement (P...\n",
       "hyp             We need to negotiate a new Partnership and Coo...\n",
       "utnoun                                                   1.255471\n",
       "unique_nouns                                                   12\n",
       "Name: 300, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestcand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f3e423-d79e-4efb-a139-7e22c9197607",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82c7f0d4-b7f4-4ad8-b38a-1a414e0fe49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "encodemod = get_effrerank_model(\"noun\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9326386-4d31-4d77-97e6-cbb402823871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsingle(mask, row, checknodes, mlen):\n",
    "    if row>0:\n",
    "        avail = []\n",
    "        # use next with highest prob\n",
    "        for n in checknodes:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                avail.append(n)\n",
    "        if len(avail)==0:\n",
    "            print(len(checknodes))\n",
    "            print(row)\n",
    "        mask[row][random.choice(avail).canvpos] = 1\n",
    "        \n",
    "def useall(mask, row, checknodes, mlen):\n",
    "    if row>0:\n",
    "        # use next with highest prob\n",
    "        for n in checknodes:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                mask[row][n.canvpos] = 1\n",
    "        \n",
    "# randomly use nodes, but possibility of more than one previous node being used\n",
    "def randommulti(mask, row, checknodes, mlen):\n",
    "    if row>0:\n",
    "        avail = []\n",
    "        # use next with highest prob\n",
    "        for n in checknodes:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                avail.append(n)\n",
    "        if len(avail)==0:\n",
    "            print(len(checknodes))\n",
    "            print(row)\n",
    "        #mask[row][random.choice(avail).canvpos] = 1\n",
    "        \n",
    "        tosamp = random.randint(1, len(avail))\n",
    "        samp = random.sample(avail, tosamp)\n",
    "        # use next with highest prob\n",
    "        for n in samp:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                mask[row][n.canvpos] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "765b0121-6fd7-43df-8771-280b89cffcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score check (at token level) the best option, and the new option (should be same until they get to non-identical tokens)\n",
    "\n",
    "SETLEN = 457\n",
    "\n",
    "# get token level scores from model\n",
    "def get_hyp_sco(inphyp, posids=None):\n",
    "    \n",
    "    tokens = xlm_tok(inphyp, return_tensors='pt').to(device)\n",
    "    tokens = tokens.input_ids\n",
    "    if posids is None: \n",
    "        positionids = torch.arange(len(tokens[0])).unsqueeze(0).to(device)\n",
    "    else:\n",
    "        # get token at the end\n",
    "        positionids = torch.tensor(posids+[posids[-1]+1]).unsqueeze(0).to(device)\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(device)\n",
    "    #print(tokens.shape)\n",
    "    #print(positionids.shape)\n",
    "    #print()\n",
    "    #print(tokens.shape)\n",
    "    #print(torch.max(positionids))\n",
    "    toked_inp = xlm_tok([\"noun\"], return_tensors=\"pt\").to(device)\n",
    "    predout = encodemod(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    tmppred = predout['score']\n",
    "    #norm = predout['norm']\n",
    "    return tmppred\n",
    "\n",
    "# test out reranking multiple EEL outputs (observe improvements)\n",
    "def lattice_multi_rerank(ind, n):\n",
    "    # get graph, get the \"best candidate\"\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    nexplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "    print(len(nexplode))\n",
    "    if len(nexplode)==0:\n",
    "        return None\n",
    "    bestcand = np.argmax(list(nexplode['utnoun']))\n",
    "    bestcand = nexplode.iloc[bestcand]\n",
    "    \n",
    "    goldsco = get_hyp_sco(bestcand['hyp'])\n",
    "    goldsco = torch.sum(goldsco[0])\n",
    "    bpred = -100\n",
    "    bhyp = \"\"\n",
    "    ascos = []\n",
    "    ahyps = []\n",
    "    numnodes = 0\n",
    "    for i in range(n):\n",
    "        graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "        # generate with model\n",
    "        bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "            flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, default_scofunct, \"noun\", {'afunc':useall}, True)\n",
    "        predhyp = bestpath[0][4:]\n",
    "        hypsco = torch.sum(get_hyp_sco(predhyp)[0])\n",
    "        if hypsco>bpred:\n",
    "            bpred = hypsco\n",
    "            bhyp = predhyp\n",
    "        ascos.append(hypsco)\n",
    "        ahyps.append(predhyp)\n",
    "        numnodes = len(flattened)\n",
    "    return bpred, bhyp, goldsco, bestcand['hyp'], ascos, ahyps, numnodes\n",
    "\n",
    "# get multiple things with the lattice, rerank on each (not optimized, so it is a bit slow)\n",
    "def all_lattice_multi(n):\n",
    "    pdistr = []\n",
    "    cnt = 0\n",
    "    for i in range(SETLEN):\n",
    "        try:\n",
    "            outval = lattice_multi_rerank(i, n)\n",
    "        except:\n",
    "            continue\n",
    "        if outval==None:\n",
    "            continue\n",
    "        else:\n",
    "            print(cnt, \" \", i, \" \", outval[0], \" \", outval[2], \" \")\n",
    "            pdistr.append({\n",
    "                'hyp':outval[1],\n",
    "                'hypsco':outval[0],\n",
    "                'gold':outval[3],\n",
    "                'goldsco':outval[2],\n",
    "                'ascos':[float(f) for f in outval[4]],\n",
    "                'ahyps':outval[5],\n",
    "                'numnodes':outval[6]\n",
    "            })\n",
    "            cnt+=1\n",
    "    res = pd.DataFrame(pdistr)\n",
    "    return res\n",
    "\n",
    "# rerank given a random sample\n",
    "def all_unnoun_multi():\n",
    "    pdistr = []\n",
    "    cnt = 0\n",
    "    for i in range(SETLEN):\n",
    "        try:\n",
    "            graph = pickle.load(open(base+str(i), 'rb'))\n",
    "        except:\n",
    "            break\n",
    "        nexplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "        if len(nexplode)==0:\n",
    "            continue\n",
    "        nexplode = nexplode.sample(n=51)\n",
    "        assert len(nexplode)==51\n",
    "        bestcand = np.argmax(list(nexplode['utnoun']))\n",
    "        bestcand = nexplode.iloc[bestcand]\n",
    "\n",
    "        goldsco = get_hyp_sco(bestcand['hyp'])\n",
    "        goldsco = torch.sum(goldsco[0])\n",
    "        pdistr.append(goldsco)\n",
    "    \n",
    "    return pdistr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2226624f-7b99-4a2b-b877-b330ddbc3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnoun = all_unnoun_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0213fd33-a9cf-4353-a36f-d4895c54a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "492cd70d-c5d1-4b19-8297-2b2d11d34617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8715, device='cuda:1', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(unnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8fd17-8c61-4cfd-bf5a-24fdc508a5ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39caf9-bd68-4aca-850e-a610c7000631",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti = all_lattice_multi(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9940da7a-691b-4e13-9a04-431ad52a12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# allmulti.to_csv(\"outputs/predcsvs/noun_comstyle_beam50.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f4f9ca38-a694-4040-8747-86a0baeb5368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allmulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "463df3af-ea19-48a1-b48f-7809ac336846",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti = pd.read_csv(\"outputs/predcsvs/noun_comstyle_multi_32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75cac813-5596-4353-a620-0c935c891656",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldamult = allmulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2852a338-0f51-4bda-bdb7-6b80e29bf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold values are the same...\n",
    "for i in range(len(allmulti)):\n",
    "    if allmulti['gold'].iloc[i] not in oldamult['gold'].iloc[i]:\n",
    "        print(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8cb619dc-5f9a-4446-977f-93a94fcf0c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8799, device='cuda:1', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "def mean(l):\n",
    "        \n",
    "    l = list(l)\n",
    "    if type(l[0]) is str:\n",
    "        l = [float(re.findall(\"\\d+\\.\\d+\", lent)[0]) for lent in l]\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "mean(allmulti['hypsco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c57df72d-dacd-4744-b7d8-1b7600d16ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti['unoun'] = [float(f) for f in unnoun]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29bfd578-5984-4911-8050-eceb09b9519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti['hypsco']  = [float(re.findall(\"\\d+\\.\\d+\", lent)[0]) for lent in allmulti['hypsco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f25690c0-819e-4b1c-908d-eeaf952e47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti['goldsco']  = [float(re.findall(\"\\d+\\.\\d+\", lent)[0]) for lent in allmulti['goldsco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e9e8ba94-45db-4b82-a7b9-266614238c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8dceb051-e0d3-4535-a4e6-a8063bb80aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  3., 22., 18., 28., 16.,  5.,  3.,  2.]),\n",
       " array([-0.16865671, -0.11990161, -0.07114651, -0.02239141,  0.02636368,\n",
       "         0.07511878,  0.12387388,  0.17262897,  0.22138407,  0.27013917,\n",
       "         0.31889427]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([float(f) for f in list(allmulti['goldsco']-allmulti['hypsco'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5dc04437-1cae-4a37-9f4b-b13564e88fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allmulti[allmulti['numnodes']>512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c0b1a89-6b07-4310-8f9d-a0ef4f853889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At a time when all nations are facing their own challenges, there is a need to forge a common agenda at the global level that will ensure that the seven billionth baby and future generations grow up in a world of peace, prosperity, freedom and justice that lasts.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmulti[allmulti['goldsco']-allmulti['hypsco']>.2]['gold'].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6873d830-cf54-44ce-aec6-aeec66fcea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8882, device='cuda:1', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(allmulti['hypsco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce368595-413b-4112-a3f3-a7bac0f532d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "generated - \n",
      "We need to negotiate a new Partnership and Cooperation Agreement (PCA) between the European Union and the Russian Federation, following the suspension of the talks due to start last year have been suspended because of the war in Georgia.\n"
     ]
    }
   ],
   "source": [
    "ind = 3\n",
    "# get model output\n",
    "graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "sco_funct = default_scofunct\n",
    "bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "        flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, sco_funct, \"noun\", {'afunc':randomsingle}, True)\n",
    "predhyp = bestpath[0][4:]\n",
    "print(\"generated - \\n\"+predhyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fc18d6cf-49e0-4e70-9297-038778885894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "We need to negotiate a new Partnership and Cooperation Agreement (PCA), between the European Union and the Russian Federation, following the suspension of talks to begin last year were suspended because of the war in Georgia.\n",
      "tensor(1.2150, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "We need to negotiate a new Partnership and Cooperation Agreement (PCA) between the European Union and the Russian Federation, following the suspension of the talks due to start last year have been suspended because of the war in Georgia.\n",
      "tensor(1.2311, device='cuda:1', grad_fn=<SumBackward0>)\n",
      "[tensor([1.3037], device='cuda:1')]\n"
     ]
    }
   ],
   "source": [
    "bestsco = get_hyp_sco(bestcand['hyp'])\n",
    "hypsco = get_hyp_sco(predhyp)\n",
    "print(bestcand['hyp'])\n",
    "print(torch.sum(bestsco[0]))\n",
    "print(predhyp)\n",
    "print(torch.sum(hypsco[0]))\n",
    "print(bsco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cae5e4d6-2cd4-4385-819a-2b9b20c3f756",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "index                                                      108283\n",
       "Unnamed: 0                                                 108283\n",
       "src             Il nous faut négocier un nouvel accord de part...\n",
       "ref             A new Partnership and Cooperation Agreement (P...\n",
       "hyp             We need to negotiate a new Partnership and Coo...\n",
       "utnoun                                                   1.255471\n",
       "unique_nouns                                                   12\n",
       "Name: 300, dtype: object"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestcand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b3825e66-875b-4898-a81c-2a727b731788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that masks are functioning in an ok way (passed)\n",
    "def mask_sanity(msk, inps, posids):\n",
    "    allinps = []\n",
    "    allpos = []\n",
    "    for m in msk:\n",
    "        # get spare\n",
    "        tmptoks = []\n",
    "        tmppos = []\n",
    "        for t in range(len(m)):\n",
    "            if m[t]!=0:\n",
    "                tmptoks.append(inps[t])\n",
    "                tmppos.append(posids[t])\n",
    "        resort = sorted(zip(tmppos, tmptoks))\n",
    "        tmptoks = [x for _,x in resort]\n",
    "        tmppos = [x for x, _ in resort]\n",
    "        allinps.append(torch.tensor(tmptoks).int())\n",
    "        allpos.append(tmppos)\n",
    "    return allinps, allpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7496785e-4f58-4a94-ab39-61d6a721eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]\n",
    "b = ['a', 'b']\n",
    "c = zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f6d1366-ff08-4e10-99f7-90b60451db51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0bea43a-b983-4847-b787-8bff05432d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score check (at token level) the best option, and the new option (should be same until they get to non-identical tokens)\n",
    "\n",
    "# get token level scores from model\n",
    "def get_hyp_sco_verb(inphyp, posids=None):\n",
    "    \n",
    "    tokens = xlm_tok(inphyp, return_tensors='pt').to(device)\n",
    "    tokens = tokens.input_ids\n",
    "    #print(inphyp)\n",
    "    #print(tokens)\n",
    "    if posids is None: \n",
    "        positionids = torch.arange(len(tokens[0])).unsqueeze(0).to(device)\n",
    "    else:\n",
    "        # get token at the end\n",
    "        positionids = torch.tensor(posids+[posids[-1]+1]).unsqueeze(0).to(device)\n",
    "    #print(positionids)\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(device)\n",
    "    #print(tokens.shape)\n",
    "    #print(positionids.shape)\n",
    "    #print()\n",
    "    #print(tokens.shape)\n",
    "    #print(torch.max(positionids))\n",
    "    toked_inp = xlm_tok([\"noun\"], return_tensors=\"pt\").to(device)\n",
    "    predout = encodemod(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    tmppred = predout['score']\n",
    "    #norm = predout['norm']\n",
    "    return tmppred, tokens, positionids, tmpmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c85186c-b788-426e-940d-85e17145ae41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ainps, apos = mask_sanity(mask, sents[0], posids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "471a3e99-a58a-4711-af00-278ae42bd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsens = xlm_tok.batch_decode(ainps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aea7f9f-40fd-45a3-8492-d8da60230f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "index = 40\n",
    "#print(apos[index])\n",
    "p_pred, p_tok, p_pos, p_mask = get_hyp_sco_verb(testsens[index][4:], apos[index])\n",
    "n_pred, n_tok, n_pos, n_mask = get_hyp_sco_verb(testsens[index][4:], None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "42867136-3d3a-4f92-9489-90773329536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0007452319841831923, 0.0007105700206011534),\n",
       " (0.0006145313382148743, 0.0005859484663233161),\n",
       " (0.0007824336062185466, 0.000746041361708194),\n",
       " (0.0009718615328893065, 0.0009266586857847869),\n",
       " (0.003711999161168933, 0.0035393480211496353),\n",
       " (0.001512863440439105, 0.001442497712559998),\n",
       " (0.0007613550405949354, 0.0007259431877173483),\n",
       " (0.00079939333954826, 0.000762212264817208),\n",
       " (0.017123648896813393, 0.016327200457453728),\n",
       " (0.003832751652225852, 0.0036544841714203358),\n",
       " (0.004214657936245203, 0.004018627107143402),\n",
       " (0.02993575483560562, 0.028543394058942795),\n",
       " (0.004783897660672665, 0.004561391193419695),\n",
       " (0.03646809235215187, 0.03477190434932709),\n",
       " (0.006932106800377369, 0.00660968292504549),\n",
       " (0.044528160244226456, 0.042457081377506256),\n",
       " (0.00988731812685728, 0.009427443146705627),\n",
       " (0.011662271805107594, 0.011119840666651726),\n",
       " (0.019538961350917816, 0.018630173057317734),\n",
       " (0.012992732226848602, 0.012388419359922409),\n",
       " (0.03538692742586136, 0.033741023391485214),\n",
       " (0.057418324053287506, 0.05474770441651344),\n",
       " (0.018466796725988388, 0.017607875168323517),\n",
       " (0.016126157715916634, 0.015376103110611439),\n",
       " (0.03505236282944679, 0.033422019332647324),\n",
       " (0.0720919743180275, 0.06873886287212372),\n",
       " (0.00913100317120552, 0.008706305176019669),\n",
       " (0.024017371237277985, 0.022900285199284554),\n",
       " (0.030602948740124702, 0.029179556295275688),\n",
       " (0.020783530548214912, 0.01981685496866703),\n",
       " (0.05261491611599922, 0.05016770958900452),\n",
       " (0.024976646527647972, 0.02513606660068035),\n",
       " (0.024182399734854698, 0.019354261457920074),\n",
       " (0.020925935357809067, 0.020006215199828148),\n",
       " (0.018922332674264908, 0.02139292284846306),\n",
       " (0.01820361241698265, 0.018312061205506325),\n",
       " (0.018443264067173004, 0.023999519646167755),\n",
       " (0.09499096870422363, 0.09791689366102219),\n",
       " (0.0275835320353508, 0.02734983153641224),\n",
       " (0.043749626725912094, 0.03722778707742691),\n",
       " (0.006756143644452095, 0.008136013522744179),\n",
       " (0.022043153643608093, 0.022126618772745132),\n",
       " (0.007487333379685879, 0.007296714000403881)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip([float(f) for f in p_pred[0]], [float(f) for f in n_pred[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e5dc36-6f53-4863-8fb9-0eb072237d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "pred1, tok1, pos1, mask1 = get_hyp_sco_verb(\"I am nice\")\n",
    "pred2, tok2, pos2, mask2 = get_hyp_sco_verb(\"I am cool\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97ba37cb-4836-4592-9052-cc0ff58c4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000],\n",
      "         [0.0074],\n",
      "         [0.0029],\n",
      "         [0.0081],\n",
      "         [0.0036]]], device='cuda:1', grad_fn=<DivBackward0>)\n",
      "tensor([[[0.0000],\n",
      "         [0.0074],\n",
      "         [0.0029],\n",
      "         [0.0080],\n",
      "         [0.0054]]], device='cuda:1', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred1)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72c979e1-e7eb-4afb-9ad0-4f82f59e7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpos = []\n",
    "for pl in apos:\n",
    "    tmp = []\n",
    "    for p in pl:\n",
    "        tmp.append(int(p))\n",
    "    fpos.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d4dce-36c6-4f5e-8098-637ef0cd7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos ids as a source of degradation?\n",
    "for i in range(1, len(fpos)):\n",
    "    for j in range(1, len(fpos[i])):\n",
    "        if fpos[i][j] is not fpos[i][j-1]+1:\n",
    "            print(\"off at \", i, \" \", fpos[i][j-1], \" \",fpos[i][j] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38768fc2-52e2-420c-835d-7ac3a975358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpos[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8c4e12-996b-44ac-9708-af5f130e0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_graph_ind(base, ind, model, funct, outfile):\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    return {\n",
    "        'hyp':run_comstyle(graph, model, funct, outfile, False)[0],\n",
    "        'ref':graph['ref'],\n",
    "        'src':graph['input']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c34654-f958-4105-9e1b-e54e2b40ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "\n",
    "from test_efficient_rerank import test_graph_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1bcd8b-0f9a-408d-88c8-a60ff09e4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(l):\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9d32ca-5164-4d35-897f-2eaffbe2c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_explode = pd.read_csv(\"outputs/score_csvs/nounexplodev1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9674f4d7-7a26-4da6-b198-465ac65f1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_vals = rerank_dist(noun_explode, rerank_single, ['utnoun', 'utnoun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53279b60-3433-4b01-893d-2c8fec2e1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    }
   ],
   "source": [
    "# get model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cfa9a73-bf14-4d57-a275-556998f9d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_graph_ind(\"outputs/graph_pickles/frtest_reversed/\", 0, encodemod, default_scofunct, \"noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "494602b3-f9f6-458b-818e-e7502b0417bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': '<s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, not the least of whom she has accused of conducting a policy of abduction for ransom.',\n",
       " 'ref': 'After all, as a campaigning investigative journalist she made many people angry besides Putin, not least of which is the current Chechen Prime Minister, Ramzan Kadyrov, whom she accused of a policy of kidnapping for ransom. ',\n",
       " 'src': \"Après tout, en tant que journaliste d'investigation en campagne, elle a enragé beaucoup d'autres gens outre Poutine, parmi lesquels l'actuel Premier ministre tchétchène Ramzan Kadyrov n'est pas des moindres, qu'elle a accusé de mener une politique d'enlèvements contre rançons. \"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b5000-f40e-4d1c-99fc-fd5b8825e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "get_scores_auto([res['hyp'][4:]], [\"noun\"], [], \"utnoun\", \"comstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb72abd-9e21-48f9-8938-027af396c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "npreds = pd.read_csv(\"outputs/predcsvs/noun_comstyle_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f8e9635-b32a-48da-a640-069d7037fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns = list(noun_explode['ref'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a207c98a-3d08-485f-9ba5-24442d3dcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for u in uns: \n",
    "    res.append(float(npreds[npreds['ref']==u]['utnoun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "588f3005-f446-4b5b-b033-52773fced2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628873924911022"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46bec18c-887d-4321-93d5-181b2397da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [gold_vals[i] - res[i] for i in range(len(res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43322d9e-ad1f-41d2-ad0c-8ad98bd61897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08779214024543762"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aa2f2d3-1eb1-4b2b-91bd-57efc3c7ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35abaad2-ca21-4f3c-8a3e-f6400f733df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1., 21., 17., 32., 15.,  8.,  3.,  1.]),\n",
       " array([-0.16788018, -0.11897451, -0.07006885, -0.02116318,  0.02774248,\n",
       "         0.07664815,  0.12555381,  0.17445948,  0.22336514,  0.2722708 ,\n",
       "         0.32117647]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1869be46-386f-4077-be92-7d8f971fd890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "24\n",
      "29\n",
      "30\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(diffs)):\n",
    "    if diffs[i]<0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e20b56f8-3949-4fd7-8a9f-d57f04a9ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = npreds[npreds['ref']==uns[13]]['ahyp'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2719e3fb-0c51-4072-911e-b90b57cd39de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>hyp</th>\n",
       "      <th>utnoun</th>\n",
       "      <th>unique_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27070</th>\n",
       "      <td>27070</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards much mo...</td>\n",
       "      <td>0.393927</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>27071</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to much more re...</td>\n",
       "      <td>0.383695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>27072</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to a much more ...</td>\n",
       "      <td>0.398260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>27073</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards a much ...</td>\n",
       "      <td>0.409214</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27074</th>\n",
       "      <td>27074</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards far mor...</td>\n",
       "      <td>0.390841</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28342</th>\n",
       "      <td>28342</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards far mor...</td>\n",
       "      <td>0.621482</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28343</th>\n",
       "      <td>28343</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path toward much mor...</td>\n",
       "      <td>0.623692</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28344</th>\n",
       "      <td>28344</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to far more res...</td>\n",
       "      <td>0.606072</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28345</th>\n",
       "      <td>28345</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards much mo...</td>\n",
       "      <td>0.623454</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28346</th>\n",
       "      <td>28346</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to much more re...</td>\n",
       "      <td>0.609591</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                src  \\\n",
       "27070       27070  En l’absence d'une voie claire vers une union ...   \n",
       "27071       27071  En l’absence d'une voie claire vers une union ...   \n",
       "27072       27072  En l’absence d'une voie claire vers une union ...   \n",
       "27073       27073  En l’absence d'une voie claire vers une union ...   \n",
       "27074       27074  En l’absence d'une voie claire vers une union ...   \n",
       "...           ...                                                ...   \n",
       "28342       28342  En l’absence d'une voie claire vers une union ...   \n",
       "28343       28343  En l’absence d'une voie claire vers une union ...   \n",
       "28344       28344  En l’absence d'une voie claire vers une union ...   \n",
       "28345       28345  En l’absence d'une voie claire vers une union ...   \n",
       "28346       28346  En l’absence d'une voie claire vers une union ...   \n",
       "\n",
       "                                                     ref  \\\n",
       "27070  Absent a clear path to a much tighter fiscal a...   \n",
       "27071  Absent a clear path to a much tighter fiscal a...   \n",
       "27072  Absent a clear path to a much tighter fiscal a...   \n",
       "27073  Absent a clear path to a much tighter fiscal a...   \n",
       "27074  Absent a clear path to a much tighter fiscal a...   \n",
       "...                                                  ...   \n",
       "28342  Absent a clear path to a much tighter fiscal a...   \n",
       "28343  Absent a clear path to a much tighter fiscal a...   \n",
       "28344  Absent a clear path to a much tighter fiscal a...   \n",
       "28345  Absent a clear path to a much tighter fiscal a...   \n",
       "28346  Absent a clear path to a much tighter fiscal a...   \n",
       "\n",
       "                                                     hyp    utnoun  \\\n",
       "27070  In the absence of a clear path towards much mo...  0.393927   \n",
       "27071  In the absence of a clear path to much more re...  0.383695   \n",
       "27072  In the absence of a clear path to a much more ...  0.398260   \n",
       "27073  In the absence of a clear path towards a much ...  0.409214   \n",
       "27074  In the absence of a clear path towards far mor...  0.390841   \n",
       "...                                                  ...       ...   \n",
       "28342  In the absence of a clear path towards far mor...  0.621482   \n",
       "28343  In the absence of a clear path toward much mor...  0.623692   \n",
       "28344  In the absence of a clear path to far more res...  0.606072   \n",
       "28345  In the absence of a clear path towards much mo...  0.623454   \n",
       "28346  In the absence of a clear path to much more re...  0.609591   \n",
       "\n",
       "       unique_nouns  \n",
       "27070             5  \n",
       "27071             4  \n",
       "27072             4  \n",
       "27073             4  \n",
       "27074             5  \n",
       "...             ...  \n",
       "28342             8  \n",
       "28343             7  \n",
       "28344             7  \n",
       "28345             8  \n",
       "28346             7  \n",
       "\n",
       "[1277 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_explode[noun_explode['ref']==uns[13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a8b4b49-3785-43a7-b70c-e67dd7167e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the absence of a clear path towards a much more restrictive financial and political union, which can only be achieved by means of a constitutional change, the euro system’s current “transition house\" of the euro system looks increasingly unsustainable.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3649ee2d-7959-439e-8d5c-0540846e3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.arange(10, dtype=torch.long).view(-1, 1)\n",
    "r = torch.arange(10, dtype=torch.long).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162d485c-94c2-4c4e-b7be-762045602f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[511, 510, 509, 508, 507, 506, 505, 504, 503, 502],\n",
       "        [512, 511, 510, 509, 508, 507, 506, 505, 504, 503],\n",
       "        [513, 512, 511, 510, 509, 508, 507, 506, 505, 504],\n",
       "        [514, 513, 512, 511, 510, 509, 508, 507, 506, 505],\n",
       "        [515, 514, 513, 512, 511, 510, 509, 508, 507, 506],\n",
       "        [516, 515, 514, 513, 512, 511, 510, 509, 508, 507],\n",
       "        [517, 516, 515, 514, 513, 512, 511, 510, 509, 508],\n",
       "        [518, 517, 516, 515, 514, 513, 512, 511, 510, 509],\n",
       "        [519, 518, 517, 516, 515, 514, 513, 512, 511, 510],\n",
       "        [520, 519, 518, 517, 516, 515, 514, 513, 512, 511]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l - r)+512-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5e2c3-788e-4a31-8a94-aba75d87b709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf8ef2-1db0-4381-b151-3827a0fdd7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
