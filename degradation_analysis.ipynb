{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "77b33fc0-6d93-4f8f-8413-57dde477187d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook to pinpoint degradation, rapid fire some more ideas, using noun setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27b5cec5-1c20-41d8-b5fa-e2255b2f3d61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-24 06:27:13.334574: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-12-24 06:27:13.334596: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.efficient_rerank import get_effrerank_model, run_comstyle\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from transformers import AutoTokenizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbe0696-b392-423b-b209-58d0b808b847",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_explode = pd.read_csv(\"outputs/score_csvs/enruexplodev1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e0ce4d2-98c9-4482-a159-702288bb5c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_fewsamp = pd.read_csv(\"outputs/score_csvs/enrufewsampv1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a3cb914-a97a-496c-926f-846c3a76368d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get graph to examine\n",
    "ind = 3\n",
    "base = \"outputs/graph_pickles/nounfull_exploded/\"\n",
    "#base = \"outputs/graph_pickles/rutest_reversed/\"\n",
    "graph = pickle.load(open(base+str(ind), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bedae011-9503-4b80-95dc-ec0e18a4b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get exploded paths, scored, for the graph\n",
    "noun_explode = pd.read_csv(\"outputs/score_csvs/frenbeam12v1.csv\")\n",
    "\n",
    "#noun_explode = pd.read_csv(\"outputs/score_csvs/nounexplodev1.csv\")\n",
    "#noun_explode = pd.read_csv(\"outputs/score_csvs/nounexplodev1.csv\")\n",
    "texplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "bestcand = np.argmax(list(texplode['utnoun']))\n",
    "bestcand = texplode.iloc[bestcand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ab64c70-f0cb-45e5-8011-e8f4c4f250ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper for exploding paths\n",
    "def explode_helper(prevpath, node, apaths, tok):\n",
    "    prevpath.append(node.token_idx)\n",
    "    if len(node.nextlist)==0:\n",
    "        apaths.append(tok.decode(prevpath))\n",
    "    else:\n",
    "        for n in node.nextlist:\n",
    "            explode_helper(prevpath, n, apaths, tok)\n",
    "    prevpath.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f9012099-8198-43ef-a86d-51aaa8b538d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pts = []\n",
    "explode_helper([], flnodes[0], pts, xlm_tok)\n",
    "pts = [p[4:] for p in pts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2b7086be-3f1e-41d8-bc71-b0362acc02df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To understand the benefits of emigration, the case of Kallstadt, a small farmer’s town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on 14 March 1869.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestcand['hyp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be428eea-a3a3-4a73-a395-31710aa11d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To understand the benefits of emigration, the case of Kallstadt, a small-scale farmers’ town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on March 14, 1869.\n"
     ]
    }
   ],
   "source": [
    "bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "            flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, default_scofunct, \"noun\", {'afunc':randomsingle}, True)\n",
    "predhyp = bestpath[0][4:]\n",
    "print(predhyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "14721e6f-c90c-4699-858d-2f8d1bfcf607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recombination sanity check\n",
    "torch.sum(mask!=torch.tril(mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82c7f0d4-b7f4-4ad8-b38a-1a414e0fe49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['roberta.pooler.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "freeze embeds\n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "encodemod = get_effrerank_model(\"noun\")\n",
    "xlm_tok = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9326386-4d31-4d77-97e6-cbb402823871",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomsingle(mask, row, checknodes, mlen):\n",
    "    if row>0:\n",
    "        avail = []\n",
    "        # use next with highest prob\n",
    "        for n in checknodes:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                avail.append(n)\n",
    "        if len(avail)==0:\n",
    "            print(len(checknodes))\n",
    "            print(row)\n",
    "        mask[row][random.choice(avail).canvpos] = 1\n",
    "        \n",
    "def useall(mask, row, checknodes, mlen):\n",
    "    if row>0:\n",
    "        # use next with highest prob\n",
    "        for n in checknodes:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                mask[row][n.canvpos] = 1\n",
    "        \n",
    "# randomly use nodes, but possibility of more than one previous node being used\n",
    "def randommulti(mask, row, checknodes, mlen):\n",
    "    if row>0:\n",
    "        avail = []\n",
    "        # use next with highest prob\n",
    "        for n in checknodes:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                avail.append(n)\n",
    "        if len(avail)==0:\n",
    "            print(len(checknodes))\n",
    "            print(row)\n",
    "        #mask[row][random.choice(avail).canvpos] = 1\n",
    "        \n",
    "        tosamp = random.randint(1, len(avail))\n",
    "        samp = random.sample(avail, tosamp)\n",
    "        # use next with highest prob\n",
    "        for n in samp:\n",
    "            if n.canvpos<mlen: # keep within bounds\n",
    "                mask[row][n.canvpos] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "765b0121-6fd7-43df-8771-280b89cffcad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score check (at token level) the best option, and the new option (should be same until they get to non-identical tokens)\n",
    "\n",
    "SETLEN = 457\n",
    "\n",
    "# get token level scores from model\n",
    "def get_hyp_sco(inphyp, posids=None):\n",
    "    \n",
    "    tokens = xlm_tok(inphyp, return_tensors='pt').to(device)\n",
    "    tokens = tokens.input_ids\n",
    "    if posids is None: \n",
    "        positionids = None\n",
    "    else:\n",
    "        # get token at the end\n",
    "        positionids = torch.tensor(posids+[posids[-1]+1]).unsqueeze(0).to(device)\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(device)\n",
    "\n",
    "    toked_inp = xlm_tok([\"noun\"], return_tensors=\"pt\").to(device)\n",
    "    predout = encodemod(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    tmppred = predout['score']\n",
    "    #norm = predout['norm']\n",
    "    return tmppred\n",
    "\n",
    "# test out reranking multiple EEL outputs (observe improvements)\n",
    "def lattice_multi_rerank(ind, n):\n",
    "    # get graph, get the \"best candidate\"\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    nexplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "    #print(len(nexplode))\n",
    "    if len(nexplode)==0:\n",
    "        return None\n",
    "    bestcand = np.argmax(list(nexplode['utnoun']))\n",
    "    bestcand = nexplode.iloc[bestcand]\n",
    "    \n",
    "    goldsco = get_hyp_sco(bestcand['hyp'])\n",
    "    goldsco = torch.sum(goldsco[0])\n",
    "    bpred = -100\n",
    "    bhyp = \"\"\n",
    "    ascos = []\n",
    "    ahyps = []\n",
    "    numnodes = 0\n",
    "    for i in range(n):\n",
    "        graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "        # generate with model\n",
    "        bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "            flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, default_scofunct, \"noun\", {'afunc':useall}, True)\n",
    "        predhyp = bestpath[0][4:]\n",
    "        hypsco = torch.sum(get_hyp_sco(predhyp)[0])\n",
    "        if hypsco>bpred:\n",
    "            bpred = hypsco\n",
    "            bhyp = predhyp\n",
    "        ascos.append(hypsco)\n",
    "        ahyps.append(predhyp)\n",
    "        numnodes = len(flattened)\n",
    "    return bpred, bhyp, goldsco, bestcand['hyp'], ascos, ahyps, numnodes\n",
    "\n",
    "# get multiple things with the lattice, rerank on each (not optimized, so it is a bit slow)\n",
    "def all_lattice_multi(n):\n",
    "    pdistr = []\n",
    "    cnt = 0\n",
    "    for i in range(SETLEN):\n",
    "        try:\n",
    "            outval = lattice_multi_rerank(i, n)\n",
    "        except:\n",
    "            print(\"had an error\")\n",
    "        if outval==None:\n",
    "            continue\n",
    "        else:\n",
    "            print(cnt, \" \", i, \" \", outval[0], \" \", outval[2], \" \")\n",
    "            pdistr.append({\n",
    "                'hyp':outval[1],\n",
    "                'hypsco':outval[0],\n",
    "                'gold':outval[3],\n",
    "                'goldsco':outval[2],\n",
    "                'ascos':[float(f) for f in outval[4]],\n",
    "                'ahyps':outval[5],\n",
    "                'numnodes':outval[6]\n",
    "            })\n",
    "            cnt+=1\n",
    "    res = pd.DataFrame(pdistr)\n",
    "    return res\n",
    "\n",
    "# rerank given a random sample\n",
    "def all_unnoun_multi():\n",
    "    pdistr = []\n",
    "    cnt = 0\n",
    "    for i in range(SETLEN):\n",
    "        try:\n",
    "            graph = pickle.load(open(base+str(i), 'rb'))\n",
    "        except:\n",
    "            break\n",
    "        nexplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "        if len(nexplode)==0:\n",
    "            continue\n",
    "        nexplode = nexplode.sample(n=32)\n",
    "        assert len(nexplode)==32\n",
    "        bestcand = np.argmax(list(nexplode['utnoun']))\n",
    "        bestcand = nexplode.iloc[bestcand]\n",
    "\n",
    "        goldsco = get_hyp_sco(bestcand['hyp'])\n",
    "        goldsco = torch.sum(goldsco[0])\n",
    "        pdistr.append(goldsco)\n",
    "    \n",
    "    return pdistr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2226624f-7b99-4a2b-b877-b330ddbc3086",
   "metadata": {},
   "outputs": [],
   "source": [
    "unnoun = all_unnoun_multi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0213fd33-a9cf-4353-a36f-d4895c54a1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.5102, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " 'To understand the benefits of emigration, the case of Kallstadt, a small-scale farmers’ town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on March 14, 1869.',\n",
       " tensor(1.5723, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " 'To understand the benefits of emigration, the case of Kallstadt, a small farmer’s town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on 14 March 1869.',\n",
       " [tensor(1.5102, device='cuda:0', grad_fn=<SumBackward0>)],\n",
       " ['To understand the benefits of emigration, the case of Kallstadt, a small-scale farmers’ town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on March 14, 1869.'],\n",
       " 399)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lattice_multi_rerank(3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "492cd70d-c5d1-4b19-8297-2b2d11d34617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9343, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(unnoun)/len(unnoun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a39caf9-bd68-4aca-850e-a610c7000631",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti = all_lattice_multi(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9940da7a-691b-4e13-9a04-431ad52a12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti.to_csv(\"outputs/predcsvs/noun_comstyle_multi_32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4f9ca38-a694-4040-8747-86a0baeb5368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allmulti)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "463df3af-ea19-48a1-b48f-7809ac336846",
   "metadata": {},
   "outputs": [],
   "source": [
    "#allmulti = pd.read_csv(\"outputs/predcsvs/noun_comstyle_multi_32.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "75cac813-5596-4353-a620-0c935c891656",
   "metadata": {},
   "outputs": [],
   "source": [
    "oldamult = allmulti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2852a338-0f51-4bda-bdb7-6b80e29bf2d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold values are the same...\n",
    "for i in range(len(allmulti)):\n",
    "    if allmulti['gold'].iloc[i] not in oldamult['gold'].iloc[i]:\n",
    "        print(\"bad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf3f729-35e5-4a05-8bba-5287f89af8cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(list(allmulti['goldsco']), list(oldamult['goldsco'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8cb619dc-5f9a-4446-977f-93a94fcf0c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.9787, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.9597, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(0.0190, device='cuda:0', grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def mean(l):\n",
    "    l = list(l)\n",
    "    if type(l[0]) is str:\n",
    "        l = [float(re.findall(\"\\d+\\.\\d+\", lent)[0]) for lent in l]\n",
    "    return sum(l)/len(l)\n",
    "\n",
    "print(mean(allmulti['goldsco']))\n",
    "print(mean(allmulti['hypsco']))\n",
    "print(mean(allmulti['goldsco'])-mean(allmulti['hypsco']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c57df72d-dacd-4744-b7d8-1b7600d16ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti['unoun'] = [float(f) for f in unnoun]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29bfd578-5984-4911-8050-eceb09b9519e",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti['hypsco']  = [float(re.findall(\"\\d+\\.\\d+\", lent)[0]) for lent in allmulti['hypsco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f25690c0-819e-4b1c-908d-eeaf952e47d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "allmulti['goldsco']  = [float(re.findall(\"\\d+\\.\\d+\", lent)[0]) for lent in allmulti['goldsco']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9e8ba94-45db-4b82-a7b9-266614238c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8dceb051-e0d3-4535-a4e6-a8063bb80aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  2.,  2.,  5., 67.,  7., 10.,  3.,  1.,  1.]),\n",
       " array([-0.18148696, -0.13931837, -0.09714978, -0.05498118, -0.01281259,\n",
       "         0.029356  ,  0.0715246 ,  0.11369319,  0.15586178,  0.19803038,\n",
       "         0.24019897]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([float(f) for f in list(allmulti['goldsco']-allmulti['hypsco'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5dc04437-1cae-4a37-9f4b-b13564e88fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allmulti[allmulti['numnodes']>512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1c0b1a89-6b07-4310-8f9d-a0ef4f853889",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'At a time when all nations are facing their own challenges, there is a need to forge a common agenda at the global level that will ensure that the seven billionth baby and future generations grow up in a world of peace, prosperity, freedom and justice that lasts.'"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allmulti[allmulti['goldsco']-allmulti['hypsco']>.2]['gold'].iloc[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6873d830-cf54-44ce-aec6-aeec66fcea40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.8882, device='cuda:0', grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(allmulti['hypsco'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce368595-413b-4112-a3f3-a7bac0f532d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated - \n",
      "To understand the benefits of emigration, the case of Kallstadt, a small-scale farmers’ town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on March 14, 1869.\n"
     ]
    }
   ],
   "source": [
    "ind = 3\n",
    "# get model output\n",
    "graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "sco_funct = default_scofunct\n",
    "bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "        flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, sco_funct, \"noun\", {'afunc':randomsingle}, True)\n",
    "predhyp = bestpath[0][4:]\n",
    "print(\"generated - \\n\"+predhyp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fc18d6cf-49e0-4e70-9297-038778885894",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predhyp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [34]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m bestsco \u001b[38;5;241m=\u001b[39m get_hyp_sco(bestcand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 2\u001b[0m hypsco \u001b[38;5;241m=\u001b[39m get_hyp_sco(\u001b[43mpredhyp\u001b[49m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(bestcand[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyp\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(torch\u001b[38;5;241m.\u001b[39msum(bestsco[\u001b[38;5;241m0\u001b[39m]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predhyp' is not defined"
     ]
    }
   ],
   "source": [
    "bestsco = get_hyp_sco(bestcand['hyp'])\n",
    "hypsco = get_hyp_sco(predhyp)\n",
    "print(bestcand['hyp'])\n",
    "print(torch.sum(bestsco[0]))\n",
    "print(predhyp)\n",
    "print(torch.sum(hypsco[0]))\n",
    "print(bsco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cb5f9be-b9ff-408c-a885-2c32e3149cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test out reranking multiple EEL outputs (observe improvements)\n",
    "def debug_multi_rerank(ind):\n",
    "    # get graph, get the \"best candidate\"\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    nexplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "    print(len(nexplode))\n",
    "    if len(nexplode)==0:\n",
    "        return None\n",
    "    bestcand = np.argmax(list(nexplode['utnoun']))\n",
    "    bestcand = nexplode.iloc[bestcand]\n",
    "    \n",
    "    goldsco = get_hyp_sco(bestcand['hyp'])\n",
    "    goldsco = torch.sum(goldsco[0])\n",
    "    bpred = -100\n",
    "    bhyp = \"\"\n",
    "    ascos = []\n",
    "    ahyps = []\n",
    "    numnodes = 0\n",
    "    \n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    # generate with model\n",
    "    bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "        flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, default_scofunct, \"noun\", {'afunc':useall}, True)\n",
    "    predhyp = bestpath[0][4:]\n",
    "    hypsco = torch.sum(get_hyp_sco(predhyp)[0])\n",
    "    \n",
    "    numnodes = len(flattened)\n",
    "    return bpred, bhyp, goldsco, bestcand['hyp'], ascos, ahyps, numnodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "00f253a1-83c8-4566-8ee9-4b9e784dd913",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist[0].prevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1dee2fc3-e6d3-4553-9ac5-0d94bf7fad44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'en_XX'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist[0].token_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a46053ca-70b4-45bf-9822-cd0b78896c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = pickle.load(open(base+str(3), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dd991223-bd5c-40e6-8be4-c5c5fe262cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<src.recom_search.model.beam_node_reverse.ReverseNode at 0x7f57456d5670>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph['root'].nextlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2caad24-4b54-474c-ba4f-02d2d8cea4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "mb_tok = AutoTokenizer.from_pretrained(\"facebook/mbart-large-50-many-to-one-mmt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dd3dfc6b-268e-44e7-a855-704b2ca8a55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recursive method to sanity check first (assume no recomb, no cycles)\n",
    "def explode_path(ind):\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    allpaths = []\n",
    "    explode_helper([], graph['root'], allpaths, mb_tok)\n",
    "    allpaths = [a[10:] for a in allpaths]\n",
    "    nexplode = noun_explode[noun_explode['ref']==graph['ref']].reset_index()\n",
    "    return allpaths, list(nexplode['hyp'])\n",
    "\n",
    "# helper for exploding paths\n",
    "def explode_helper(prevpath, node, apaths, tok):\n",
    "    prevpath.append(node.token_idx)\n",
    "    if len(node.nextlist)==0:\n",
    "        #print(prevpath)\n",
    "        apaths.append(mb_tok.decode(prevpath))\n",
    "    else:\n",
    "        for n in node.nextlist:\n",
    "            explode_helper(prevpath, n, apaths, tok)\n",
    "    prevpath.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e40280-a38e-4322-ae84-6e31d7590177",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestpath , flattened, pnodes, mask, sents, posids, pred, _, \\\n",
    "        flnodes, dpath, beplist, besclist, totnodes, bsco = run_comstyle(graph, encodemod, default_scofunct, \"noun\", {'afunc':useall}, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d4cacaca-3f42-4d38-89dd-accb758a8eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "apths = []\n",
    "explode_helper([], pnodes[0][0], apths, xlm_tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a2ba3171-9a37-437c-9520-b44c54a87791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cb3236bb-501f-412b-9c21-3332faa53888",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lattice reversal is ok \n",
    "for p in postrev:\n",
    "    assert p in prerev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bcd65d-8c67-440f-aa56-c6ccc6a11b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# have some doubts about explosion algorithm, check if outputs are the same\n",
    "def new_explode_paths(ind):\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    queue = []\n",
    "    visited = []\n",
    "    # start from root\n",
    "    queue.append(([], graph['root']))\n",
    "    while len(queue)>0:\n",
    "        # always append token to end\n",
    "        prevtoks, curnode = queue.pop()\n",
    "        # avoid cycles\n",
    "        if curnode in visited:\n",
    "            mb_tok\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cae5e4d6-2cd4-4385-819a-2b9b20c3f756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-100,\n",
       " '',\n",
       " tensor(1.5723, device='cuda:0', grad_fn=<SumBackward0>),\n",
       " 'To understand the benefits of emigration, the case of Kallstadt, a small farmer’s town in southwestern Germany, is particularly telling. Friedrich (Fred) Trump – Donald Trump’s grandfather – was born there on 14 March 1869.',\n",
       " [],\n",
       " [],\n",
       " 399)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debug_multi_rerank(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b3825e66-875b-4898-a81c-2a727b731788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that masks are functioning in an ok way (passed)\n",
    "def mask_sanity(msk, inps, posids):\n",
    "    allinps = []\n",
    "    allpos = []\n",
    "    for m in msk:\n",
    "        # get spare\n",
    "        tmptoks = []\n",
    "        tmppos = []\n",
    "        for t in range(len(m)):\n",
    "            if m[t]!=0:\n",
    "                tmptoks.append(inps[t])\n",
    "                tmppos.append(posids[t])\n",
    "        resort = sorted(zip(tmppos, tmptoks))\n",
    "        tmptoks = [x for _,x in resort]\n",
    "        tmppos = [x for x, _ in resort]\n",
    "        allinps.append(torch.tensor(tmptoks).int())\n",
    "        allpos.append(tmppos)\n",
    "    return allinps, allpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7496785e-4f58-4a94-ab39-61d6a721eb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1, 2]\n",
    "b = ['a', 'b']\n",
    "c = zip(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7f6d1366-ff08-4e10-99f7-90b60451db51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 'a'), (2, 'b')]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0bea43a-b983-4847-b787-8bff05432d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score check (at token level) the best option, and the new option (should be same until they get to non-identical tokens)\n",
    "\n",
    "# get token level scores from model\n",
    "def get_hyp_sco_verb(inphyp, posids=None):\n",
    "    \n",
    "    tokens = xlm_tok(inphyp, return_tensors='pt').to(device)\n",
    "    tokens = tokens.input_ids\n",
    "    #print(inphyp)\n",
    "    #print(tokens)\n",
    "    \n",
    "    if posids is None: \n",
    "        positionids = torch.arange(len(tokens[0])).unsqueeze(0).to(device)+2\n",
    "        print(positionids)\n",
    "        #mask = tokens.ne(-1).int()\n",
    "        #incremental_indices = (torch.cumsum(mask, dim=1).type_as(mask) + 0) * mask\n",
    "        #positionids = incremental_indices.long() + 1\n",
    "    elif -1 in posids:\n",
    "        positionids = None\n",
    "    else:\n",
    "        # get token at the end\n",
    "        positionids = torch.tensor(posids+[posids[-1]+1]).unsqueeze(0).to(device)\n",
    "        print(positionids)\n",
    "    #print(positionids)\n",
    "    tmpmask = torch.tril(torch.ones(len(tokens[0]), len(tokens[0]))).unsqueeze(0).to(device)\n",
    "    #print(tokens.shape)\n",
    "    #print(positionids.shape)\n",
    "    #print()\n",
    "    #print(tokens.shape)\n",
    "    #print(torch.max(positionids))\n",
    "    toked_inp = xlm_tok([\"noun\"], return_tensors=\"pt\").to(device)\n",
    "    predout = encodemod(toked_inp.input_ids, toked_inp.attention_mask, tokens, positionids, \\\n",
    "        tmpmask)\n",
    "    tmppred = predout['score']\n",
    "    #norm = predout['norm']\n",
    "    return tmppred, tokens, positionids, tmpmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c55cb90e-db73-4b4e-a74b-cdb89b262c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = mask.to(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4c85186c-b788-426e-940d-85e17145ae41",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [38]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ainps, apos \u001b[38;5;241m=\u001b[39m \u001b[43mmask_sanity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msents\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mposids\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36mmask_sanity\u001b[0;34m(msk, inps, posids)\u001b[0m\n\u001b[1;32m      8\u001b[0m tmppos \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(m)):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m m[t]\u001b[38;5;241m!=\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     11\u001b[0m         tmptoks\u001b[38;5;241m.\u001b[39mappend(inps[t])\n\u001b[1;32m     12\u001b[0m         tmppos\u001b[38;5;241m.\u001b[39mappend(posids[t])\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "ainps, apos = mask_sanity(mask, sents[0], posids[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "471a3e99-a58a-4711-af00-278ae42bd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "testsens = xlm_tok.batch_decode(ainps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7aea7f9f-40fd-45a3-8492-d8da60230f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "         20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]],\n",
      "       device='cuda:0')\n",
      "tensor([[ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "         20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 33, 34, 35, 36]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "index = 50\n",
    "#print(apos[index])\n",
    "p_pred, p_tok, p_pos, p_mask = get_hyp_sco_verb(testsens[index][4:], None)\n",
    "n_pred, n_tok, n_pos, n_mask = get_hyp_sco_verb(testsens[index][4:], apos[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "42867136-3d3a-4f92-9489-90773329536d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.0, 0.0),\n",
       " (0.0008179583819583058, 0.0008406794513575733),\n",
       " (0.0008266505901701748, 0.0008496131049469113),\n",
       " (0.0008246707147918642, 0.0008475782815366983),\n",
       " (0.0008184637990780175, 0.000841198896523565),\n",
       " (0.0015539380256086588, 0.001597102964296937),\n",
       " (0.0008968535694293678, 0.0009217661572620273),\n",
       " (0.0009072879911400378, 0.0009324904531240463),\n",
       " (0.001034791232086718, 0.0010635354556143284),\n",
       " (0.02084461599588394, 0.02142363227903843),\n",
       " (0.00419287895783782, 0.004309347830712795),\n",
       " (0.004512493032962084, 0.004637839738279581),\n",
       " (0.035868171602487564, 0.0368645079433918),\n",
       " (0.005156939383596182, 0.005300187971442938),\n",
       " (0.04388004168868065, 0.0450989305973053),\n",
       " (0.008241300471127033, 0.00847022607922554),\n",
       " (0.05495584383606911, 0.05648239329457283),\n",
       " (0.01089283637702465, 0.011195415630936623),\n",
       " (0.00667963782325387, 0.0068651833571493626),\n",
       " (0.023293253034353256, 0.02394028753042221),\n",
       " (0.015207698568701744, 0.01563013345003128),\n",
       " (0.03848055750131607, 0.039549462497234344),\n",
       " (0.07867869734764099, 0.08086422085762024),\n",
       " (0.024155782535672188, 0.0248267762362957),\n",
       " (0.01963886246085167, 0.020184386521577835),\n",
       " (0.03561443090438843, 0.03660372272133827),\n",
       " (0.09380032867193222, 0.09640589356422424),\n",
       " (0.02502523362636566, 0.02572038024663925),\n",
       " (0.02230800688266754, 0.022927673533558846),\n",
       " (0.10204185545444489, 0.10487635433673859),\n",
       " (0.024956030771136284, 0.025649255141615868),\n",
       " (0.02451021783053875, 0.025191057473421097),\n",
       " (0.019400250166654587, 0.019761081784963608),\n",
       " (0.02253054454922676, 0.020123198628425598),\n",
       " (0.11360475420951843, 0.11427363008260727),\n",
       " (0.008861389942467213, 0.009091651067137718)]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip([float(f) for f in p_pred[0]], [float(f) for f in n_pred[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2e5dc36-6f53-4863-8fb9-0eb072237d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n"
     ]
    }
   ],
   "source": [
    "pred1, tok1, pos1, mask1 = get_hyp_sco_verb(\"I am nice\")\n",
    "pred2, tok2, pos2, mask2 = get_hyp_sco_verb(\"I am cool\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97ba37cb-4836-4592-9052-cc0ff58c4e35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0000],\n",
      "         [0.0074],\n",
      "         [0.0029],\n",
      "         [0.0081],\n",
      "         [0.0036]]], device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor([[[0.0000],\n",
      "         [0.0074],\n",
      "         [0.0029],\n",
      "         [0.0080],\n",
      "         [0.0054]]], device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(pred1)\n",
    "print(pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72c979e1-e7eb-4afb-9ad0-4f82f59e7984",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpos = []\n",
    "for pl in apos:\n",
    "    tmp = []\n",
    "    for p in pl:\n",
    "        tmp.append(int(p))\n",
    "    fpos.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec3d4dce-36c6-4f5e-8098-637ef0cd7a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos ids as a source of degradation?\n",
    "for i in range(1, len(fpos)):\n",
    "    for j in range(1, len(fpos[i])):\n",
    "        if fpos[i][j] is not fpos[i][j-1]+1:\n",
    "            print(\"off at \", i, \" \", fpos[i][j-1], \" \",fpos[i][j] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38768fc2-52e2-420c-835d-7ac3a975358f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpos[40:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da8c4e12-996b-44ac-9708-af5f130e0605",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_graph_ind(base, ind, model, funct, outfile):\n",
    "    graph = pickle.load(open(base+str(ind), 'rb'))\n",
    "    return {\n",
    "        'hyp':run_comstyle(graph, model, funct, outfile, False)[0],\n",
    "        'ref':graph['ref'],\n",
    "        'src':graph['input']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c34654-f958-4105-9e1b-e54e2b40ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from encode_utils.rerank_data import rerank_dist, rerank_single\n",
    "from encode_utils.mt_scores import get_scores_auto\n",
    "from encode_utils.sco_funct import weightaddprob, default_scofunct\n",
    "\n",
    "from test_efficient_rerank import test_graph_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c1bcd8b-0f9a-408d-88c8-a60ff09e4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(l):\n",
    "    return sum(l)/len(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5a9d32ca-5164-4d35-897f-2eaffbe2c047",
   "metadata": {},
   "outputs": [],
   "source": [
    "noun_explode = pd.read_csv(\"outputs/score_csvs/nounexplodev1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9674f4d7-7a26-4da6-b198-465ac65f1a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_vals = rerank_dist(noun_explode, rerank_single, ['utnoun', 'utnoun'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "53279b60-3433-4b01-893d-2c8fec2e1a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlm-roberta-large were not used when initializing XLMRobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing XLMRobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLMRobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Encoder model frozen.\n",
      "Loading weights from /mnt/data1/prasann/latticegen/lattice-generation/COMET/lightning_logs/version_44/checkpoints/epoch=9-step=40000.ckpt.\n"
     ]
    }
   ],
   "source": [
    "# get model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3cfa9a73-bf14-4d57-a275-556998f9d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = test_graph_ind(\"outputs/graph_pickles/frtest_reversed/\", 0, encodemod, default_scofunct, \"noun\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "494602b3-f9f6-458b-818e-e7502b0417bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hyp': '<s> After all, as a field investigative journalist, she has instilled in many people besides Putin, including the current Chechen Prime Minister Ramzan Kadyrov, not the least of whom she has accused of conducting a policy of abduction for ransom.',\n",
       " 'ref': 'After all, as a campaigning investigative journalist she made many people angry besides Putin, not least of which is the current Chechen Prime Minister, Ramzan Kadyrov, whom she accused of a policy of kidnapping for ransom. ',\n",
       " 'src': \"Après tout, en tant que journaliste d'investigation en campagne, elle a enragé beaucoup d'autres gens outre Poutine, parmi lesquels l'actuel Premier ministre tchétchène Ramzan Kadyrov n'est pas des moindres, qu'elle a accusé de mener une politique d'enlèvements contre rançons. \"}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b5000-f40e-4d1c-99fc-fd5b8825e57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "get_scores_auto([res['hyp'][4:]], [\"noun\"], [], \"utnoun\", \"comstyle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cb72abd-9e21-48f9-8938-027af396c06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "npreds = pd.read_csv(\"outputs/predcsvs/noun_comstyle_v2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2f8e9635-b32a-48da-a640-069d7037fab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "uns = list(noun_explode['ref'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a207c98a-3d08-485f-9ba5-24442d3dcc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for u in uns: \n",
    "    res.append(float(npreds[npreds['ref']==u]['utnoun']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "588f3005-f446-4b5b-b033-52773fced2f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8628873924911022"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "46bec18c-887d-4321-93d5-181b2397da7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diffs = [gold_vals[i] - res[i] for i in range(len(res))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "43322d9e-ad1f-41d2-ad0c-8ad98bd61897",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08779214024543762"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2aa2f2d3-1eb1-4b2b-91bd-57efc3c7ae87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "35abaad2-ca21-4f3c-8a3e-f6400f733df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  1.,  1., 21., 17., 32., 15.,  8.,  3.,  1.]),\n",
       " array([-0.16788018, -0.11897451, -0.07006885, -0.02116318,  0.02774248,\n",
       "         0.07664815,  0.12555381,  0.17445948,  0.22336514,  0.2722708 ,\n",
       "         0.32117647]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1869be46-386f-4077-be92-7d8f971fd890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "24\n",
      "29\n",
      "30\n",
      "75\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(diffs)):\n",
    "    if diffs[i]<0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e20b56f8-3949-4fd7-8a9f-d57f04a9ed34",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = npreds[npreds['ref']==uns[13]]['ahyp'].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2719e3fb-0c51-4072-911e-b90b57cd39de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>src</th>\n",
       "      <th>ref</th>\n",
       "      <th>hyp</th>\n",
       "      <th>utnoun</th>\n",
       "      <th>unique_nouns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27070</th>\n",
       "      <td>27070</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards much mo...</td>\n",
       "      <td>0.393927</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27071</th>\n",
       "      <td>27071</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to much more re...</td>\n",
       "      <td>0.383695</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27072</th>\n",
       "      <td>27072</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to a much more ...</td>\n",
       "      <td>0.398260</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27073</th>\n",
       "      <td>27073</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards a much ...</td>\n",
       "      <td>0.409214</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27074</th>\n",
       "      <td>27074</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards far mor...</td>\n",
       "      <td>0.390841</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28342</th>\n",
       "      <td>28342</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards far mor...</td>\n",
       "      <td>0.621482</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28343</th>\n",
       "      <td>28343</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path toward much mor...</td>\n",
       "      <td>0.623692</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28344</th>\n",
       "      <td>28344</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to far more res...</td>\n",
       "      <td>0.606072</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28345</th>\n",
       "      <td>28345</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path towards much mo...</td>\n",
       "      <td>0.623454</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28346</th>\n",
       "      <td>28346</td>\n",
       "      <td>En l’absence d'une voie claire vers une union ...</td>\n",
       "      <td>Absent a clear path to a much tighter fiscal a...</td>\n",
       "      <td>In the absence of a clear path to much more re...</td>\n",
       "      <td>0.609591</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1277 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                                src  \\\n",
       "27070       27070  En l’absence d'une voie claire vers une union ...   \n",
       "27071       27071  En l’absence d'une voie claire vers une union ...   \n",
       "27072       27072  En l’absence d'une voie claire vers une union ...   \n",
       "27073       27073  En l’absence d'une voie claire vers une union ...   \n",
       "27074       27074  En l’absence d'une voie claire vers une union ...   \n",
       "...           ...                                                ...   \n",
       "28342       28342  En l’absence d'une voie claire vers une union ...   \n",
       "28343       28343  En l’absence d'une voie claire vers une union ...   \n",
       "28344       28344  En l’absence d'une voie claire vers une union ...   \n",
       "28345       28345  En l’absence d'une voie claire vers une union ...   \n",
       "28346       28346  En l’absence d'une voie claire vers une union ...   \n",
       "\n",
       "                                                     ref  \\\n",
       "27070  Absent a clear path to a much tighter fiscal a...   \n",
       "27071  Absent a clear path to a much tighter fiscal a...   \n",
       "27072  Absent a clear path to a much tighter fiscal a...   \n",
       "27073  Absent a clear path to a much tighter fiscal a...   \n",
       "27074  Absent a clear path to a much tighter fiscal a...   \n",
       "...                                                  ...   \n",
       "28342  Absent a clear path to a much tighter fiscal a...   \n",
       "28343  Absent a clear path to a much tighter fiscal a...   \n",
       "28344  Absent a clear path to a much tighter fiscal a...   \n",
       "28345  Absent a clear path to a much tighter fiscal a...   \n",
       "28346  Absent a clear path to a much tighter fiscal a...   \n",
       "\n",
       "                                                     hyp    utnoun  \\\n",
       "27070  In the absence of a clear path towards much mo...  0.393927   \n",
       "27071  In the absence of a clear path to much more re...  0.383695   \n",
       "27072  In the absence of a clear path to a much more ...  0.398260   \n",
       "27073  In the absence of a clear path towards a much ...  0.409214   \n",
       "27074  In the absence of a clear path towards far mor...  0.390841   \n",
       "...                                                  ...       ...   \n",
       "28342  In the absence of a clear path towards far mor...  0.621482   \n",
       "28343  In the absence of a clear path toward much mor...  0.623692   \n",
       "28344  In the absence of a clear path to far more res...  0.606072   \n",
       "28345  In the absence of a clear path towards much mo...  0.623454   \n",
       "28346  In the absence of a clear path to much more re...  0.609591   \n",
       "\n",
       "       unique_nouns  \n",
       "27070             5  \n",
       "27071             4  \n",
       "27072             4  \n",
       "27073             4  \n",
       "27074             5  \n",
       "...             ...  \n",
       "28342             8  \n",
       "28343             7  \n",
       "28344             7  \n",
       "28345             8  \n",
       "28346             7  \n",
       "\n",
       "[1277 rows x 6 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_explode[noun_explode['ref']==uns[13]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6a8b4b49-3785-43a7-b70c-e67dd7167e8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In the absence of a clear path towards a much more restrictive financial and political union, which can only be achieved by means of a constitutional change, the euro system’s current “transition house\" of the euro system looks increasingly unsustainable.'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3649ee2d-7959-439e-8d5c-0540846e3662",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = torch.arange(10, dtype=torch.long).view(-1, 1)\n",
    "r = torch.arange(10, dtype=torch.long).view(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162d485c-94c2-4c4e-b7be-762045602f94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[511, 510, 509, 508, 507, 506, 505, 504, 503, 502],\n",
       "        [512, 511, 510, 509, 508, 507, 506, 505, 504, 503],\n",
       "        [513, 512, 511, 510, 509, 508, 507, 506, 505, 504],\n",
       "        [514, 513, 512, 511, 510, 509, 508, 507, 506, 505],\n",
       "        [515, 514, 513, 512, 511, 510, 509, 508, 507, 506],\n",
       "        [516, 515, 514, 513, 512, 511, 510, 509, 508, 507],\n",
       "        [517, 516, 515, 514, 513, 512, 511, 510, 509, 508],\n",
       "        [518, 517, 516, 515, 514, 513, 512, 511, 510, 509],\n",
       "        [519, 518, 517, 516, 515, 514, 513, 512, 511, 510],\n",
       "        [520, 519, 518, 517, 516, 515, 514, 513, 512, 511]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(l - r)+512-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d5e2c3-788e-4a31-8a94-aba75d87b709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf8ef2-1db0-4381-b151-3827a0fdd7df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
